{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "from kan import KAN\n",
    "import string\n",
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = './media/datasets/archive.zip'\n",
    "extract_dir = './media/datasets/csv/'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "    zip_file.extractall(extract_dir)\n",
    "\n",
    "dataframe_train = pd.read_csv(extract_dir+'twitter_training.csv', names=['ID','user','SC','Comment'])\n",
    "dataframe_test = pd.read_csv(extract_dir+'twitter_validation.csv', names=['ID','user','SC','Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train.iloc[1250:1257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropRowValue(dataframe,column,values):\n",
    "    return dataframe[~dataframe[column].isin(values)]\n",
    "\n",
    "def sentimentFilter(sentence, category):\n",
    "    \"\"\"\n",
    "    By default the category entered to the sentimentFilter function will be transformed to 1\n",
    "    \"\"\"\n",
    "    sentiment_num_list = []\n",
    "    for sentiment in sentence:\n",
    "        if sentiment == category:\n",
    "            sentiment_num_list.append(1)\n",
    "        else:\n",
    "            sentiment_num_list.append(0)\n",
    "    return sentiment_num_list\n",
    "\n",
    "# training\n",
    "filter_dataframe_train = dropRowValue(dataframe_train,'SC',['Neutral','Irrelevant']).drop(['ID','user'], axis=1)\n",
    "list_x_train = filter_dataframe_train['Comment'].to_list()\n",
    "list_y_train = filter_dataframe_train['SC'].to_list()\n",
    "y_train = sentimentFilter(list_y_train,'Positive')\n",
    "\n",
    "# testing\n",
    "filter_dataframe_test = dropRowValue(dataframe_test,'SC',['Neutral','Irrelevant']).drop(['ID','user'], axis=1)\n",
    "list_x_test = filter_dataframe_test['Comment'].to_list()\n",
    "list_y_test = filter_dataframe_test['SC'].to_list()\n",
    "y_test = sentimentFilter(list_y_test,'Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "emoji.replace_emoji(\"Hello! ‚òÄÔ∏è I'm currently enjoying a beautiful day on a tropical island üèùÔ∏è while practicing some yoga üßò‚Äç‚ôÇÔ∏è and sipping on a refreshing watermelon juice üçâüçπ. The sound of the waves üåä and the warmth of the sun ‚òÄÔ∏è make it the perfect day to relax in my swimsuit üëô and listen to the birds ü¶ú singing in the palm trees üå¥. Don't forget your sunglasses üï∂Ô∏è!\",\n",
    "                        replace=lambda chars,\n",
    "                        data_dict: chars.encode('ascii', 'namereplace').decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emojiMask(sentence):\n",
    "    emoji_mask_sentence = emoji.replace_emoji(sentence,\n",
    "                        replace=lambda chars,\n",
    "                        data_dict: chars.encode('ascii', 'namereplace').decode())\n",
    "    emoji_mask_sentence = re.sub(r\"\\\\N\\{(.+?)\\}\", r\"\\1\", emoji_mask_sentence)\n",
    "    return emoji_mask_sentence\n",
    "\n",
    "\n",
    "x_train_emojimask = [emojiMask(str(row)) for row in list_x_train]\n",
    "x_test_emojimask = [emojiMask(str(row)) for row in list_x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSentence(sentence, stopwords=True):\n",
    "    stopwords_vocabulary = nltk.corpus.stopwords.words('english')\n",
    "    stopwords_pattern = r'\\b(?:' + '\\s*|'.join(map(re.escape, stopwords_vocabulary)) + r')\\b' if stopwords else ''\n",
    "    # clean_sentence = re.sub(stopwords_pattern + r'|[^\\w\\s]', '', sentence)\n",
    "    lower_sentence = sentence.lower()\n",
    "    clean_sentence = re.sub(stopwords_pattern + r'|[^\\w\\s]', '', lower_sentence)\n",
    "    return clean_sentence\n",
    "\n",
    "\n",
    "x_train_clean = [cleanSentence(row) for row in x_train_emojimask]\n",
    "x_test_clean = [cleanSentence(row) for row in x_test_emojimask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "encoded_x_train = list(map(lambda x: tokenizer.encode(x), x_train_clean))\n",
    "encoded_x_test = list(map(lambda x: tokenizer.encode(x), x_test_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum length of sequences\n",
    "max_train_length = max(len(seq) for seq in encoded_x_train)\n",
    "max_test_length = max(len(seq) for seq in encoded_x_test)\n",
    "max_length = max(max_test_length,max_train_length)\n",
    "\n",
    "\n",
    "# Pad sequences to ensure they all have the same length\n",
    "padded_encoded_x_train = np.array([seq + [0]*(max_length - len(seq)) for seq in encoded_x_train])\n",
    "padded_encoded_x_test = np.array([seq + [0]*(max_length - len(seq)) for seq in encoded_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "dataset['train_input'] = torch.from_numpy(padded_encoded_x_train)\n",
    "dataset['test_input'] = torch.from_numpy(padded_encoded_x_test)\n",
    "dataset['train_label'] = torch.from_numpy(np.array(y_train))\n",
    "dataset['test_label'] = torch.from_numpy(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAN_model = KAN(width=[max_length,2], grid=3, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(KAN_model(dataset['train_input']), dim=1) == dataset['train_label']).float())\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(KAN_model(dataset['test_input']), dim=1) == dataset['test_label']).float())\n",
    "\n",
    "results = KAN_model.train(dataset, opt=\"LBFGS\", steps=20, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./media/models/result_kan1.obj', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./media/models/result_kan1.obj', 'rb') as fr:\n",
    "    loaded_result = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAN.load_ckpt(KAN_model, name='KAN_model', folder='./media/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.argmax(KAN_model(dataset['train_input']), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(example.numpy() == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAN_model(dataset['train_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./media/datasets/MMcomments/comments.json') as json_file:\n",
    "    comment_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "comment_list = comment_dict['comments']\n",
    "comment_list[0].items()\n",
    "\n",
    "threshold = 0.5  \n",
    "\n",
    "filter_comment_list = []\n",
    "for _ in range(len(comment_list)):\n",
    "    for sentence, sentiment in comment_list[_].items():\n",
    "        sentence_emojiMask = emojiMask(sentence)\n",
    "        clean_sentence = str(cleanSentence(sentence_emojiMask))\n",
    "        filter_comment_list.append(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tokens_comments = list(map(lambda x: tokenizer.encode(x), filter_comment_list))\n",
    "\n",
    "# Determine the maximum length of sequences\n",
    "filter_comment_dict = {}\n",
    "max_comments_length = max(len(seq) for seq in filter_tokens_comments)\n",
    "padded_encoded_filter_tokens = np.array([seq + [0]*(max_comments_length - len(seq)) for seq in filter_tokens_comments])\n",
    "filter_comment_dict['comments'] = torch.from_numpy(padded_encoded_filter_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[286, 400]' is invalid for input of size 20020",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mKAN_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_comment_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda3/envs/pykan-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda3/envs/pykan-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/miniconda3/envs/pykan-env/lib/python3.9/site-packages/kan/KAN.py:311\u001b[0m, in \u001b[0;36mKAN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m--> 311\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m         x_symbolic, postacts_symbolic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_fun[l](x)\n",
      "File \u001b[0;32m/data/miniconda3/envs/pykan-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda3/envs/pykan-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/miniconda3/envs/pykan-env/lib/python3.9/site-packages/kan/KANLayer.py:170\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    168\u001b[0m batch \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# x: shape (batch, in_dim) => shape (size, batch) (size = out_dim * in_dim)\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij,k->ikj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    171\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[1;32m    172\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch, size)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[286, 400]' is invalid for input of size 20020"
     ]
    }
   ],
   "source": [
    "KAN_model(filter_comment_dict['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_KAN_model = KAN(width=[max_length,2], k=3, noise_scale=0.1, bias_trainable=False, sp_trainable=False, sb_trainable=False)\n",
    "\n",
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(CL_KAN_model(dataset['train_input']), dim=1) == dataset['train_label']).float())\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(CL_KAN_model(dataset['test_input']), dim=1) == dataset['test_label']).float())\n",
    "\n",
    "CL_results = CL_KAN_model.train(dataset, opt=\"LBFGS\", steps=20, update_grid=False, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
