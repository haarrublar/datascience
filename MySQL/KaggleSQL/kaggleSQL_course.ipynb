{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Google bigquery is a fully manage, serverless data warehouse by Google Cloud. It is used for managing large-scale data using SQL queries.\n",
    "\"\"\"\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package google.cloud.bigquery in google.cloud:\n",
      "\n",
      "NAME\n",
      "    google.cloud.bigquery - Google BigQuery API wrapper.\n",
      "\n",
      "DESCRIPTION\n",
      "    The main concepts with this API are:\n",
      "\n",
      "    - :class:`~google.cloud.bigquery.client.Client` manages connections to the\n",
      "      BigQuery API. Use the client methods to run jobs (such as a\n",
      "      :class:`~google.cloud.bigquery.job.QueryJob` via\n",
      "      :meth:`~google.cloud.bigquery.client.Client.query`) and manage resources.\n",
      "\n",
      "    - :class:`~google.cloud.bigquery.dataset.Dataset` represents a\n",
      "      collection of tables.\n",
      "\n",
      "    - :class:`~google.cloud.bigquery.table.Table` represents a single \"relation\".\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _helpers\n",
      "    _http\n",
      "    _job_helpers\n",
      "    _pandas_helpers\n",
      "    _pyarrow_helpers\n",
      "    _tqdm_helpers\n",
      "    _versions_helpers\n",
      "    client\n",
      "    dataset\n",
      "    dbapi (package)\n",
      "    encryption_configuration\n",
      "    enums\n",
      "    exceptions\n",
      "    external_config\n",
      "    format_options\n",
      "    iam\n",
      "    job (package)\n",
      "    magics (package)\n",
      "    model\n",
      "    opentelemetry_tracing\n",
      "    query\n",
      "    retry\n",
      "    routine (package)\n",
      "    schema\n",
      "    standard_sql\n",
      "    table\n",
      "    version\n",
      "\n",
      "SUBMODULES\n",
      "    bigquery_version\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        google.cloud.bigquery.dataset.AccessEntry\n",
      "        google.cloud.bigquery.dataset.Dataset\n",
      "        google.cloud.bigquery.dataset.DatasetReference\n",
      "        google.cloud.bigquery.encryption_configuration.EncryptionConfiguration\n",
      "        google.cloud.bigquery.enums.Compression\n",
      "        google.cloud.bigquery.enums.CreateDisposition\n",
      "        google.cloud.bigquery.enums.DecimalTargetType\n",
      "        google.cloud.bigquery.enums.DestinationFormat\n",
      "        google.cloud.bigquery.enums.DeterminismLevel\n",
      "        google.cloud.bigquery.enums.Encoding\n",
      "        google.cloud.bigquery.enums.KeyResultStatementKind\n",
      "        google.cloud.bigquery.enums.QueryPriority\n",
      "        google.cloud.bigquery.enums.SchemaUpdateOption\n",
      "        google.cloud.bigquery.enums.SourceFormat\n",
      "        google.cloud.bigquery.enums.WriteDisposition\n",
      "        google.cloud.bigquery.external_config.BigtableColumn\n",
      "        google.cloud.bigquery.external_config.BigtableColumnFamily\n",
      "        google.cloud.bigquery.external_config.BigtableOptions\n",
      "        google.cloud.bigquery.external_config.CSVOptions\n",
      "        google.cloud.bigquery.external_config.ExternalConfig\n",
      "        google.cloud.bigquery.external_config.ExternalSourceFormat\n",
      "        google.cloud.bigquery.external_config.GoogleSheetsOptions\n",
      "        google.cloud.bigquery.external_config.HivePartitioningOptions\n",
      "        google.cloud.bigquery.format_options.AvroOptions\n",
      "        google.cloud.bigquery.format_options.ParquetOptions\n",
      "        google.cloud.bigquery.job.base.SessionInfo\n",
      "        google.cloud.bigquery.job.copy_.OperationType\n",
      "        google.cloud.bigquery.job.query.ScriptOptions\n",
      "        google.cloud.bigquery.model.Model\n",
      "        google.cloud.bigquery.model.ModelReference\n",
      "        google.cloud.bigquery.query.ConnectionProperty\n",
      "        google.cloud.bigquery.query.SqlParameterScalarTypes\n",
      "        google.cloud.bigquery.query.UDFResource\n",
      "        google.cloud.bigquery.routine.routine.RemoteFunctionOptions\n",
      "        google.cloud.bigquery.routine.routine.Routine\n",
      "        google.cloud.bigquery.routine.routine.RoutineArgument\n",
      "        google.cloud.bigquery.routine.routine.RoutineReference\n",
      "        google.cloud.bigquery.routine.routine.RoutineType\n",
      "        google.cloud.bigquery.schema.FieldElementType\n",
      "        google.cloud.bigquery.schema.PolicyTagList\n",
      "        google.cloud.bigquery.schema.SchemaField\n",
      "        google.cloud.bigquery.standard_sql.StandardSqlDataType\n",
      "        google.cloud.bigquery.standard_sql.StandardSqlField\n",
      "        google.cloud.bigquery.standard_sql.StandardSqlStructType\n",
      "        google.cloud.bigquery.standard_sql.StandardSqlTableType\n",
      "        google.cloud.bigquery.table.CloneDefinition\n",
      "        google.cloud.bigquery.table.PartitionRange\n",
      "        google.cloud.bigquery.table.RangePartitioning\n",
      "        google.cloud.bigquery.table.Row\n",
      "        google.cloud.bigquery.table.SnapshotDefinition\n",
      "        google.cloud.bigquery.table.TimePartitioning\n",
      "        google.cloud.bigquery.table.TimePartitioningType\n",
      "    builtins.str(builtins.object)\n",
      "        google.cloud.bigquery.enums.SqlTypeNames(builtins.str, enum.Enum)\n",
      "        google.cloud.bigquery.enums.StandardSqlTypeNames(builtins.str, enum.Enum)\n",
      "    builtins.tuple(builtins.object)\n",
      "        google.cloud.bigquery.job.base.TransactionInfo\n",
      "        google.cloud.bigquery.job.query.DmlStats\n",
      "    enum.Enum(builtins.object)\n",
      "        google.cloud.bigquery.enums.AutoRowIDs\n",
      "        google.cloud.bigquery.enums.SqlTypeNames(builtins.str, enum.Enum)\n",
      "        google.cloud.bigquery.enums.StandardSqlTypeNames(builtins.str, enum.Enum)\n",
      "    google.cloud.bigquery.exceptions.BigQueryError(builtins.Exception)\n",
      "        google.cloud.bigquery.exceptions.LegacyBigQueryStorageError\n",
      "        google.cloud.bigquery.exceptions.LegacyPyarrowError\n",
      "    google.cloud.bigquery.job.base._AsyncJob(google.api_core.future.polling.PollingFuture)\n",
      "        google.cloud.bigquery.job.base.UnknownJob\n",
      "        google.cloud.bigquery.job.copy_.CopyJob\n",
      "        google.cloud.bigquery.job.extract.ExtractJob\n",
      "        google.cloud.bigquery.job.load.LoadJob\n",
      "        google.cloud.bigquery.job.query.QueryJob\n",
      "    google.cloud.bigquery.job.base._JobConfig(builtins.object)\n",
      "        google.cloud.bigquery.job.copy_.CopyJobConfig\n",
      "        google.cloud.bigquery.job.extract.ExtractJobConfig\n",
      "        google.cloud.bigquery.job.load.LoadJobConfig\n",
      "        google.cloud.bigquery.job.query.QueryJobConfig\n",
      "    google.cloud.bigquery.query._AbstractQueryParameter(builtins.object)\n",
      "        google.cloud.bigquery.query.ArrayQueryParameter\n",
      "        google.cloud.bigquery.query.RangeQueryParameter\n",
      "        google.cloud.bigquery.query.ScalarQueryParameter\n",
      "        google.cloud.bigquery.query.StructQueryParameter\n",
      "    google.cloud.bigquery.query._AbstractQueryParameterType(builtins.object)\n",
      "        google.cloud.bigquery.query.ArrayQueryParameterType\n",
      "        google.cloud.bigquery.query.RangeQueryParameterType\n",
      "        google.cloud.bigquery.query.ScalarQueryParameterType\n",
      "        google.cloud.bigquery.query.StructQueryParameterType\n",
      "    google.cloud.bigquery.table._TableBase(builtins.object)\n",
      "        google.cloud.bigquery.table.Table\n",
      "        google.cloud.bigquery.table.TableReference\n",
      "    google.cloud.client.ClientWithProject(google.cloud.client.Client, google.cloud.client._ClientProjectMixin)\n",
      "        google.cloud.bigquery.client.Client\n",
      "\n",
      "    class AccessEntry(builtins.object)\n",
      "     |  AccessEntry(role: Optional[str] = None, entity_type: Optional[str] = None, entity_id: Union[Dict[str, Any], str, NoneType] = None)\n",
      "     |\n",
      "     |  Represents grant of an access role to an entity.\n",
      "     |\n",
      "     |  An entry must have exactly one of the allowed\n",
      "     |  :class:`google.cloud.bigquery.enums.EntityTypes`. If anything but ``view``, ``routine``,\n",
      "     |  or ``dataset`` are set, a ``role`` is also required. ``role`` is omitted for ``view``,\n",
      "     |  ``routine``, ``dataset``, because they are always read-only.\n",
      "     |\n",
      "     |  See https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      role:\n",
      "     |          Role granted to the entity. The following string values are\n",
      "     |          supported: `'READER'`, `'WRITER'`, `'OWNER'`. It may also be\n",
      "     |          :data:`None` if the ``entity_type`` is ``view``, ``routine``, or ``dataset``.\n",
      "     |\n",
      "     |      entity_type:\n",
      "     |          Type of entity being granted the role. See\n",
      "     |          :class:`google.cloud.bigquery.enums.EntityTypes` for supported types.\n",
      "     |\n",
      "     |      entity_id:\n",
      "     |          If the ``entity_type`` is not 'view', 'routine', or 'dataset', the\n",
      "     |          ``entity_id`` is the ``str`` ID of the entity being granted the role. If\n",
      "     |          the ``entity_type`` is 'view' or 'routine', the ``entity_id`` is a ``dict``\n",
      "     |          representing the view or routine from a different dataset to grant access\n",
      "     |          to in the following format for views::\n",
      "     |\n",
      "     |              {\n",
      "     |                  'projectId': string,\n",
      "     |                  'datasetId': string,\n",
      "     |                  'tableId': string\n",
      "     |              }\n",
      "     |\n",
      "     |          For routines::\n",
      "     |\n",
      "     |              {\n",
      "     |                  'projectId': string,\n",
      "     |                  'datasetId': string,\n",
      "     |                  'routineId': string\n",
      "     |              }\n",
      "     |\n",
      "     |          If the ``entity_type`` is 'dataset', the ``entity_id`` is a ``dict`` that includes\n",
      "     |          a 'dataset' field with a ``dict`` representing the dataset and a 'target_types'\n",
      "     |          field with a ``str`` value of the dataset's resource type::\n",
      "     |\n",
      "     |              {\n",
      "     |                  'dataset': {\n",
      "     |                      'projectId': string,\n",
      "     |                      'datasetId': string,\n",
      "     |                  },\n",
      "     |                  'target_types: 'VIEWS'\n",
      "     |              }\n",
      "     |\n",
      "     |  Raises:\n",
      "     |      ValueError:\n",
      "     |          If a ``view``, ``routine``, or ``dataset`` has ``role`` set, or a non ``view``,\n",
      "     |          non ``routine``, and non ``dataset`` **does not** have a ``role`` set.\n",
      "     |\n",
      "     |  Examples:\n",
      "     |      >>> entry = AccessEntry('OWNER', 'userByEmail', 'user@example.com')\n",
      "     |\n",
      "     |      >>> view = {\n",
      "     |      ...     'projectId': 'my-project',\n",
      "     |      ...     'datasetId': 'my_dataset',\n",
      "     |      ...     'tableId': 'my_table'\n",
      "     |      ... }\n",
      "     |      >>> entry = AccessEntry(None, 'view', view)\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self, role: Optional[str] = None, entity_type: Optional[str] = None, entity_id: Union[Dict[str, Any], str, NoneType] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Construct the API resource representation of this access entry\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Access entry represented as an API resource\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'AccessEntry' from builtins.type\n",
      "     |      Factory: construct an access entry given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]):\n",
      "     |              Access entry resource representation returned from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.AccessEntry:\n",
      "     |              Access entry parsed from ``resource``.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the resource has more keys than ``role`` and one additional\n",
      "     |              key.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  entity_id\n",
      "     |      The entity_id of the entry.\n",
      "     |\n",
      "     |  entity_type\n",
      "     |      The entity_type of the entry.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  dataset\n",
      "     |      API resource representation of a dataset reference.\n",
      "     |\n",
      "     |  dataset_target_types\n",
      "     |      Which resources that the dataset in this entry applies to.\n",
      "     |\n",
      "     |  domain\n",
      "     |      A domain to grant access to.\n",
      "     |\n",
      "     |  group_by_email\n",
      "     |      An email address of a Google Group to grant access to.\n",
      "     |\n",
      "     |  role\n",
      "     |      The role of the entry.\n",
      "     |\n",
      "     |  routine\n",
      "     |      API resource representation of a routine reference.\n",
      "     |\n",
      "     |  special_group\n",
      "     |      A special group to grant access to.\n",
      "     |\n",
      "     |  user_by_email\n",
      "     |      An email address of a user to grant access to.\n",
      "     |\n",
      "     |  view\n",
      "     |      API resource representation of a view reference.\n",
      "\n",
      "    class ArrayQueryParameter(_AbstractQueryParameter)\n",
      "     |  ArrayQueryParameter(name, array_type, values) -> None\n",
      "     |\n",
      "     |  Named / positional query parameters for array values.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      name (Optional[str]):\n",
      "     |          Parameter name, used via ``@foo`` syntax.  If None, the\n",
      "     |          parameter can only be addressed via position (``?``).\n",
      "     |\n",
      "     |      array_type (Union[str, ScalarQueryParameterType, StructQueryParameterType]):\n",
      "     |          The type of array elements. If given as a string, it must be one of\n",
      "     |          `'STRING'`, `'INT64'`, `'FLOAT64'`, `'NUMERIC'`, `'BIGNUMERIC'`, `'BOOL'`,\n",
      "     |          `'TIMESTAMP'`, `'DATE'`, or `'STRUCT'`/`'RECORD'`.\n",
      "     |          If the type is ``'STRUCT'``/``'RECORD'`` and ``values`` is empty,\n",
      "     |          the exact item type cannot be deduced, thus a ``StructQueryParameterType``\n",
      "     |          instance needs to be passed in.\n",
      "     |\n",
      "     |      values (List[appropriate type]): The parameter array values.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ArrayQueryParameter\n",
      "     |      _AbstractQueryParameter\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, name, array_type, values) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct JSON API representation for the parameter.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'ArrayQueryParameter' from builtins.type\n",
      "     |      Factory: construct parameter from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ArrayQueryParameter: Instance\n",
      "     |\n",
      "     |  positional(array_type: str, values: list) -> 'ArrayQueryParameter' from builtins.type\n",
      "     |      Factory for positional parameters.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          array_type (Union[str, ScalarQueryParameterType, StructQueryParameterType]):\n",
      "     |              The type of array elements. If given as a string, it must be one of\n",
      "     |              `'STRING'`, `'INT64'`, `'FLOAT64'`, `'NUMERIC'`, `'BIGNUMERIC'`,\n",
      "     |              `'BOOL'`, `'TIMESTAMP'`, `'DATE'`, or `'STRUCT'`/`'RECORD'`.\n",
      "     |              If the type is ``'STRUCT'``/``'RECORD'`` and ``values`` is empty,\n",
      "     |              the exact item type cannot be deduced, thus a ``StructQueryParameterType``\n",
      "     |              instance needs to be passed in.\n",
      "     |\n",
      "     |          values (List[appropriate type]): The parameter array values.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ArrayQueryParameter: Instance without name\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameter:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class ArrayQueryParameterType(_AbstractQueryParameterType)\n",
      "     |  ArrayQueryParameterType(array_type, *, name=None, description=None)\n",
      "     |\n",
      "     |  Type representation for array query parameters.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      array_type (Union[ScalarQueryParameterType, StructQueryParameterType]):\n",
      "     |          The type of array elements.\n",
      "     |      name (Optional[str]):\n",
      "     |          The name of the query parameter. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |      description (Optional[str]):\n",
      "     |          The query parameter description. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ArrayQueryParameterType\n",
      "     |      _AbstractQueryParameterType\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, array_type, *, name=None, description=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Construct JSON API representation for the parameter type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource) from builtins.type\n",
      "     |      Factory: construct parameter type from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ArrayQueryParameterType: Instance\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameterType:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class AutoRowIDs(enum.Enum)\n",
      "     |  AutoRowIDs(*values)\n",
      "     |\n",
      "     |  How to handle automatic insert IDs when inserting rows as a stream.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      AutoRowIDs\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  DISABLED = <AutoRowIDs.DISABLED: 1>\n",
      "     |\n",
      "     |  GENERATE_UUID = <AutoRowIDs.GENERATE_UUID: 2>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |\n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |\n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.EnumType:\n",
      "     |\n",
      "     |  __contains__(value) from enum.EnumType\n",
      "     |      Return True if `value` is in `cls`.\n",
      "     |\n",
      "     |      `value` is in `cls` if:\n",
      "     |      1) `value` is a member of `cls`, or\n",
      "     |      2) `value` is the value of one of the `cls`'s members.\n",
      "     |\n",
      "     |  __getitem__(name) from enum.EnumType\n",
      "     |      Return the member matching `name`.\n",
      "     |\n",
      "     |  __iter__() from enum.EnumType\n",
      "     |      Return members in definition order.\n",
      "     |\n",
      "     |  __len__() from enum.EnumType\n",
      "     |      Return the number of members (no aliases)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |\n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |\n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "\n",
      "    class AvroOptions(builtins.object)\n",
      "     |  Options if source format is set to AVRO.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, bool]:\n",
      "     |              A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, bool]) -> 'AvroOptions' from builtins.type\n",
      "     |      Factory: construct an instance from a resource dict.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, bool]):\n",
      "     |              Definition of a :class:`~.format_options.AvroOptions` instance in\n",
      "     |              the same representation as is returned from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          :class:`~.format_options.AvroOptions`:\n",
      "     |              Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  use_avro_logical_types\n",
      "     |      [Optional] If sourceFormat is set to 'AVRO', indicates whether to\n",
      "     |      interpret logical types as the corresponding BigQuery data type (for\n",
      "     |      example, TIMESTAMP), instead of using the raw type (for example,\n",
      "     |      INTEGER).\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#AvroOptions.FIELDS.use_avro_logical_types\n",
      "\n",
      "    class BigtableColumn(builtins.object)\n",
      "     |  Options for a Bigtable column.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]:\n",
      "     |              A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'BigtableColumn' from builtins.type\n",
      "     |      Factory: construct a :class:`~.external_config.BigtableColumn`\n",
      "     |      instance given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of a :class:`~.external_config.BigtableColumn`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          external_config.BigtableColumn: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  encoding\n",
      "     |      str: The encoding of the values when the type is not `STRING`\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumn.FIELDS.encoding\n",
      "     |\n",
      "     |  field_name\n",
      "     |      str: An identifier to use if the qualifier is not a valid BigQuery\n",
      "     |      field identifier\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumn.FIELDS.field_name\n",
      "     |\n",
      "     |  only_read_latest\n",
      "     |      bool: If this is set, only the latest version of value in this\n",
      "     |      column are exposed.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumn.FIELDS.only_read_latest\n",
      "     |\n",
      "     |  qualifier_encoded\n",
      "     |      Union[str, bytes]: The qualifier encoded in binary.\n",
      "     |\n",
      "     |      The type is ``str`` (Python 2.x) or ``bytes`` (Python 3.x). The module\n",
      "     |      will handle base64 encoding for you.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumn.FIELDS.qualifier_encoded\n",
      "     |\n",
      "     |  qualifier_string\n",
      "     |      str: A valid UTF-8 string qualifier\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumn.FIELDS.qualifier_string\n",
      "     |\n",
      "     |  type_\n",
      "     |      str: The type to convert the value in cells of this column.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumn.FIELDS.type\n",
      "\n",
      "    class BigtableColumnFamily(builtins.object)\n",
      "     |  Options for a Bigtable column family.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]:\n",
      "     |              A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'BigtableColumnFamily' from builtins.type\n",
      "     |      Factory: construct a :class:`~.external_config.BigtableColumnFamily`\n",
      "     |      instance given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of a :class:`~.external_config.BigtableColumnFamily`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          :class:`~.external_config.BigtableColumnFamily`:\n",
      "     |              Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  columns\n",
      "     |      List[BigtableColumn]: Lists of columns\n",
      "     |      that should be exposed as individual fields.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumnFamily.FIELDS.columns\n",
      "     |\n",
      "     |  encoding\n",
      "     |      str: The encoding of the values when the type is not `STRING`\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumnFamily.FIELDS.encoding\n",
      "     |\n",
      "     |  family_id\n",
      "     |      str: Identifier of the column family.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumnFamily.FIELDS.family_id\n",
      "     |\n",
      "     |  only_read_latest\n",
      "     |      bool: If this is set only the latest version of value are exposed\n",
      "     |      for all columns in this column family.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumnFamily.FIELDS.only_read_latest\n",
      "     |\n",
      "     |  type_\n",
      "     |      str: The type to convert the value in cells of this column family.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableColumnFamily.FIELDS.type\n",
      "\n",
      "    class BigtableOptions(builtins.object)\n",
      "     |  Options that describe how to treat Bigtable tables as BigQuery tables.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]:\n",
      "     |              A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'BigtableOptions' from builtins.type\n",
      "     |      Factory: construct a :class:`~.external_config.BigtableOptions`\n",
      "     |      instance given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of a :class:`~.external_config.BigtableOptions`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          BigtableOptions: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  column_families\n",
      "     |      List[:class:`~.external_config.BigtableColumnFamily`]: List of\n",
      "     |      column families to expose in the table schema along with their types.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableOptions.FIELDS.column_families\n",
      "     |\n",
      "     |  ignore_unspecified_column_families\n",
      "     |      bool: If :data:`True`, ignore columns not specified in\n",
      "     |      :attr:`column_families` list. Defaults to :data:`False`.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableOptions.FIELDS.ignore_unspecified_column_families\n",
      "     |\n",
      "     |  read_rowkey_as_string\n",
      "     |      bool: If :data:`True`, rowkey column families will be read and\n",
      "     |      converted to string. Defaults to :data:`False`.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#BigtableOptions.FIELDS.read_rowkey_as_string\n",
      "\n",
      "    class CSVOptions(builtins.object)\n",
      "     |  Options that describe how to treat CSV files as BigQuery tables.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'CSVOptions' from builtins.type\n",
      "     |      Factory: construct a :class:`~.external_config.CSVOptions` instance\n",
      "     |      given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of a :class:`~.external_config.CSVOptions`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          CSVOptions: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  allow_jagged_rows\n",
      "     |      bool: If :data:`True`, BigQuery treats missing trailing columns as\n",
      "     |      null values. Defaults to :data:`False`.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.allow_jagged_rows\n",
      "     |\n",
      "     |  allow_quoted_newlines\n",
      "     |      bool: If :data:`True`, quoted data sections that contain newline\n",
      "     |      characters in a CSV file are allowed. Defaults to :data:`False`.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.allow_quoted_newlines\n",
      "     |\n",
      "     |  encoding\n",
      "     |      str: The character encoding of the data.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.encoding\n",
      "     |\n",
      "     |  field_delimiter\n",
      "     |      str: The separator for fields in a CSV file. Defaults to comma (',').\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.field_delimiter\n",
      "     |\n",
      "     |  preserve_ascii_control_characters\n",
      "     |      bool: Indicates if the embedded ASCII control characters\n",
      "     |      (the first 32 characters in the ASCII-table, from '\u0000' to '\u001f') are preserved.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.preserve_ascii_control_characters\n",
      "     |\n",
      "     |  quote_character\n",
      "     |      str: The value that is used to quote data sections in a CSV file.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.quote\n",
      "     |\n",
      "     |  skip_leading_rows\n",
      "     |      int: The number of rows at the top of a CSV file.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#CsvOptions.FIELDS.skip_leading_rows\n",
      "\n",
      "    class Client(google.cloud.client.ClientWithProject)\n",
      "     |  Client(project=None, credentials=None, _http=None, location=None, default_query_job_config=None, default_load_job_config=None, client_info=None, client_options=None) -> None\n",
      "     |\n",
      "     |  Client to bundle configuration needed for API requests.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      project (Optional[str]):\n",
      "     |          Project ID for the project which the client acts on behalf of.\n",
      "     |          Will be passed when creating a dataset / job. If not passed,\n",
      "     |          falls back to the default inferred from the environment.\n",
      "     |      credentials (Optional[google.auth.credentials.Credentials]):\n",
      "     |          The OAuth2 Credentials to use for this client. If not passed\n",
      "     |          (and if no ``_http`` object is passed), falls back to the\n",
      "     |          default inferred from the environment.\n",
      "     |      _http (Optional[requests.Session]):\n",
      "     |          HTTP object to make requests. Can be any object that\n",
      "     |          defines ``request()`` with the same interface as\n",
      "     |          :meth:`requests.Session.request`. If not passed, an ``_http``\n",
      "     |          object is created that is bound to the ``credentials`` for the\n",
      "     |          current object.\n",
      "     |          This parameter should be considered private, and could change in\n",
      "     |          the future.\n",
      "     |      location (Optional[str]):\n",
      "     |          Default location for jobs / datasets / tables.\n",
      "     |      default_query_job_config (Optional[google.cloud.bigquery.job.QueryJobConfig]):\n",
      "     |          Default ``QueryJobConfig``.\n",
      "     |          Will be merged into job configs passed into the ``query`` method.\n",
      "     |      default_load_job_config (Optional[google.cloud.bigquery.job.LoadJobConfig]):\n",
      "     |          Default ``LoadJobConfig``.\n",
      "     |          Will be merged into job configs passed into the ``load_table_*`` methods.\n",
      "     |      client_info (Optional[google.api_core.client_info.ClientInfo]):\n",
      "     |          The client info used to send a user-agent string along with API\n",
      "     |          requests. If ``None``, then default info will be used. Generally,\n",
      "     |          you only need to set this if you're developing your own library\n",
      "     |          or partner tool.\n",
      "     |      client_options (Optional[Union[google.api_core.client_options.ClientOptions, Dict]]):\n",
      "     |          Client options used to set user options on the client. API Endpoint\n",
      "     |          should be set through client_options.\n",
      "     |\n",
      "     |  Raises:\n",
      "     |      google.auth.exceptions.DefaultCredentialsError:\n",
      "     |          Raised if ``credentials`` is not specified and the library fails\n",
      "     |          to acquire default credentials.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Client\n",
      "     |      google.cloud.client.ClientWithProject\n",
      "     |      google.cloud.client.Client\n",
      "     |      google.cloud.client._ClientFactoryMixin\n",
      "     |      google.cloud.client._ClientProjectMixin\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __enter__(self)\n",
      "     |\n",
      "     |  __exit__(self, exc_type, exc_value, traceback)\n",
      "     |\n",
      "     |  __init__(self, project=None, credentials=None, _http=None, location=None, default_query_job_config=None, default_load_job_config=None, client_info=None, client_options=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  cancel_job(self, job_id: str, project: Optional[str] = None, location: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> Union[google.cloud.bigquery.job.load.LoadJob, google.cloud.bigquery.job.copy_.CopyJob, google.cloud.bigquery.job.extract.ExtractJob, google.cloud.bigquery.job.query.QueryJob]\n",
      "     |      Attempt to cancel a job from a job ID.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel\n",
      "     |\n",
      "     |      Args:\n",
      "     |          job_id (Union[                 str,                 google.cloud.bigquery.job.LoadJob,                 google.cloud.bigquery.job.CopyJob,                 google.cloud.bigquery.job.ExtractJob,                 google.cloud.bigquery.job.QueryJob             ]): Job identifier.\n",
      "     |          project (Optional[str]):\n",
      "     |              ID of the project which owns the job (defaults to the client's project).\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where the job was run. Ignored if ``job_id`` is a job\n",
      "     |              object.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Union[                 google.cloud.bigquery.job.LoadJob,                 google.cloud.bigquery.job.CopyJob,                 google.cloud.bigquery.job.ExtractJob,                 google.cloud.bigquery.job.QueryJob,             ]:\n",
      "     |              Job instance, based on the resource returned by the API.\n",
      "     |\n",
      "     |  close(self)\n",
      "     |      Close the underlying transport objects, releasing system resources.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |          The client instance can be used for making additional requests even\n",
      "     |          after closing, in which case the underlying connections are\n",
      "     |          automatically re-created.\n",
      "     |\n",
      "     |  copy_table(self, sources: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str, Sequence[Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str]]], destination: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, job_config: Optional[google.cloud.bigquery.job.copy_.CopyJobConfig] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.job.copy_.CopyJob\n",
      "     |      Copy one or more tables to another table.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#jobconfigurationtablecopy\n",
      "     |\n",
      "     |      Args:\n",
      "     |          sources (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,                 Sequence[                     Union[                         google.cloud.bigquery.table.Table,                         google.cloud.bigquery.table.TableReference,                         google.cloud.bigquery.table.TableListItem,                         str,                     ]                 ],             ]):\n",
      "     |              Table or tables to be copied.\n",
      "     |          destination (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,             ]):\n",
      "     |              Table into which data is to be copied.\n",
      "     |          job_id (Optional[str]): The ID of the job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The user-provided prefix for a randomly generated job ID.\n",
      "     |              This parameter will be ignored if a ``job_id`` is also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of any\n",
      "     |              source table as well as the destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          job_config (Optional[google.cloud.bigquery.job.CopyJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.CopyJob: A new copy job instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of :class:`~google.cloud.bigquery.job.CopyJobConfig`\n",
      "     |              class.\n",
      "     |\n",
      "     |  create_dataset(self, dataset: Union[str, google.cloud.bigquery.dataset.Dataset, google.cloud.bigquery.dataset.DatasetReference, google.cloud.bigquery.dataset.DatasetListItem], exists_ok: bool = False, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.dataset.Dataset\n",
      "     |      API call: create the dataset via a POST request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset (Union[                 google.cloud.bigquery.dataset.Dataset,                 google.cloud.bigquery.dataset.DatasetReference,                 google.cloud.bigquery.dataset.DatasetListItem,                 str,             ]):\n",
      "     |              A :class:`~google.cloud.bigquery.dataset.Dataset` to create.\n",
      "     |              If ``dataset`` is a reference, an empty dataset is created\n",
      "     |              with the specified ID and client's default location.\n",
      "     |          exists_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"already exists\"\n",
      "     |              errors when creating the dataset.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.Dataset:\n",
      "     |              A new ``Dataset`` returned from the API.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.Conflict:\n",
      "     |              If the dataset already exists.\n",
      "     |\n",
      "     |      Example:\n",
      "     |\n",
      "     |          >>> from google.cloud import bigquery\n",
      "     |          >>> client = bigquery.Client()\n",
      "     |          >>> dataset = bigquery.Dataset('my_project.my_dataset')\n",
      "     |          >>> dataset = client.create_dataset(dataset)\n",
      "     |\n",
      "     |  create_job(self, job_config: dict, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> Union[google.cloud.bigquery.job.load.LoadJob, google.cloud.bigquery.job.copy_.CopyJob, google.cloud.bigquery.job.extract.ExtractJob, google.cloud.bigquery.job.query.QueryJob]\n",
      "     |      Create a new job.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          job_config (dict): configuration job representation returned from the API.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Union[                 google.cloud.bigquery.job.LoadJob,                 google.cloud.bigquery.job.CopyJob,                 google.cloud.bigquery.job.ExtractJob,                 google.cloud.bigquery.job.QueryJob             ]:\n",
      "     |              A new job instance.\n",
      "     |\n",
      "     |  create_routine(self, routine: google.cloud.bigquery.routine.routine.Routine, exists_ok: bool = False, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.routine.routine.Routine\n",
      "     |      [Beta] Create a routine via a POST request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/insert\n",
      "     |\n",
      "     |      Args:\n",
      "     |          routine (google.cloud.bigquery.routine.Routine):\n",
      "     |              A :class:`~google.cloud.bigquery.routine.Routine` to create.\n",
      "     |              The dataset that the routine belongs to must already exist.\n",
      "     |          exists_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"already exists\"\n",
      "     |              errors when creating the routine.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.Routine:\n",
      "     |              A new ``Routine`` returned from the service.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.Conflict:\n",
      "     |              If the routine already exists.\n",
      "     |\n",
      "     |  create_table(self, table: Union[str, google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem], exists_ok: bool = False, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.table.Table\n",
      "     |      API call:  create a table via a PUT request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,             ]):\n",
      "     |              A :class:`~google.cloud.bigquery.table.Table` to create.\n",
      "     |              If ``table`` is a reference, an empty table is created\n",
      "     |              with the specified ID. The dataset that the table belongs to\n",
      "     |              must already exist.\n",
      "     |          exists_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"already exists\"\n",
      "     |              errors when creating the table.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.Table:\n",
      "     |              A new ``Table`` returned from the service.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.Conflict:\n",
      "     |              If the table already exists.\n",
      "     |\n",
      "     |  dataset(self, dataset_id: str, project: Optional[str] = None) -> google.cloud.bigquery.dataset.DatasetReference\n",
      "     |      Deprecated: Construct a reference to a dataset.\n",
      "     |\n",
      "     |      .. deprecated:: 1.24.0\n",
      "     |         Construct a\n",
      "     |         :class:`~google.cloud.bigquery.dataset.DatasetReference` using its\n",
      "     |         constructor or use a string where previously a reference object\n",
      "     |         was used.\n",
      "     |\n",
      "     |         As of ``google-cloud-bigquery`` version 1.7.0, all client methods\n",
      "     |         that take a\n",
      "     |         :class:`~google.cloud.bigquery.dataset.DatasetReference` or\n",
      "     |         :class:`~google.cloud.bigquery.table.TableReference` also take a\n",
      "     |         string in standard SQL format, e.g. ``project.dataset_id`` or\n",
      "     |         ``project.dataset_id.table_id``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset_id (str): ID of the dataset.\n",
      "     |\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID for the dataset (defaults to the project of the client).\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.DatasetReference:\n",
      "     |              a new ``DatasetReference`` instance.\n",
      "     |\n",
      "     |  delete_dataset(self, dataset: Union[google.cloud.bigquery.dataset.Dataset, google.cloud.bigquery.dataset.DatasetReference, google.cloud.bigquery.dataset.DatasetListItem, str], delete_contents: bool = False, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, not_found_ok: bool = False) -> None\n",
      "     |      Delete a dataset.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/delete\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset (Union[                 google.cloud.bigquery.dataset.Dataset,                 google.cloud.bigquery.dataset.DatasetReference,                 google.cloud.bigquery.dataset.DatasetListItem,                 str,             ]):\n",
      "     |              A reference to the dataset to delete. If a string is passed\n",
      "     |              in, this method attempts to create a dataset reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.dataset.DatasetReference.from_string`.\n",
      "     |          delete_contents (Optional[bool]):\n",
      "     |              If True, delete all the tables in the dataset. If False and\n",
      "     |              the dataset contains tables, the request will fail.\n",
      "     |              Default is False.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          not_found_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"not found\" errors\n",
      "     |              when deleting the dataset.\n",
      "     |\n",
      "     |  delete_job_metadata(self, job_id: Union[str, google.cloud.bigquery.job.load.LoadJob, google.cloud.bigquery.job.copy_.CopyJob, google.cloud.bigquery.job.extract.ExtractJob, google.cloud.bigquery.job.query.QueryJob], project: Optional[str] = None, location: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, not_found_ok: bool = False)\n",
      "     |      [Beta] Delete job metadata from job history.\n",
      "     |\n",
      "     |      Note: This does not stop a running job. Use\n",
      "     |      :func:`~google.cloud.bigquery.client.Client.cancel_job` instead.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          job_id (Union[                 str,                 LoadJob,                 CopyJob,                 ExtractJob,                 QueryJob             ]): Job or job identifier.\n",
      "     |          project (Optional[str]):\n",
      "     |              ID of the project which owns the job (defaults to the client's project).\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where the job was run. Ignored if ``job_id`` is a job\n",
      "     |              object.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          not_found_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"not found\" errors\n",
      "     |              when deleting the job.\n",
      "     |\n",
      "     |  delete_model(self, model: Union[google.cloud.bigquery.model.Model, google.cloud.bigquery.model.ModelReference, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, not_found_ok: bool = False) -> None\n",
      "     |      [Beta] Delete a model\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/models/delete\n",
      "     |\n",
      "     |      Args:\n",
      "     |          model (Union[                 google.cloud.bigquery.model.Model,                 google.cloud.bigquery.model.ModelReference,                 str,             ]):\n",
      "     |              A reference to the model to delete. If a string is passed in,\n",
      "     |              this method attempts to create a model reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.model.ModelReference.from_string`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          not_found_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"not found\" errors\n",
      "     |              when deleting the model.\n",
      "     |\n",
      "     |  delete_routine(self, routine: Union[google.cloud.bigquery.routine.routine.Routine, google.cloud.bigquery.routine.routine.RoutineReference, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, not_found_ok: bool = False) -> None\n",
      "     |      [Beta] Delete a routine.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/delete\n",
      "     |\n",
      "     |      Args:\n",
      "     |          routine (Union[                 google.cloud.bigquery.routine.Routine,                 google.cloud.bigquery.routine.RoutineReference,                 str,             ]):\n",
      "     |              A reference to the routine to delete. If a string is passed\n",
      "     |              in, this method attempts to create a routine reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.routine.RoutineReference.from_string`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          not_found_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"not found\" errors\n",
      "     |              when deleting the routine.\n",
      "     |\n",
      "     |  delete_table(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, not_found_ok: bool = False) -> None\n",
      "     |      Delete a table\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/delete\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,             ]):\n",
      "     |              A reference to the table to delete. If a string is passed in,\n",
      "     |              this method attempts to create a table reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.table.TableReference.from_string`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          not_found_ok (Optional[bool]):\n",
      "     |              Defaults to ``False``. If ``True``, ignore \"not found\" errors\n",
      "     |              when deleting the table.\n",
      "     |\n",
      "     |  extract_table(self, source: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, google.cloud.bigquery.model.Model, google.cloud.bigquery.model.ModelReference, str], destination_uris: Union[str, Sequence[str]], job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, job_config: Optional[google.cloud.bigquery.job.extract.ExtractJobConfig] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, source_type: str = 'Table') -> google.cloud.bigquery.job.extract.ExtractJob\n",
      "     |      Start a job to extract a table into Cloud Storage files.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#jobconfigurationextract\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 google.cloud.bigquery.model.Model,                 google.cloud.bigquery.model.ModelReference,                 src,             ]):\n",
      "     |              Table or Model to be extracted.\n",
      "     |          destination_uris (Union[str, Sequence[str]]):\n",
      "     |              URIs of Cloud Storage file(s) into which table data is to be\n",
      "     |              extracted; in format\n",
      "     |              ``gs://<bucket_name>/<object_name_or_glob>``.\n",
      "     |          job_id (Optional[str]): The ID of the job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The user-provided prefix for a randomly generated job ID.\n",
      "     |              This parameter will be ignored if a ``job_id`` is also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              source table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          job_config (Optional[google.cloud.bigquery.job.ExtractJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          source_type (Optional[str]):\n",
      "     |              Type of source to be extracted.``Table`` or ``Model``. Defaults to ``Table``.\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.ExtractJob: A new extract job instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of :class:`~google.cloud.bigquery.job.ExtractJobConfig`\n",
      "     |              class.\n",
      "     |          ValueError:\n",
      "     |              If ``source_type`` is not among ``Table``,``Model``.\n",
      "     |\n",
      "     |  get_dataset(self, dataset_ref: Union[google.cloud.bigquery.dataset.DatasetReference, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.dataset.Dataset\n",
      "     |      Fetch the dataset referenced by ``dataset_ref``\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset_ref (Union[                 google.cloud.bigquery.dataset.DatasetReference,                 str,             ]):\n",
      "     |              A reference to the dataset to fetch from the BigQuery API.\n",
      "     |              If a string is passed in, this method attempts to create a\n",
      "     |              dataset reference from a string using\n",
      "     |              :func:`~google.cloud.bigquery.dataset.DatasetReference.from_string`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.Dataset:\n",
      "     |              A ``Dataset`` instance.\n",
      "     |\n",
      "     |  get_iam_policy(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], requested_policy_version: int = 1, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.api_core.iam.Policy\n",
      "     |\n",
      "     |  get_job(self, job_id: Union[str, google.cloud.bigquery.job.load.LoadJob, google.cloud.bigquery.job.copy_.CopyJob, google.cloud.bigquery.job.extract.ExtractJob, google.cloud.bigquery.job.query.QueryJob], project: Optional[str] = None, location: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> Union[google.cloud.bigquery.job.load.LoadJob, google.cloud.bigquery.job.copy_.CopyJob, google.cloud.bigquery.job.extract.ExtractJob, google.cloud.bigquery.job.query.QueryJob, google.cloud.bigquery.job.base.UnknownJob]\n",
      "     |      Fetch a job for the project associated with this client.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          job_id (Union[                 str,                 job.LoadJob,                 job.CopyJob,                 job.ExtractJob,                 job.QueryJob             ]):\n",
      "     |              Job identifier.\n",
      "     |          project (Optional[str]):\n",
      "     |              ID of the project which owns the job (defaults to the client's project).\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where the job was run. Ignored if ``job_id`` is a job\n",
      "     |              object.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Union[job.LoadJob, job.CopyJob, job.ExtractJob, job.QueryJob, job.UnknownJob]:\n",
      "     |              Job instance, based on the resource returned by the API.\n",
      "     |\n",
      "     |  get_model(self, model_ref: Union[google.cloud.bigquery.model.ModelReference, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.model.Model\n",
      "     |      [Beta] Fetch the model referenced by ``model_ref``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |         model_ref (Union[                 google.cloud.bigquery.model.ModelReference,                 str,             ]):\n",
      "     |             A reference to the model to fetch from the BigQuery API.\n",
      "     |             If a string is passed in, this method attempts to create a\n",
      "     |             model reference from a string using\n",
      "     |             :func:`google.cloud.bigquery.model.ModelReference.from_string`.\n",
      "     |         retry (Optional[google.api_core.retry.Retry]):\n",
      "     |             How to retry the RPC.\n",
      "     |         timeout (Optional[float]):\n",
      "     |             The number of seconds to wait for the underlying HTTP transport\n",
      "     |             before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |         google.cloud.bigquery.model.Model: A ``Model`` instance.\n",
      "     |\n",
      "     |  get_routine(self, routine_ref: Union[google.cloud.bigquery.routine.routine.Routine, google.cloud.bigquery.routine.routine.RoutineReference, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.routine.routine.Routine\n",
      "     |      [Beta] Get the routine referenced by ``routine_ref``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |         routine_ref (Union[                 google.cloud.bigquery.routine.Routine,                 google.cloud.bigquery.routine.RoutineReference,                 str,             ]):\n",
      "     |             A reference to the routine to fetch from the BigQuery API. If\n",
      "     |             a string is passed in, this method attempts to create a\n",
      "     |             reference from a string using\n",
      "     |             :func:`google.cloud.bigquery.routine.RoutineReference.from_string`.\n",
      "     |         retry (Optional[google.api_core.retry.Retry]):\n",
      "     |             How to retry the API call.\n",
      "     |         timeout (Optional[float]):\n",
      "     |             The number of seconds to wait for the underlying HTTP transport\n",
      "     |             before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |         google.cloud.bigquery.routine.Routine:\n",
      "     |             A ``Routine`` instance.\n",
      "     |\n",
      "     |  get_service_account_email(self, project: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> str\n",
      "     |      Get the email address of the project's BigQuery service account\n",
      "     |\n",
      "     |      Note:\n",
      "     |          This is the service account that BigQuery uses to manage tables\n",
      "     |          encrypted by a key in KMS.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID to use for retreiving service account email.\n",
      "     |              Defaults to the client's project.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str:\n",
      "     |              service account email address\n",
      "     |\n",
      "     |      Example:\n",
      "     |\n",
      "     |          >>> from google.cloud import bigquery\n",
      "     |          >>> client = bigquery.Client()\n",
      "     |          >>> client.get_service_account_email()\n",
      "     |          my_service_account@my-project.iam.gserviceaccount.com\n",
      "     |\n",
      "     |  get_table(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.table.Table\n",
      "     |      Fetch the table referenced by ``table``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,             ]):\n",
      "     |              A reference to the table to fetch from the BigQuery API.\n",
      "     |              If a string is passed in, this method attempts to create a\n",
      "     |              table reference from a string using\n",
      "     |              :func:`google.cloud.bigquery.table.TableReference.from_string`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.Table:\n",
      "     |              A ``Table`` instance.\n",
      "     |\n",
      "     |  insert_rows(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, str], rows: Union[Iterable[Tuple], Iterable[Mapping[str, Any]]], selected_fields: Optional[Sequence[google.cloud.bigquery.schema.SchemaField]] = None, **kwargs) -> Sequence[Dict[str, Any]]\n",
      "     |      Insert rows into a table via the streaming API.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/insertAll\n",
      "     |\n",
      "     |      BigQuery will reject insertAll payloads that exceed a defined limit (10MB).\n",
      "     |      Additionally, if a payload vastly exceeds this limit, the request is rejected\n",
      "     |      by the intermediate architecture, which returns a 413 (Payload Too Large) status code.\n",
      "     |\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/quotas#streaming_inserts\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 str,             ]):\n",
      "     |              The destination table for the row data, or a reference to it.\n",
      "     |          rows (Union[Sequence[Tuple], Sequence[Dict]]):\n",
      "     |              Row data to be inserted. If a list of tuples is given, each\n",
      "     |              tuple should contain data for each schema field on the\n",
      "     |              current table and in the same order as the schema fields. If\n",
      "     |              a list of dictionaries is given, the keys must include all\n",
      "     |              required fields in the schema. Keys which do not correspond\n",
      "     |              to a field in the schema are ignored.\n",
      "     |          selected_fields (Sequence[google.cloud.bigquery.schema.SchemaField]):\n",
      "     |              The fields to return. Required if ``table`` is a\n",
      "     |              :class:`~google.cloud.bigquery.table.TableReference`.\n",
      "     |          kwargs (dict):\n",
      "     |              Keyword arguments to\n",
      "     |              :meth:`~google.cloud.bigquery.client.Client.insert_rows_json`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Sequence[Mappings]:\n",
      "     |              One mapping per row with insert errors: the \"index\" key\n",
      "     |              identifies the row, and the \"errors\" key contains a list of\n",
      "     |              the mappings describing one or more problems with the row.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: if table's schema is not set or `rows` is not a `Sequence`.\n",
      "     |\n",
      "     |  insert_rows_from_dataframe(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, str], dataframe, selected_fields: Optional[Sequence[google.cloud.bigquery.schema.SchemaField]] = None, chunk_size: int = 500, **kwargs: Dict) -> Sequence[Sequence[dict]]\n",
      "     |      Insert rows into a table from a dataframe via the streaming API.\n",
      "     |\n",
      "     |      BigQuery will reject insertAll payloads that exceed a defined limit (10MB).\n",
      "     |      Additionally, if a payload vastly exceeds this limit, the request is rejected\n",
      "     |      by the intermediate architecture, which returns a 413 (Payload Too Large) status code.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/quotas#streaming_inserts\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 str,             ]):\n",
      "     |              The destination table for the row data, or a reference to it.\n",
      "     |          dataframe (pandas.DataFrame):\n",
      "     |              A :class:`~pandas.DataFrame` containing the data to load. Any\n",
      "     |              ``NaN`` values present in the dataframe are omitted from the\n",
      "     |              streaming API request(s).\n",
      "     |          selected_fields (Sequence[google.cloud.bigquery.schema.SchemaField]):\n",
      "     |              The fields to return. Required if ``table`` is a\n",
      "     |              :class:`~google.cloud.bigquery.table.TableReference`.\n",
      "     |          chunk_size (int):\n",
      "     |              The number of rows to stream in a single chunk. Must be positive.\n",
      "     |          kwargs (Dict):\n",
      "     |              Keyword arguments to\n",
      "     |              :meth:`~google.cloud.bigquery.client.Client.insert_rows_json`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Sequence[Sequence[Mappings]]:\n",
      "     |              A list with insert errors for each insert chunk. Each element\n",
      "     |              is a list containing one mapping per row with insert errors:\n",
      "     |              the \"index\" key identifies the row, and the \"errors\" key\n",
      "     |              contains a list of the mappings describing one or more problems\n",
      "     |              with the row.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: if table's schema is not set\n",
      "     |\n",
      "     |  insert_rows_json(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], json_rows: Sequence[Mapping[str, Any]], row_ids: Union[Iterable[Optional[str]], google.cloud.bigquery.enums.AutoRowIDs, NoneType] = <AutoRowIDs.GENERATE_UUID: 2>, skip_invalid_rows: Optional[bool] = None, ignore_unknown_values: Optional[bool] = None, template_suffix: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> Sequence[dict]\n",
      "     |      Insert rows into a table without applying local type conversions.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/insertAll\n",
      "     |\n",
      "     |      BigQuery will reject insertAll payloads that exceed a defined limit (10MB).\n",
      "     |      Additionally, if a payload vastly exceeds this limit, the request is rejected\n",
      "     |      by the intermediate architecture, which returns a 413 (Payload Too Large) status code.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/quotas#streaming_inserts\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str             ]):\n",
      "     |              The destination table for the row data, or a reference to it.\n",
      "     |          json_rows (Sequence[Dict]):\n",
      "     |              Row data to be inserted. Keys must match the table schema fields\n",
      "     |              and values must be JSON-compatible representations.\n",
      "     |          row_ids (Union[Iterable[str], AutoRowIDs, None]):\n",
      "     |              Unique IDs, one per row being inserted. An ID can also be\n",
      "     |              ``None``, indicating that an explicit insert ID should **not**\n",
      "     |              be used for that row. If the argument is omitted altogether,\n",
      "     |              unique IDs are created automatically.\n",
      "     |\n",
      "     |              .. versionchanged:: 2.21.0\n",
      "     |                  Can also be an iterable, not just a sequence, or an\n",
      "     |                  :class:`AutoRowIDs` enum member.\n",
      "     |\n",
      "     |              .. deprecated:: 2.21.0\n",
      "     |                  Passing ``None`` to explicitly request autogenerating insert IDs is\n",
      "     |                  deprecated, use :attr:`AutoRowIDs.GENERATE_UUID` instead.\n",
      "     |\n",
      "     |          skip_invalid_rows (Optional[bool]):\n",
      "     |              Insert all valid rows of a request, even if invalid rows exist.\n",
      "     |              The default value is ``False``, which causes the entire request\n",
      "     |              to fail if any invalid rows exist.\n",
      "     |          ignore_unknown_values (Optional[bool]):\n",
      "     |              Accept rows that contain values that do not match the schema.\n",
      "     |              The unknown values are ignored. Default is ``False``, which\n",
      "     |              treats unknown values as errors.\n",
      "     |          template_suffix (Optional[str]):\n",
      "     |              Treat ``name`` as a template table and provide a suffix.\n",
      "     |              BigQuery will create the table ``<name> + <template_suffix>``\n",
      "     |              based on the schema of the template table. See\n",
      "     |              https://cloud.google.com/bigquery/streaming-data-into-bigquery#template-tables\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Sequence[Mappings]:\n",
      "     |              One mapping per row with insert errors: the \"index\" key\n",
      "     |              identifies the row, and the \"errors\" key contains a list of\n",
      "     |              the mappings describing one or more problems with the row.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: if `json_rows` is not a `Sequence`.\n",
      "     |\n",
      "     |  job_from_resource(self, resource: dict) -> Union[google.cloud.bigquery.job.copy_.CopyJob, google.cloud.bigquery.job.extract.ExtractJob, google.cloud.bigquery.job.load.LoadJob, google.cloud.bigquery.job.query.QueryJob, google.cloud.bigquery.job.base.UnknownJob]\n",
      "     |      Detect correct job type from resource and instantiate.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): one job resource from API response\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Union[job.CopyJob, job.ExtractJob, job.LoadJob, job.QueryJob, job.UnknownJob]:\n",
      "     |              The job instance, constructed via the resource.\n",
      "     |\n",
      "     |  list_datasets(self, project: Optional[str] = None, include_all: bool = False, filter: Optional[str] = None, max_results: Optional[int] = None, page_token: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, page_size: Optional[int] = None) -> google.api_core.page_iterator.Iterator\n",
      "     |      List datasets for the project associated with this client.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list\n",
      "     |\n",
      "     |      Args:\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID to use for retreiving datasets. Defaults to the\n",
      "     |              client's project.\n",
      "     |          include_all (Optional[bool]):\n",
      "     |              True if results include hidden datasets. Defaults to False.\n",
      "     |          filter (Optional[str]):\n",
      "     |              An expression for filtering the results by label.\n",
      "     |              For syntax, see\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list#body.QUERY_PARAMETERS.filter\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of datasets to return.\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Token representing a cursor into the datasets. If not passed,\n",
      "     |              the API will return the first page of datasets. The token marks\n",
      "     |              the beginning of the iterator to be returned and the value of\n",
      "     |              the ``page_token`` can be accessed at ``next_page_token`` of the\n",
      "     |              :class:`~google.api_core.page_iterator.HTTPIterator`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              Maximum number of datasets to return per page.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.api_core.page_iterator.Iterator:\n",
      "     |              Iterator of :class:`~google.cloud.bigquery.dataset.DatasetListItem`.\n",
      "     |              associated with the project.\n",
      "     |\n",
      "     |  list_jobs(self, project: Optional[str] = None, parent_job: Union[google.cloud.bigquery.job.query.QueryJob, str, NoneType] = None, max_results: Optional[int] = None, page_token: Optional[str] = None, all_users: Optional[bool] = None, state_filter: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, min_creation_time: Optional[datetime.datetime] = None, max_creation_time: Optional[datetime.datetime] = None, page_size: Optional[int] = None) -> google.api_core.page_iterator.Iterator\n",
      "     |      List jobs for the project associated with this client.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/list\n",
      "     |\n",
      "     |      Args:\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID to use for retreiving datasets. Defaults\n",
      "     |              to the client's project.\n",
      "     |          parent_job (Optional[Union[                 google.cloud.bigquery.job._AsyncJob,                 str,             ]]):\n",
      "     |              If set, retrieve only child jobs of the specified parent.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of jobs to return.\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Opaque marker for the next \"page\" of jobs. If not\n",
      "     |              passed, the API will return the first page of jobs. The token\n",
      "     |              marks the beginning of the iterator to be returned and the\n",
      "     |              value of the ``page_token`` can be accessed at\n",
      "     |              ``next_page_token`` of\n",
      "     |              :class:`~google.api_core.page_iterator.HTTPIterator`.\n",
      "     |          all_users (Optional[bool]):\n",
      "     |              If true, include jobs owned by all users in the project.\n",
      "     |              Defaults to :data:`False`.\n",
      "     |          state_filter (Optional[str]):\n",
      "     |              If set, include only jobs matching the given state. One of:\n",
      "     |                  * ``\"done\"``\n",
      "     |                  * ``\"pending\"``\n",
      "     |                  * ``\"running\"``\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          min_creation_time (Optional[datetime.datetime]):\n",
      "     |              Min value for job creation time. If set, only jobs created\n",
      "     |              after or at this timestamp are returned. If the datetime has\n",
      "     |              no time zone assumes UTC time.\n",
      "     |          max_creation_time (Optional[datetime.datetime]):\n",
      "     |              Max value for job creation time. If set, only jobs created\n",
      "     |              before or at this timestamp are returned. If the datetime has\n",
      "     |              no time zone assumes UTC time.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              Maximum number of jobs to return per page.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.api_core.page_iterator.Iterator:\n",
      "     |              Iterable of job instances.\n",
      "     |\n",
      "     |  list_models(self, dataset: Union[google.cloud.bigquery.dataset.Dataset, google.cloud.bigquery.dataset.DatasetReference, google.cloud.bigquery.dataset.DatasetListItem, str], max_results: Optional[int] = None, page_token: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, page_size: Optional[int] = None) -> google.api_core.page_iterator.Iterator\n",
      "     |      [Beta] List models in the dataset.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/models/list\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset (Union[                 google.cloud.bigquery.dataset.Dataset,                 google.cloud.bigquery.dataset.DatasetReference,                 google.cloud.bigquery.dataset.DatasetListItem,                 str,             ]):\n",
      "     |              A reference to the dataset whose models to list from the\n",
      "     |              BigQuery API. If a string is passed in, this method attempts\n",
      "     |              to create a dataset reference from a string using\n",
      "     |              :func:`google.cloud.bigquery.dataset.DatasetReference.from_string`.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of models to return. Defaults to a\n",
      "     |              value set by the API.\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Token representing a cursor into the models. If not passed,\n",
      "     |              the API will return the first page of models. The token marks\n",
      "     |              the beginning of the iterator to be returned and the value of\n",
      "     |              the ``page_token`` can be accessed at ``next_page_token`` of the\n",
      "     |              :class:`~google.api_core.page_iterator.HTTPIterator`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              Maximum number of models to return per page.\n",
      "     |              Defaults to a value set by the API.\n",
      "     |\n",
      "     |       Returns:\n",
      "     |          google.api_core.page_iterator.Iterator:\n",
      "     |              Iterator of\n",
      "     |              :class:`~google.cloud.bigquery.model.Model` contained\n",
      "     |              within the requested dataset.\n",
      "     |\n",
      "     |  list_partitions(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> Sequence[str]\n",
      "     |      List the partitions in a table.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,             ]):\n",
      "     |              The table or reference from which to get partition info\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[str]:\n",
      "     |              A list of the partition ids present in the partitioned table\n",
      "     |\n",
      "     |  list_projects(self, max_results: Optional[int] = None, page_token: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, page_size: Optional[int] = None) -> google.api_core.page_iterator.Iterator\n",
      "     |      List projects for the project associated with this client.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/projects/list\n",
      "     |\n",
      "     |      Args:\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of projects to return.\n",
      "     |              Defaults to a value set by the API.\n",
      "     |\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Token representing a cursor into the projects. If not passed,\n",
      "     |              the API will return the first page of projects. The token marks\n",
      "     |              the beginning of the iterator to be returned and the value of\n",
      "     |              the ``page_token`` can be accessed at ``next_page_token`` of the\n",
      "     |              :class:`~google.api_core.page_iterator.HTTPIterator`.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |          page_size (Optional[int]):\n",
      "     |              Maximum number of projects to return in each page.\n",
      "     |              Defaults to a value set by the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.api_core.page_iterator.Iterator:\n",
      "     |              Iterator of :class:`~google.cloud.bigquery.client.Project`\n",
      "     |              accessible to the current client.\n",
      "     |\n",
      "     |  list_routines(self, dataset: Union[google.cloud.bigquery.dataset.Dataset, google.cloud.bigquery.dataset.DatasetReference, google.cloud.bigquery.dataset.DatasetListItem, str], max_results: Optional[int] = None, page_token: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, page_size: Optional[int] = None) -> google.api_core.page_iterator.Iterator\n",
      "     |      [Beta] List routines in the dataset.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines/list\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset (Union[                 google.cloud.bigquery.dataset.Dataset,                 google.cloud.bigquery.dataset.DatasetReference,                 google.cloud.bigquery.dataset.DatasetListItem,                 str,             ]):\n",
      "     |              A reference to the dataset whose routines to list from the\n",
      "     |              BigQuery API. If a string is passed in, this method attempts\n",
      "     |              to create a dataset reference from a string using\n",
      "     |              :func:`google.cloud.bigquery.dataset.DatasetReference.from_string`.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of routines to return. Defaults\n",
      "     |              to a value set by the API.\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Token representing a cursor into the routines. If not passed,\n",
      "     |              the API will return the first page of routines. The token marks\n",
      "     |              the beginning of the iterator to be returned and the value of the\n",
      "     |              ``page_token`` can be accessed at ``next_page_token`` of the\n",
      "     |              :class:`~google.api_core.page_iterator.HTTPIterator`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              Maximum number of routines to return per page.\n",
      "     |              Defaults to a value set by the API.\n",
      "     |\n",
      "     |       Returns:\n",
      "     |          google.api_core.page_iterator.Iterator:\n",
      "     |              Iterator of all\n",
      "     |              :class:`~google.cloud.bigquery.routine.Routine`s contained\n",
      "     |              within the requested dataset, limited by ``max_results``.\n",
      "     |\n",
      "     |  list_rows(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableListItem, google.cloud.bigquery.table.TableReference, str], selected_fields: Optional[Sequence[google.cloud.bigquery.schema.SchemaField]] = None, max_results: Optional[int] = None, page_token: Optional[str] = None, start_index: Optional[int] = None, page_size: Optional[int] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.table.RowIterator\n",
      "     |      List the rows of the table.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/list\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         This method assumes that the provided schema is up-to-date with the\n",
      "     |         schema as defined on the back-end: if the two schemas are not\n",
      "     |         identical, the values returned may be incomplete. To ensure that the\n",
      "     |         local copy of the schema is up-to-date, call ``client.get_table``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableListItem,                 google.cloud.bigquery.table.TableReference,                 str,             ]):\n",
      "     |              The table to list, or a reference to it. When the table\n",
      "     |              object does not contain a schema and ``selected_fields`` is\n",
      "     |              not supplied, this method calls ``get_table`` to fetch the\n",
      "     |              table schema.\n",
      "     |          selected_fields (Sequence[google.cloud.bigquery.schema.SchemaField]):\n",
      "     |              The fields to return. If not supplied, data for all columns\n",
      "     |              are downloaded.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of rows to return.\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Token representing a cursor into the table's rows.\n",
      "     |              If not passed, the API will return the first page of the\n",
      "     |              rows. The token marks the beginning of the iterator to be\n",
      "     |              returned and the value of the ``page_token`` can be accessed\n",
      "     |              at ``next_page_token`` of the\n",
      "     |              :class:`~google.cloud.bigquery.table.RowIterator`.\n",
      "     |          start_index (Optional[int]):\n",
      "     |              The zero-based index of the starting row to read.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              The maximum number of rows in each page of results from this request.\n",
      "     |              Non-positive values are ignored. Defaults to a sensible value set by the API.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.RowIterator:\n",
      "     |              Iterator of row data\n",
      "     |              :class:`~google.cloud.bigquery.table.Row`-s. During each\n",
      "     |              page, the iterator will have the ``total_rows`` attribute\n",
      "     |              set, which counts the total number of rows **in the table**\n",
      "     |              (this is distinct from the total number of rows in the\n",
      "     |              current page: ``iterator.page.num_items``).\n",
      "     |\n",
      "     |  list_tables(self, dataset: Union[google.cloud.bigquery.dataset.Dataset, google.cloud.bigquery.dataset.DatasetReference, google.cloud.bigquery.dataset.DatasetListItem, str], max_results: Optional[int] = None, page_token: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, page_size: Optional[int] = None) -> google.api_core.page_iterator.Iterator\n",
      "     |      List tables in the dataset.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/list\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset (Union[                 google.cloud.bigquery.dataset.Dataset,                 google.cloud.bigquery.dataset.DatasetReference,                 google.cloud.bigquery.dataset.DatasetListItem,                 str,             ]):\n",
      "     |              A reference to the dataset whose tables to list from the\n",
      "     |              BigQuery API. If a string is passed in, this method attempts\n",
      "     |              to create a dataset reference from a string using\n",
      "     |              :func:`google.cloud.bigquery.dataset.DatasetReference.from_string`.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of tables to return. Defaults\n",
      "     |              to a value set by the API.\n",
      "     |          page_token (Optional[str]):\n",
      "     |              Token representing a cursor into the tables. If not passed,\n",
      "     |              the API will return the first page of tables. The token marks\n",
      "     |              the beginning of the iterator to be returned and the value of\n",
      "     |              the ``page_token`` can be accessed at ``next_page_token`` of the\n",
      "     |              :class:`~google.api_core.page_iterator.HTTPIterator`.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              Maximum number of tables to return per page.\n",
      "     |              Defaults to a value set by the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.api_core.page_iterator.Iterator:\n",
      "     |              Iterator of\n",
      "     |              :class:`~google.cloud.bigquery.table.TableListItem` contained\n",
      "     |              within the requested dataset.\n",
      "     |\n",
      "     |  load_table_from_dataframe(self, dataframe: 'pandas.DataFrame', destination: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, str], num_retries: int = 6, job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, job_config: Optional[google.cloud.bigquery.job.load.LoadJobConfig] = None, parquet_compression: str = 'snappy', timeout: Union[NoneType, float, Tuple[float, float]] = None) -> google.cloud.bigquery.job.load.LoadJob\n",
      "     |      Upload the contents of a table from a pandas DataFrame.\n",
      "     |\n",
      "     |      Similar to :meth:`load_table_from_uri`, this method creates, starts and\n",
      "     |      returns a :class:`~google.cloud.bigquery.job.LoadJob`.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |          REPEATED fields are NOT supported when using the CSV source format.\n",
      "     |          They are supported when using the PARQUET source format, but\n",
      "     |          due to the way they are encoded in the ``parquet`` file,\n",
      "     |          a mismatch with the existing table schema can occur, so\n",
      "     |          REPEATED fields are not properly supported when using ``pyarrow<4.0.0``\n",
      "     |          using the parquet format.\n",
      "     |\n",
      "     |          https://github.com/googleapis/python-bigquery/issues/19\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataframe (pandas.Dataframe):\n",
      "     |              A :class:`~pandas.DataFrame` containing the data to load.\n",
      "     |          destination (Union[                 Table,                 TableReference,                 str             ]):\n",
      "     |              The destination table to use for loading the data. If it is an\n",
      "     |              existing table, the schema of the :class:`~pandas.DataFrame`\n",
      "     |              must match the schema of the destination table. If the table\n",
      "     |              does not yet exist, the schema is inferred from the\n",
      "     |              :class:`~pandas.DataFrame`.\n",
      "     |\n",
      "     |              If a string is passed in, this method attempts to create a\n",
      "     |              table reference from a string using\n",
      "     |              :func:`google.cloud.bigquery.table.TableReference.from_string`.\n",
      "     |          num_retries (Optional[int]): Number of upload retries. Defaults to 6.\n",
      "     |          job_id (Optional[str]): Name of the job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The user-provided prefix for a randomly generated\n",
      "     |              job ID. This parameter will be ignored if a ``job_id`` is\n",
      "     |              also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          job_config (Optional[LoadJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |\n",
      "     |              To override the default pandas data type conversions, supply\n",
      "     |              a value for\n",
      "     |              :attr:`~google.cloud.bigquery.job.LoadJobConfig.schema` with\n",
      "     |              column names matching those of the dataframe. The BigQuery\n",
      "     |              schema is used to determine the correct data type conversion.\n",
      "     |              Indexes are not loaded.\n",
      "     |\n",
      "     |              By default, this method uses the parquet source format. To\n",
      "     |              override this, supply a value for\n",
      "     |              :attr:`~google.cloud.bigquery.job.LoadJobConfig.source_format`\n",
      "     |              with the format name. Currently only\n",
      "     |              :attr:`~google.cloud.bigquery.job.SourceFormat.CSV` and\n",
      "     |              :attr:`~google.cloud.bigquery.job.SourceFormat.PARQUET` are\n",
      "     |              supported.\n",
      "     |          parquet_compression (Optional[str]):\n",
      "     |              [Beta] The compression method to use if intermittently\n",
      "     |              serializing ``dataframe`` to a parquet file.\n",
      "     |              Defaults to \"snappy\".\n",
      "     |\n",
      "     |              The argument is directly passed as the ``compression``\n",
      "     |              argument to the underlying ``pyarrow.parquet.write_table()``\n",
      "     |              method (the default value \"snappy\" gets converted to uppercase).\n",
      "     |              https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html#pyarrow-parquet-write-table\n",
      "     |\n",
      "     |              If the job config schema is missing, the argument is directly\n",
      "     |              passed as the ``compression`` argument to the underlying\n",
      "     |              ``DataFrame.to_parquet()`` method.\n",
      "     |              https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html#pandas.DataFrame.to_parquet\n",
      "     |          timeout (Optional[flaot]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``. Depending on the retry strategy, a request may\n",
      "     |              be repeated several times using the same timeout each time.\n",
      "     |              Defaults to None.\n",
      "     |\n",
      "     |              Can also be passed as a tuple (connect_timeout, read_timeout).\n",
      "     |              See :meth:`requests.Session.request` documentation for details.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.LoadJob: A new load job.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If a usable parquet engine cannot be found. This method\n",
      "     |              requires :mod:`pyarrow` to be installed.\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of\n",
      "     |              :class:`~google.cloud.bigquery.job.LoadJobConfig` class.\n",
      "     |\n",
      "     |  load_table_from_file(self, file_obj: IO[bytes], destination: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], rewind: bool = False, size: Optional[int] = None, num_retries: int = 6, job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, job_config: Optional[google.cloud.bigquery.job.load.LoadJobConfig] = None, timeout: Union[NoneType, float, Tuple[float, float]] = None) -> google.cloud.bigquery.job.load.LoadJob\n",
      "     |      Upload the contents of this table from a file-like object.\n",
      "     |\n",
      "     |      Similar to :meth:`load_table_from_uri`, this method creates, starts and\n",
      "     |      returns a :class:`~google.cloud.bigquery.job.LoadJob`.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          file_obj (IO[bytes]):\n",
      "     |              A file handle opened in binary mode for reading.\n",
      "     |          destination (Union[Table,                 TableReference,                 TableListItem,                 str             ]):\n",
      "     |              Table into which data is to be loaded. If a string is passed\n",
      "     |              in, this method attempts to create a table reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.table.TableReference.from_string`.\n",
      "     |          rewind (Optional[bool]):\n",
      "     |              If True, seek to the beginning of the file handle before\n",
      "     |              reading the file. Defaults to False.\n",
      "     |          size (Optional[int]):\n",
      "     |              The number of bytes to read from the file handle. If size is\n",
      "     |              ``None`` or large, resumable upload will be used. Otherwise,\n",
      "     |              multipart upload will be used.\n",
      "     |          num_retries (Optional[int]): Number of upload retries. Defaults to 6.\n",
      "     |          job_id (Optional[str]): Name of the job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The user-provided prefix for a randomly generated job ID.\n",
      "     |              This parameter will be ignored if a ``job_id`` is also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          job_config (Optional[LoadJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``. Depending on the retry strategy, a request\n",
      "     |              may be repeated several times using the same timeout each time.\n",
      "     |              Defaults to None.\n",
      "     |\n",
      "     |              Can also be passed as a tuple (connect_timeout, read_timeout).\n",
      "     |              See :meth:`requests.Session.request` documentation for details.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.LoadJob: A new load job.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``size`` is not passed in and can not be determined, or if\n",
      "     |              the ``file_obj`` can be detected to be a file opened in text\n",
      "     |              mode.\n",
      "     |\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of\n",
      "     |              :class:`~google.cloud.bigquery.job.LoadJobConfig` class.\n",
      "     |\n",
      "     |  load_table_from_json(self, json_rows: Iterable[Dict[str, Any]], destination: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], num_retries: int = 6, job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, job_config: Optional[google.cloud.bigquery.job.load.LoadJobConfig] = None, timeout: Union[NoneType, float, Tuple[float, float]] = None) -> google.cloud.bigquery.job.load.LoadJob\n",
      "     |      Upload the contents of a table from a JSON string or dict.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          json_rows (Iterable[Dict[str, Any]]):\n",
      "     |              Row data to be inserted. Keys must match the table schema fields\n",
      "     |              and values must be JSON-compatible representations.\n",
      "     |\n",
      "     |              .. note::\n",
      "     |\n",
      "     |                  If your data is already a newline-delimited JSON string,\n",
      "     |                  it is best to wrap it into a file-like object and pass it\n",
      "     |                  to :meth:`~google.cloud.bigquery.client.Client.load_table_from_file`::\n",
      "     |\n",
      "     |                      import io\n",
      "     |                      from google.cloud import bigquery\n",
      "     |\n",
      "     |                      data = u'{\"foo\": \"bar\"}'\n",
      "     |                      data_as_file = io.StringIO(data)\n",
      "     |\n",
      "     |                      client = bigquery.Client()\n",
      "     |                      client.load_table_from_file(data_as_file, ...)\n",
      "     |\n",
      "     |          destination (Union[                 Table,                 TableReference,                 TableListItem,                 str             ]):\n",
      "     |              Table into which data is to be loaded. If a string is passed\n",
      "     |              in, this method attempts to create a table reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.table.TableReference.from_string`.\n",
      "     |          num_retries (Optional[int]): Number of upload retries. Defaults to 6.\n",
      "     |          job_id (Optional[str]): Name of the job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The user-provided prefix for a randomly generated job ID.\n",
      "     |              This parameter will be ignored if a ``job_id`` is also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          job_config (Optional[LoadJobConfig]):\n",
      "     |              Extra configuration options for the job. The ``source_format``\n",
      "     |              setting is always set to\n",
      "     |              :attr:`~google.cloud.bigquery.job.SourceFormat.NEWLINE_DELIMITED_JSON`.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``. Depending on the retry strategy, a request may\n",
      "     |              be repeated several times using the same timeout each time.\n",
      "     |              Defaults to None.\n",
      "     |\n",
      "     |              Can also be passed as a tuple (connect_timeout, read_timeout).\n",
      "     |              See :meth:`requests.Session.request` documentation for details.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.LoadJob: A new load job.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of\n",
      "     |              :class:`~google.cloud.bigquery.job.LoadJobConfig` class.\n",
      "     |\n",
      "     |  load_table_from_uri(self, source_uris: Union[str, Sequence[str]], destination: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, job_config: Optional[google.cloud.bigquery.job.load.LoadJobConfig] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.job.load.LoadJob\n",
      "     |      Starts a job for loading data into a table from Cloud Storage.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#jobconfigurationload\n",
      "     |\n",
      "     |      Args:\n",
      "     |          source_uris (Union[str, Sequence[str]]):\n",
      "     |              URIs of data files to be loaded; in format\n",
      "     |              ``gs://<bucket_name>/<object_name_or_glob>``.\n",
      "     |          destination (Union[                 google.cloud.bigquery.table.Table,                 google.cloud.bigquery.table.TableReference,                 google.cloud.bigquery.table.TableListItem,                 str,             ]):\n",
      "     |              Table into which data is to be loaded. If a string is passed\n",
      "     |              in, this method attempts to create a table reference from a\n",
      "     |              string using\n",
      "     |              :func:`google.cloud.bigquery.table.TableReference.from_string`.\n",
      "     |          job_id (Optional[str]): Name of the job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The user-provided prefix for a randomly generated job ID.\n",
      "     |              This parameter will be ignored if a ``job_id`` is also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          job_config (Optional[google.cloud.bigquery.job.LoadJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.LoadJob: A new load job.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of\n",
      "     |              :class:`~google.cloud.bigquery.job.LoadJobConfig` class.\n",
      "     |\n",
      "     |  query(self, query: str, job_config: Optional[google.cloud.bigquery.job.query.QueryJobConfig] = None, job_id: Optional[str] = None, job_id_prefix: Optional[str] = None, location: Optional[str] = None, project: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, job_retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c196a0>, api_method: Union[str, google.cloud.bigquery.enums.QueryApiMethod] = <QueryApiMethod.INSERT: 'INSERT'>) -> google.cloud.bigquery.job.query.QueryJob\n",
      "     |      Run a SQL query.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#jobconfigurationquery\n",
      "     |\n",
      "     |      Args:\n",
      "     |          query (str):\n",
      "     |              SQL query to be executed. Defaults to the standard SQL\n",
      "     |              dialect. Use the ``job_config`` parameter to change dialects.\n",
      "     |          job_config (Optional[google.cloud.bigquery.job.QueryJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |              To override any options that were previously set in\n",
      "     |              the ``default_query_job_config`` given to the\n",
      "     |              ``Client`` constructor, manually set those options to ``None``,\n",
      "     |              or whatever value is preferred.\n",
      "     |          job_id (Optional[str]): ID to use for the query job.\n",
      "     |          job_id_prefix (Optional[str]):\n",
      "     |              The prefix to use for a randomly generated job ID. This parameter\n",
      "     |              will be ignored if a ``job_id`` is also given.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              table used in the query as well as the destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.  This only applies to making RPC\n",
      "     |              calls.  It isn't used to retry failed jobs.  This has\n",
      "     |              a reasonable default that should only be overridden\n",
      "     |              with care.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          job_retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry failed jobs.  The default retries\n",
      "     |              rate-limit-exceeded errors.  Passing ``None`` disables\n",
      "     |              job retry.\n",
      "     |\n",
      "     |              Not all jobs can be retried.  If ``job_id`` is\n",
      "     |              provided, then the job returned by the query will not\n",
      "     |              be retryable, and an exception will be raised if a\n",
      "     |              non-``None`` (and non-default) value for ``job_retry``\n",
      "     |              is also provided.\n",
      "     |\n",
      "     |              Note that errors aren't detected until ``result()`` is\n",
      "     |              called on the job returned. The ``job_retry``\n",
      "     |              specified here becomes the default ``job_retry`` for\n",
      "     |              ``result()``, where it can also be specified.\n",
      "     |          api_method (Union[str, enums.QueryApiMethod]):\n",
      "     |              Method with which to start the query job.\n",
      "     |\n",
      "     |              See :class:`google.cloud.bigquery.enums.QueryApiMethod` for\n",
      "     |              details on the difference between the query start methods.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.QueryJob: A new query job instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of\n",
      "     |              :class:`~google.cloud.bigquery.job.QueryJobConfig`\n",
      "     |              class, or if both ``job_id`` and non-``None`` non-default\n",
      "     |              ``job_retry`` are provided.\n",
      "     |\n",
      "     |  query_and_wait(self, query, *, job_config: Optional[google.cloud.bigquery.job.query.QueryJobConfig] = None, location: Optional[str] = None, project: Optional[str] = None, api_timeout: Optional[float] = None, wait_timeout: Optional[float] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, job_retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c196a0>, page_size: Optional[int] = None, max_results: Optional[int] = None) -> google.cloud.bigquery.table.RowIterator\n",
      "     |      Run the query, wait for it to finish, and return the results.\n",
      "     |\n",
      "     |      While ``jobCreationMode=JOB_CREATION_OPTIONAL`` is in preview in the\n",
      "     |      ``jobs.query`` REST API, use the default ``jobCreationMode`` unless\n",
      "     |      the environment variable ``QUERY_PREVIEW_ENABLED=true``. After\n",
      "     |      ``jobCreationMode`` is GA, this method will always use\n",
      "     |      ``jobCreationMode=JOB_CREATION_OPTIONAL``. See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/query\n",
      "     |\n",
      "     |      Args:\n",
      "     |          query (str):\n",
      "     |              SQL query to be executed. Defaults to the standard SQL\n",
      "     |              dialect. Use the ``job_config`` parameter to change dialects.\n",
      "     |          job_config (Optional[google.cloud.bigquery.job.QueryJobConfig]):\n",
      "     |              Extra configuration options for the job.\n",
      "     |              To override any options that were previously set in\n",
      "     |              the ``default_query_job_config`` given to the\n",
      "     |              ``Client`` constructor, manually set those options to ``None``,\n",
      "     |              or whatever value is preferred.\n",
      "     |          location (Optional[str]):\n",
      "     |              Location where to run the job. Must match the location of the\n",
      "     |              table used in the query as well as the destination table.\n",
      "     |          project (Optional[str]):\n",
      "     |              Project ID of the project of where to run the job. Defaults\n",
      "     |              to the client's project.\n",
      "     |          api_timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          wait_timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the query to finish. If the\n",
      "     |              query doesn't finish before this timeout, the client attempts\n",
      "     |              to cancel the query.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.  This only applies to making RPC\n",
      "     |              calls.  It isn't used to retry failed jobs.  This has\n",
      "     |              a reasonable default that should only be overridden\n",
      "     |              with care.\n",
      "     |          job_retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry failed jobs.  The default retries\n",
      "     |              rate-limit-exceeded errors.  Passing ``None`` disables\n",
      "     |              job retry. Not all jobs can be retried.\n",
      "     |          page_size (Optional[int]):\n",
      "     |              The maximum number of rows in each page of results from this\n",
      "     |              request. Non-positive values are ignored.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              The maximum total number of rows from this request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.RowIterator:\n",
      "     |              Iterator of row data\n",
      "     |              :class:`~google.cloud.bigquery.table.Row`-s. During each\n",
      "     |              page, the iterator will have the ``total_rows`` attribute\n",
      "     |              set, which counts the total number of rows **in the result\n",
      "     |              set** (this is distinct from the total number of rows in the\n",
      "     |              current page: ``iterator.page.num_items``).\n",
      "     |\n",
      "     |              If the query is a special query that produces no results, e.g.\n",
      "     |              a DDL query, an ``_EmptyRowIterator`` instance is returned.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError:\n",
      "     |              If ``job_config`` is not an instance of\n",
      "     |              :class:`~google.cloud.bigquery.job.QueryJobConfig`\n",
      "     |              class.\n",
      "     |\n",
      "     |  schema_from_json(self, file_or_path: 'PathType') -> List[google.cloud.bigquery.schema.SchemaField]\n",
      "     |      Takes a file object or file path that contains json that describes\n",
      "     |      a table schema.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[SchemaField]:\n",
      "     |              List of :class:`~google.cloud.bigquery.schema.SchemaField` objects.\n",
      "     |\n",
      "     |  schema_to_json(self, schema_list: Sequence[google.cloud.bigquery.schema.SchemaField], destination: 'PathType')\n",
      "     |      Takes a list of schema field objects.\n",
      "     |\n",
      "     |      Serializes the list of schema field objects as json to a file.\n",
      "     |\n",
      "     |      Destination is a file path or a file object.\n",
      "     |\n",
      "     |  set_iam_policy(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], policy: google.api_core.iam.Policy, updateMask: Optional[str] = None, retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.api_core.iam.Policy\n",
      "     |\n",
      "     |  test_iam_permissions(self, table: Union[google.cloud.bigquery.table.Table, google.cloud.bigquery.table.TableReference, google.cloud.bigquery.table.TableListItem, str], permissions: Sequence[str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> Dict[str, Any]\n",
      "     |\n",
      "     |  update_dataset(self, dataset: google.cloud.bigquery.dataset.Dataset, fields: Sequence[str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.dataset.Dataset\n",
      "     |      Change some fields of a dataset.\n",
      "     |\n",
      "     |      Use ``fields`` to specify which fields to update. At least one field\n",
      "     |      must be provided. If a field is listed in ``fields`` and is ``None`` in\n",
      "     |      ``dataset``, it will be deleted.\n",
      "     |\n",
      "     |      If ``dataset.etag`` is not ``None``, the update will only\n",
      "     |      succeed if the dataset on the server has the same ETag. Thus\n",
      "     |      reading a dataset with ``get_dataset``, changing its fields,\n",
      "     |      and then passing it to ``update_dataset`` will ensure that the changes\n",
      "     |      will only be saved if no modifications to the dataset occurred\n",
      "     |      since the read.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset (google.cloud.bigquery.dataset.Dataset):\n",
      "     |              The dataset to update.\n",
      "     |          fields (Sequence[str]):\n",
      "     |              The properties of ``dataset`` to change. These are strings\n",
      "     |              corresponding to the properties of\n",
      "     |              :class:`~google.cloud.bigquery.dataset.Dataset`.\n",
      "     |\n",
      "     |              For example, to update the default expiration times, specify\n",
      "     |              both properties in the ``fields`` argument:\n",
      "     |\n",
      "     |              .. code-block:: python\n",
      "     |\n",
      "     |                  bigquery_client.update_dataset(\n",
      "     |                      dataset,\n",
      "     |                      [\n",
      "     |                          \"default_partition_expiration_ms\",\n",
      "     |                          \"default_table_expiration_ms\",\n",
      "     |                      ]\n",
      "     |                  )\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.Dataset:\n",
      "     |              The modified ``Dataset`` instance.\n",
      "     |\n",
      "     |  update_model(self, model: google.cloud.bigquery.model.Model, fields: Sequence[str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.model.Model\n",
      "     |      [Beta] Change some fields of a model.\n",
      "     |\n",
      "     |      Use ``fields`` to specify which fields to update. At least one field\n",
      "     |      must be provided. If a field is listed in ``fields`` and is ``None``\n",
      "     |      in ``model``, the field value will be deleted.\n",
      "     |\n",
      "     |      If ``model.etag`` is not ``None``, the update will only succeed if\n",
      "     |      the model on the server has the same ETag. Thus reading a model with\n",
      "     |      ``get_model``, changing its fields, and then passing it to\n",
      "     |      ``update_model`` will ensure that the changes will only be saved if\n",
      "     |      no modifications to the model occurred since the read.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          model (google.cloud.bigquery.model.Model): The model to update.\n",
      "     |          fields (Sequence[str]):\n",
      "     |              The properties of ``model`` to change. These are strings\n",
      "     |              corresponding to the properties of\n",
      "     |              :class:`~google.cloud.bigquery.model.Model`.\n",
      "     |\n",
      "     |              For example, to update the descriptive properties of the model,\n",
      "     |              specify them in the ``fields`` argument:\n",
      "     |\n",
      "     |              .. code-block:: python\n",
      "     |\n",
      "     |                  bigquery_client.update_model(\n",
      "     |                      model, [\"description\", \"friendly_name\"]\n",
      "     |                  )\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              A description of how to retry the API call.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.model.Model:\n",
      "     |              The model resource returned from the API call.\n",
      "     |\n",
      "     |  update_routine(self, routine: google.cloud.bigquery.routine.routine.Routine, fields: Sequence[str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.routine.routine.Routine\n",
      "     |      [Beta] Change some fields of a routine.\n",
      "     |\n",
      "     |      Use ``fields`` to specify which fields to update. At least one field\n",
      "     |      must be provided. If a field is listed in ``fields`` and is ``None``\n",
      "     |      in ``routine``, the field value will be deleted.\n",
      "     |\n",
      "     |      .. warning::\n",
      "     |         During beta, partial updates are not supported. You must provide\n",
      "     |         all fields in the resource.\n",
      "     |\n",
      "     |      If :attr:`~google.cloud.bigquery.routine.Routine.etag` is not\n",
      "     |      ``None``, the update will only succeed if the resource on the server\n",
      "     |      has the same ETag. Thus reading a routine with\n",
      "     |      :func:`~google.cloud.bigquery.client.Client.get_routine`, changing\n",
      "     |      its fields, and then passing it to this method will ensure that the\n",
      "     |      changes will only be saved if no modifications to the resource\n",
      "     |      occurred since the read.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          routine (google.cloud.bigquery.routine.Routine):\n",
      "     |              The routine to update.\n",
      "     |          fields (Sequence[str]):\n",
      "     |              The fields of ``routine`` to change, spelled as the\n",
      "     |              :class:`~google.cloud.bigquery.routine.Routine` properties.\n",
      "     |\n",
      "     |              For example, to update the description property of the routine,\n",
      "     |              specify it in the ``fields`` argument:\n",
      "     |\n",
      "     |              .. code-block:: python\n",
      "     |\n",
      "     |                  bigquery_client.update_routine(\n",
      "     |                      routine, [\"description\"]\n",
      "     |                  )\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              A description of how to retry the API call.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.Routine:\n",
      "     |              The routine resource returned from the API call.\n",
      "     |\n",
      "     |  update_table(self, table: google.cloud.bigquery.table.Table, fields: Sequence[str], retry: google.api_core.retry.retry_unary.Retry = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> google.cloud.bigquery.table.Table\n",
      "     |      Change some fields of a table.\n",
      "     |\n",
      "     |      Use ``fields`` to specify which fields to update. At least one field\n",
      "     |      must be provided. If a field is listed in ``fields`` and is ``None``\n",
      "     |      in ``table``, the field value will be deleted.\n",
      "     |\n",
      "     |      If ``table.etag`` is not ``None``, the update will only succeed if\n",
      "     |      the table on the server has the same ETag. Thus reading a table with\n",
      "     |      ``get_table``, changing its fields, and then passing it to\n",
      "     |      ``update_table`` will ensure that the changes will only be saved if\n",
      "     |      no modifications to the table occurred since the read.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table (google.cloud.bigquery.table.Table): The table to update.\n",
      "     |          fields (Sequence[str]):\n",
      "     |              The fields of ``table`` to change, spelled as the\n",
      "     |              :class:`~google.cloud.bigquery.table.Table` properties.\n",
      "     |\n",
      "     |              For example, to update the descriptive properties of the table,\n",
      "     |              specify them in the ``fields`` argument:\n",
      "     |\n",
      "     |              .. code-block:: python\n",
      "     |\n",
      "     |                  bigquery_client.update_table(\n",
      "     |                      table,\n",
      "     |                      [\"description\", \"friendly_name\"]\n",
      "     |                  )\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              A description of how to retry the API call.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.Table:\n",
      "     |              The table resource returned from the API call.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  location\n",
      "     |      Default location for jobs / datasets / tables.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  default_load_job_config\n",
      "     |      Default ``LoadJobConfig``.\n",
      "     |      Will be merged into job configs passed into the ``load_table_*`` methods.\n",
      "     |\n",
      "     |  default_query_job_config\n",
      "     |      Default ``QueryJobConfig`` or ``None``.\n",
      "     |\n",
      "     |      Will be merged into job configs passed into the ``query`` or\n",
      "     |      ``query_and_wait`` methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  SCOPE = ('https://www.googleapis.com/auth/cloud-platform',)\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.client.Client:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Explicitly state that clients are not pickleable.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google.cloud.client._ClientFactoryMixin:\n",
      "     |\n",
      "     |  from_service_account_info(info, *args, **kwargs) from builtins.type\n",
      "     |      Factory to retrieve JSON credentials while creating client.\n",
      "     |\n",
      "     |      :type info: dict\n",
      "     |      :param info:\n",
      "     |          The JSON object with a private key and other credentials\n",
      "     |          information (downloaded from the Google APIs console).\n",
      "     |\n",
      "     |      :type args: tuple\n",
      "     |      :param args: Remaining positional arguments to pass to constructor.\n",
      "     |\n",
      "     |      :param kwargs: Remaining keyword arguments to pass to constructor.\n",
      "     |\n",
      "     |      :rtype: :class:`_ClientFactoryMixin`\n",
      "     |      :returns: The client created with the retrieved JSON credentials.\n",
      "     |      :raises TypeError: if there is a conflict with the kwargs\n",
      "     |               and the credentials created by the factory.\n",
      "     |\n",
      "     |  from_service_account_json(json_credentials_path, *args, **kwargs) from builtins.type\n",
      "     |      Factory to retrieve JSON credentials while creating client.\n",
      "     |\n",
      "     |      :type json_credentials_path: str\n",
      "     |      :param json_credentials_path: The path to a private key file (this file\n",
      "     |                                    was given to you when you created the\n",
      "     |                                    service account). This file must contain\n",
      "     |                                    a JSON object with a private key and\n",
      "     |                                    other credentials information (downloaded\n",
      "     |                                    from the Google APIs console).\n",
      "     |\n",
      "     |      :type args: tuple\n",
      "     |      :param args: Remaining positional arguments to pass to constructor.\n",
      "     |\n",
      "     |      :param kwargs: Remaining keyword arguments to pass to constructor.\n",
      "     |\n",
      "     |      :rtype: :class:`_ClientFactoryMixin`\n",
      "     |      :returns: The client created with the retrieved JSON credentials.\n",
      "     |      :raises TypeError: if there is a conflict with the kwargs\n",
      "     |               and the credentials created by the factory.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.cloud.client._ClientFactoryMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class CloneDefinition(builtins.object)\n",
      "     |  CloneDefinition(resource: Dict[str, Any])\n",
      "     |\n",
      "     |  Information about base table and clone time of the clone.\n",
      "     |\n",
      "     |  See https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#clonedefinition\n",
      "     |\n",
      "     |  Args:\n",
      "     |      resource: Clone definition representation returned from the API.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, resource: Dict[str, Any])\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class Compression(builtins.object)\n",
      "     |  The compression type to use for exported files. The default value is\n",
      "     |  :attr:`NONE`.\n",
      "     |\n",
      "     |  :attr:`DEFLATE` and :attr:`SNAPPY` are\n",
      "     |  only supported for Avro.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  DEFLATE = 'DEFLATE'\n",
      "     |\n",
      "     |  GZIP = 'GZIP'\n",
      "     |\n",
      "     |  NONE = 'NONE'\n",
      "     |\n",
      "     |  SNAPPY = 'SNAPPY'\n",
      "\n",
      "    class ConnectionProperty(builtins.object)\n",
      "     |  ConnectionProperty(key: str = '', value: str = '')\n",
      "     |\n",
      "     |  A connection-level property to customize query behavior.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/ConnectionProperty\n",
      "     |\n",
      "     |  Args:\n",
      "     |      key:\n",
      "     |          The key of the property to set, for example, ``'time_zone'`` or\n",
      "     |          ``'session_id'``.\n",
      "     |      value: The value of the property to set.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, key: str = '', value: str = '')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> Dict[str, Any]\n",
      "     |      Construct JSON API representation for the connection property.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource) -> 'ConnectionProperty' from builtins.type\n",
      "     |      Construct :class:`~google.cloud.bigquery.query.ConnectionProperty`\n",
      "     |      from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource: JSON representation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          A connection property.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  key\n",
      "     |      Name of the property.\n",
      "     |\n",
      "     |      For example:\n",
      "     |\n",
      "     |      * ``time_zone``\n",
      "     |      * ``session_id``\n",
      "     |\n",
      "     |  value\n",
      "     |      Value of the property.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class CopyJob(google.cloud.bigquery.job.base._AsyncJob)\n",
      "     |  CopyJob(job_id, sources, destination, client, job_config=None)\n",
      "     |\n",
      "     |  Asynchronous job: copy data into a table from other tables.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      job_id (str): the job's ID, within the project belonging to ``client``.\n",
      "     |\n",
      "     |      sources (List[google.cloud.bigquery.table.TableReference]): Table from which data is to be loaded.\n",
      "     |\n",
      "     |      destination (google.cloud.bigquery.table.TableReference): Table into which data is to be loaded.\n",
      "     |\n",
      "     |      client (google.cloud.bigquery.client.Client):\n",
      "     |          A client which holds credentials and project configuration\n",
      "     |          for the dataset (which requires a project).\n",
      "     |\n",
      "     |      job_config (Optional[google.cloud.bigquery.job.CopyJobConfig]):\n",
      "     |          Extra configuration options for the copy job.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CopyJob\n",
      "     |      google.cloud.bigquery.job.base._AsyncJob\n",
      "     |      google.api_core.future.polling.PollingFuture\n",
      "     |      google.api_core.future.base.Future\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, job_id, sources, destination, client, job_config=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Generate a resource for :meth:`_begin`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource, client) from abc.ABCMeta\n",
      "     |      Factory: construct a job given its API representation\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         This method assumes that the project found in the resource matches\n",
      "     |         the client's project.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): dataset job representation returned from the API\n",
      "     |          client (google.cloud.bigquery.client.Client):\n",
      "     |              Client which holds credentials and project\n",
      "     |              configuration for the dataset.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.CopyJob: Job parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  configuration\n",
      "     |      The configuration for this copy job.\n",
      "     |\n",
      "     |  create_disposition\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.CopyJobConfig.create_disposition`.\n",
      "     |\n",
      "     |  destination\n",
      "     |      google.cloud.bigquery.table.TableReference: Table into which data\n",
      "     |      is to be loaded.\n",
      "     |\n",
      "     |  destination_encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for the destination table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.CopyJobConfig.destination_encryption_configuration`.\n",
      "     |\n",
      "     |  sources\n",
      "     |      List[google.cloud.bigquery.table.TableReference]): Table(s) from\n",
      "     |      which data is to be loaded.\n",
      "     |\n",
      "     |  write_disposition\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.CopyJobConfig.write_disposition`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  cancel(self, client=None, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  cancel job via a POST request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating that the cancel request was sent.\n",
      "     |\n",
      "     |  cancelled(self)\n",
      "     |      Check if the job has been cancelled.\n",
      "     |\n",
      "     |      This always returns False. It's not possible to check if a job was\n",
      "     |      cancelled in the API. This method is here to satisfy the interface\n",
      "     |      for :class:`google.api_core.future.Future`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: False\n",
      "     |\n",
      "     |  done(self, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, reload: bool = True) -> bool\n",
      "     |      Checks if the job is complete.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          reload (Optional[bool]):\n",
      "     |              If ``True``, make an API call to refresh the job state of\n",
      "     |              unfinished jobs before checking. Default ``True``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: True if the job is complete, False otherwise.\n",
      "     |\n",
      "     |  exists(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  test for the existence of the job via a GET request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating existence of the job.\n",
      "     |\n",
      "     |  reload(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None)\n",
      "     |      API call:  refresh job properties via a GET request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |  result(self, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> '_AsyncJob'\n",
      "     |      Start the job and wait for it to complete and get the result.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          _AsyncJob: This instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.GoogleAPICallError:\n",
      "     |              if the job failed.\n",
      "     |          concurrent.futures.TimeoutError:\n",
      "     |              if the job did not complete in the given timeout.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  created\n",
      "     |      Datetime at which the job was created.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the creation time (None until set from the server).\n",
      "     |\n",
      "     |  ended\n",
      "     |      Datetime at which the job finished.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the end time (None until set from the server).\n",
      "     |\n",
      "     |  error_result\n",
      "     |      Error information about the job as a whole.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[Mapping]: the error information (None until set from the server).\n",
      "     |\n",
      "     |  errors\n",
      "     |      Information about individual errors generated by the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[List[Mapping]]:\n",
      "     |              the error information (None until set from the server).\n",
      "     |\n",
      "     |  etag\n",
      "     |      ETag for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the ETag (None until set from the server).\n",
      "     |\n",
      "     |  job_id\n",
      "     |      str: ID of the job.\n",
      "     |\n",
      "     |  job_type\n",
      "     |      Type of job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: one of 'load', 'copy', 'extract', 'query'.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |  location\n",
      "     |      str: Location where the job runs.\n",
      "     |\n",
      "     |  num_child_jobs\n",
      "     |      The number of child jobs executed.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.num_child_jobs\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          int\n",
      "     |\n",
      "     |  parent_job_id\n",
      "     |      Return the ID of the parent job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.parent_job_id\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: parent job id.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the job's APIs.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the path based on project and job ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the project (derived from the client).\n",
      "     |\n",
      "     |  reservation_usage\n",
      "     |      Job resource usage breakdown by reservation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[google.cloud.bigquery.job.ReservationUsage]:\n",
      "     |              Reservation usage stats. Can be empty if not set from the server.\n",
      "     |\n",
      "     |  script_statistics\n",
      "     |      Statistics for a child job of a script.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      URL for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  session_info\n",
      "     |      [Preview] Information of the session if this job is part of one.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  started\n",
      "     |      Datetime at which the job was started.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the start time (None until set from the server).\n",
      "     |\n",
      "     |  state\n",
      "     |      Status of the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]:\n",
      "     |              the state (None until set from the server).\n",
      "     |\n",
      "     |  transaction_info\n",
      "     |      Information of the multi-statement transaction if this job is part of one.\n",
      "     |\n",
      "     |      Since a scripting query job can execute multiple transactions, this\n",
      "     |      property is only expected on child jobs. Use the\n",
      "     |      :meth:`google.cloud.bigquery.client.Client.list_jobs` method with the\n",
      "     |      ``parent_job`` parameter to iterate over child jobs.\n",
      "     |\n",
      "     |      .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  user_email\n",
      "     |      E-mail address of user who submitted the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.api_core.future.polling.PollingFuture:\n",
      "     |\n",
      "     |  add_done_callback(self, fn)\n",
      "     |      Add a callback to be executed when the operation is complete.\n",
      "     |\n",
      "     |      If the operation is not already complete, this will start a helper\n",
      "     |      thread to poll for the status of the operation in the background.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          fn (Callable[Future]): The callback to execute when the operation\n",
      "     |              is complete.\n",
      "     |\n",
      "     |  exception(self, timeout=<object object at 0x7202a04c6650>)\n",
      "     |      Get the exception from the operation, blocking if necessary.\n",
      "     |\n",
      "     |      See the documentation for the :meth:`result` method for details on how\n",
      "     |      this method operates, as both ``result`` and this method rely on the\n",
      "     |      exact same polling logic. The only difference is that this method does\n",
      "     |      not accept ``retry`` and ``polling`` arguments but relies on the default ones\n",
      "     |      instead.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          timeout (int): How long to wait for the operation to complete.\n",
      "     |          If None, wait indefinitely.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[google.api_core.GoogleAPICallError]: The operation's\n",
      "     |              error.\n",
      "     |\n",
      "     |  running(self)\n",
      "     |      True if the operation is currently running.\n",
      "     |\n",
      "     |  set_exception(self, exception)\n",
      "     |      Set the Future's exception.\n",
      "     |\n",
      "     |  set_result(self, result)\n",
      "     |      Set the Future's result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.api_core.future.base.Future:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class CopyJobConfig(google.cloud.bigquery.job.base._JobConfig)\n",
      "     |  CopyJobConfig(**kwargs) -> None\n",
      "     |\n",
      "     |  Configuration options for copy jobs.\n",
      "     |\n",
      "     |  All properties in this class are optional. Values which are :data:`None` ->\n",
      "     |  server defaults. Set properties on the constructed configuration by using\n",
      "     |  the property name as the name of a keyword argument.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      CopyJobConfig\n",
      "     |      google.cloud.bigquery.job.base._JobConfig\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, **kwargs) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  create_disposition\n",
      "     |      google.cloud.bigquery.job.CreateDisposition: Specifies behavior\n",
      "     |      for creating tables.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationTableCopy.FIELDS.create_disposition\n",
      "     |\n",
      "     |  destination_encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for the destination table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationTableCopy.FIELDS.destination_encryption_configuration\n",
      "     |\n",
      "     |  destination_expiration_time\n",
      "     |      google.cloud.bigquery.job.DestinationExpirationTime: The time when the\n",
      "     |      destination table expires. Expired tables will be deleted and their storage reclaimed.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationTableCopy.FIELDS.destination_expiration_time\n",
      "     |\n",
      "     |  operation_type\n",
      "     |      The operation to perform with this copy job.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationTableCopy.FIELDS.operation_type\n",
      "     |\n",
      "     |  write_disposition\n",
      "     |      google.cloud.bigquery.job.WriteDisposition: Action that occurs if\n",
      "     |      the destination table already exists.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationTableCopy.FIELDS.write_disposition\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Override to be able to raise error if an unknown property is being set\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of the job config.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> '_JobConfig' from builtins.type\n",
      "     |      Factory: construct a job configuration given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict):\n",
      "     |              A job configuration in the same representation as is returned\n",
      "     |              from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job._JobConfig: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  job_timeout_ms\n",
      "     |      Optional parameter. Job timeout in milliseconds. If this time limit is exceeded, BigQuery might attempt to stop the job.\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfiguration.FIELDS.job_timeout_ms\n",
      "     |      e.g.\n",
      "     |\n",
      "     |          job_config = bigquery.QueryJobConfig( job_timeout_ms = 5000 )\n",
      "     |          or\n",
      "     |          job_config.job_timeout_ms = 5000\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |      This method always returns a dict. Once a job has been created on the\n",
      "     |      server, its labels cannot be modified anymore.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "\n",
      "    class CreateDisposition(builtins.object)\n",
      "     |  Specifies whether the job is allowed to create new tables. The default\n",
      "     |  value is :attr:`CREATE_IF_NEEDED`.\n",
      "     |\n",
      "     |  Creation, truncation and append actions occur as one atomic update\n",
      "     |  upon job completion.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  CREATE_IF_NEEDED = 'CREATE_IF_NEEDED'\n",
      "     |\n",
      "     |  CREATE_NEVER = 'CREATE_NEVER'\n",
      "\n",
      "    class Dataset(builtins.object)\n",
      "     |  Dataset(dataset_ref) -> None\n",
      "     |\n",
      "     |  Datasets are containers for tables.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#resource-dataset\n",
      "     |\n",
      "     |  Args:\n",
      "     |      dataset_ref (Union[google.cloud.bigquery.dataset.DatasetReference, str]):\n",
      "     |          A pointer to a dataset. If ``dataset_ref`` is a string, it must\n",
      "     |          include both the project ID and the dataset ID, separated by\n",
      "     |          ``.``.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, dataset_ref) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  model = _get_model_reference(self, model_id)\n",
      "     |      Constructs a ModelReference.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          model_id (str): the ID of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.model.ModelReference:\n",
      "     |              A ModelReference for a model in this dataset.\n",
      "     |\n",
      "     |  routine = _get_routine_reference(self, routine_id)\n",
      "     |      Constructs a RoutineReference.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          routine_id (str): the ID of the routine.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.RoutineReference:\n",
      "     |              A RoutineReference for a routine in this dataset.\n",
      "     |\n",
      "     |  table = _get_table_reference(self, table_id: str) -> google.cloud.bigquery.table.TableReference\n",
      "     |      Constructs a TableReference.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table_id (str): The ID of the table.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.TableReference:\n",
      "     |              A table reference for a table in this dataset.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this dataset\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: The dataset represented as an API resource\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'Dataset' from builtins.type\n",
      "     |      Factory: construct a dataset given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str: object]):\n",
      "     |              Dataset resource representation returned from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.Dataset:\n",
      "     |              Dataset parsed from ``resource``.\n",
      "     |\n",
      "     |  from_string(full_dataset_id: str) -> 'Dataset' from builtins.type\n",
      "     |      Construct a dataset from fully-qualified dataset ID.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          full_dataset_id (str):\n",
      "     |              A fully-qualified dataset ID in standard SQL format. Must\n",
      "     |              include both the project ID and the dataset ID, separated by\n",
      "     |              ``.``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dataset: Dataset parsed from ``full_dataset_id``.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |          >>> Dataset.from_string('my-project-id.some_dataset')\n",
      "     |          Dataset(DatasetReference('my-project-id', 'some_dataset'))\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``full_dataset_id`` is not a fully-qualified dataset ID in\n",
      "     |              standard SQL format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  created\n",
      "     |      Union[datetime.datetime, None]: Datetime at which the dataset was\n",
      "     |      created (:data:`None` until set from the server).\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      str: Dataset ID.\n",
      "     |\n",
      "     |  etag\n",
      "     |      Union[str, None]: ETag for the dataset resource (:data:`None` until\n",
      "     |      set from the server).\n",
      "     |\n",
      "     |  full_dataset_id\n",
      "     |      Union[str, None]: ID for the dataset resource (:data:`None` until\n",
      "     |      set from the server)\n",
      "     |\n",
      "     |      In the format ``project_id:dataset_id``.\n",
      "     |\n",
      "     |  modified\n",
      "     |      Union[datetime.datetime, None]: Datetime at which the dataset was\n",
      "     |      last modified (:data:`None` until set from the server).\n",
      "     |\n",
      "     |  path\n",
      "     |      str: URL path for the dataset based on project and dataset ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      str: Project ID of the project bound to the dataset.\n",
      "     |\n",
      "     |  reference\n",
      "     |      google.cloud.bigquery.dataset.DatasetReference: A reference to this\n",
      "     |      dataset.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      Union[str, None]: URL for the dataset resource (:data:`None` until\n",
      "     |      set from the server).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  access_entries\n",
      "     |      List[google.cloud.bigquery.dataset.AccessEntry]: Dataset's access\n",
      "     |      entries.\n",
      "     |\n",
      "     |      ``role`` augments the entity type and must be present **unless** the\n",
      "     |      entity type is ``view`` or ``routine``.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          TypeError: If 'value' is not a sequence\n",
      "     |          ValueError:\n",
      "     |              If any item in the sequence is not an\n",
      "     |              :class:`~google.cloud.bigquery.dataset.AccessEntry`.\n",
      "     |\n",
      "     |  default_encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for all tables in the dataset.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See `protecting data with Cloud KMS keys\n",
      "     |      <https://cloud.google.com/bigquery/docs/customer-managed-encryption>`_\n",
      "     |      in the BigQuery documentation.\n",
      "     |\n",
      "     |  default_partition_expiration_ms\n",
      "     |      Optional[int]: The default partition expiration for all\n",
      "     |      partitioned tables in the dataset, in milliseconds.\n",
      "     |\n",
      "     |      Once this property is set, all newly-created partitioned tables in\n",
      "     |      the dataset will have an ``time_paritioning.expiration_ms`` property\n",
      "     |      set to this value, and changing the value will only affect new\n",
      "     |      tables, not existing ones. The storage in a partition will have an\n",
      "     |      expiration time of its partition time plus this value.\n",
      "     |\n",
      "     |      Setting this property overrides the use of\n",
      "     |      ``default_table_expiration_ms`` for partitioned tables: only one of\n",
      "     |      ``default_table_expiration_ms`` and\n",
      "     |      ``default_partition_expiration_ms`` will be used for any new\n",
      "     |      partitioned table. If you provide an explicit\n",
      "     |      ``time_partitioning.expiration_ms`` when creating or updating a\n",
      "     |      partitioned table, that value takes precedence over the default\n",
      "     |      partition expiration time indicated by this property.\n",
      "     |\n",
      "     |  default_rounding_mode\n",
      "     |      Union[str, None]: defaultRoundingMode of the dataset as set by the user\n",
      "     |      (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Set the value to one of ``'ROUND_HALF_AWAY_FROM_ZERO'``, ``'ROUND_HALF_EVEN'``, or\n",
      "     |      ``'ROUNDING_MODE_UNSPECIFIED'``.\n",
      "     |\n",
      "     |      See `default rounding mode\n",
      "     |      <https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#Dataset.FIELDS.default_rounding_mode>`_\n",
      "     |      in REST API docs and `updating the default rounding model\n",
      "     |      <https://cloud.google.com/bigquery/docs/updating-datasets#update_rounding_mode>`_\n",
      "     |      guide.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  default_table_expiration_ms\n",
      "     |      Union[int, None]: Default expiration time for tables in the dataset\n",
      "     |      (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  description\n",
      "     |      Optional[str]: Description of the dataset as set by the user\n",
      "     |      (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  friendly_name\n",
      "     |      Union[str, None]: Title of the dataset as set by the user\n",
      "     |      (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  is_case_insensitive\n",
      "     |      Optional[bool]: True if the dataset and its table names are case-insensitive, otherwise False.\n",
      "     |      By default, this is False, which means the dataset and its table names are case-sensitive.\n",
      "     |      This field does not affect routine references.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the dataset.\n",
      "     |\n",
      "     |      This method always returns a dict. To change a dataset's labels,\n",
      "     |      modify the dict, then call\n",
      "     |      :meth:`google.cloud.bigquery.client.Client.update_dataset`. To delete\n",
      "     |      a label, set its value to :data:`None` before updating.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  location\n",
      "     |      Union[str, None]: Location in which the dataset is hosted as set by\n",
      "     |      the user (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  max_time_travel_hours\n",
      "     |      Optional[int]: Defines the time travel window in hours. The value can\n",
      "     |      be from 48 to 168 hours (2 to 7 days), and in multiple of 24 hours\n",
      "     |      (48, 72, 96, 120, 144, 168).\n",
      "     |      The default value is 168 hours if this is not set.\n",
      "     |\n",
      "     |  storage_billing_model\n",
      "     |      Union[str, None]: StorageBillingModel of the dataset as set by the user\n",
      "     |      (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Set the value to one of ``'LOGICAL'``, ``'PHYSICAL'``, or\n",
      "     |      ``'STORAGE_BILLING_MODEL_UNSPECIFIED'``. This change takes 24 hours to\n",
      "     |      take effect and you must wait 14 days before you can change the storage\n",
      "     |      billing model again.\n",
      "     |\n",
      "     |      See `storage billing model\n",
      "     |      <https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#Dataset.FIELDS.storage_billing_model>`_\n",
      "     |      in REST API docs and `updating the storage billing model\n",
      "     |      <https://cloud.google.com/bigquery/docs/updating-datasets#update_storage_billing_models>`_\n",
      "     |      guide.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "\n",
      "    class DatasetReference(builtins.object)\n",
      "     |  DatasetReference(project, dataset_id)\n",
      "     |\n",
      "     |  DatasetReferences are pointers to datasets.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets#datasetreference\n",
      "     |\n",
      "     |  Args:\n",
      "     |      project (str): The ID of the project\n",
      "     |      dataset_id (str): The ID of the dataset\n",
      "     |\n",
      "     |  Raises:\n",
      "     |      ValueError: If either argument is not of type ``str``.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self, project, dataset_id)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  model = _get_model_reference(self, model_id)\n",
      "     |      Constructs a ModelReference.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          model_id (str): the ID of the model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.model.ModelReference:\n",
      "     |              A ModelReference for a model in this dataset.\n",
      "     |\n",
      "     |  routine = _get_routine_reference(self, routine_id)\n",
      "     |      Constructs a RoutineReference.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          routine_id (str): the ID of the routine.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.RoutineReference:\n",
      "     |              A RoutineReference for a routine in this dataset.\n",
      "     |\n",
      "     |  table = _get_table_reference(self, table_id: str) -> google.cloud.bigquery.table.TableReference\n",
      "     |      Constructs a TableReference.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table_id (str): The ID of the table.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.TableReference:\n",
      "     |              A table reference for a table in this dataset.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this dataset reference\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, str]: dataset reference represented as an API resource\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'DatasetReference' from builtins.type\n",
      "     |      Factory: construct a dataset reference given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, str]):\n",
      "     |              Dataset reference resource representation returned from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.dataset.DatasetReference:\n",
      "     |              Dataset reference parsed from ``resource``.\n",
      "     |\n",
      "     |  from_string(dataset_id: str, default_project: Optional[str] = None) -> 'DatasetReference' from builtins.type\n",
      "     |      Construct a dataset reference from dataset ID string.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          dataset_id (str):\n",
      "     |              A dataset ID in standard SQL format. If ``default_project``\n",
      "     |              is not specified, this must include both the project ID and\n",
      "     |              the dataset ID, separated by ``.``.\n",
      "     |          default_project (Optional[str]):\n",
      "     |              The project ID to use when ``dataset_id`` does not include a\n",
      "     |              project ID.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          DatasetReference:\n",
      "     |              Dataset reference parsed from ``dataset_id``.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |          >>> DatasetReference.from_string('my-project-id.some_dataset')\n",
      "     |          DatasetReference('my-project-id', 'some_dataset')\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``dataset_id`` is not a fully-qualified dataset ID in\n",
      "     |              standard SQL format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      str: Dataset ID.\n",
      "     |\n",
      "     |  path\n",
      "     |      str: URL path for the dataset based on project and dataset ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      str: Project ID of the dataset.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class DecimalTargetType(builtins.object)\n",
      "     |  The data types that could be used as a target type when converting decimal values.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#DecimalTargetType\n",
      "     |\n",
      "     |  .. versionadded:: 2.21.0\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  BIGNUMERIC = 'BIGNUMERIC'\n",
      "     |\n",
      "     |  NUMERIC = 'NUMERIC'\n",
      "     |\n",
      "     |  STRING = 'STRING'\n",
      "\n",
      "    class DestinationFormat(builtins.object)\n",
      "     |  The exported file format. The default value is :attr:`CSV`.\n",
      "     |\n",
      "     |  Tables with nested or repeated fields cannot be exported as CSV.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  AVRO = 'AVRO'\n",
      "     |\n",
      "     |  CSV = 'CSV'\n",
      "     |\n",
      "     |  NEWLINE_DELIMITED_JSON = 'NEWLINE_DELIMITED_JSON'\n",
      "     |\n",
      "     |  PARQUET = 'PARQUET'\n",
      "\n",
      "    class DeterminismLevel(builtins.object)\n",
      "     |  Specifies determinism level for JavaScript user-defined functions (UDFs).\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#DeterminismLevel\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  DETERMINISM_LEVEL_UNSPECIFIED = 'DETERMINISM_LEVEL_UNSPECIFIED'\n",
      "     |\n",
      "     |  DETERMINISTIC = 'DETERMINISTIC'\n",
      "     |\n",
      "     |  NOT_DETERMINISTIC = 'NOT_DETERMINISTIC'\n",
      "\n",
      "    class DmlStats(builtins.tuple)\n",
      "     |  DmlStats(inserted_row_count: int = 0, deleted_row_count: int = 0, updated_row_count: int = 0)\n",
      "     |\n",
      "     |  Detailed statistics for DML statements.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/DmlStats\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      DmlStats\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |\n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |\n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new DmlStats object replacing specified fields with new values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new DmlStats object from a sequence or iterable\n",
      "     |\n",
      "     |  from_api_repr(stats: Dict[str, str]) -> 'DmlStats' from builtins.type\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(_cls, inserted_row_count: int = 0, deleted_row_count: int = 0, updated_row_count: int = 0)\n",
      "     |      Create new instance of DmlStats(inserted_row_count, deleted_row_count, updated_row_count)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  inserted_row_count\n",
      "     |      Alias for field number 0\n",
      "     |\n",
      "     |  deleted_row_count\n",
      "     |      Alias for field number 1\n",
      "     |\n",
      "     |  updated_row_count\n",
      "     |      Alias for field number 2\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'deleted_row_count': <class 'int'>, 'inserted_row_c...\n",
      "     |\n",
      "     |  __match_args__ = ('inserted_row_count', 'deleted_row_count', 'updated_...\n",
      "     |\n",
      "     |  __orig_bases__ = (<function NamedTuple>,)\n",
      "     |\n",
      "     |  _field_defaults = {'deleted_row_count': 0, 'inserted_row_count': 0, 'u...\n",
      "     |\n",
      "     |  _fields = ('inserted_row_count', 'deleted_row_count', 'updated_row_cou...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |\n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return bool(key in self).\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |\n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |\n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |\n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |\n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "\n",
      "    class Encoding(builtins.object)\n",
      "     |  The character encoding of the data. The default is :attr:`UTF_8`.\n",
      "     |\n",
      "     |  BigQuery decodes the data after the raw, binary data has been\n",
      "     |  split using the values of the quote and fieldDelimiter properties.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  ISO_8859_1 = 'ISO-8859-1'\n",
      "     |\n",
      "     |  UTF_8 = 'UTF-8'\n",
      "\n",
      "    class EncryptionConfiguration(builtins.object)\n",
      "     |  EncryptionConfiguration(kms_key_name=None) -> None\n",
      "     |\n",
      "     |  Custom encryption configuration (e.g., Cloud KMS keys).\n",
      "     |\n",
      "     |  Args:\n",
      "     |      kms_key_name (str): resource ID of Cloud KMS key used for encryption\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self, kms_key_name=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Construct the API resource representation of this encryption\n",
      "     |      configuration.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]:\n",
      "     |              Encryption configuration as represented as an API resource\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource) from builtins.type\n",
      "     |      Construct an encryption configuration from its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]):\n",
      "     |              An encryption configuration representation as returned from\n",
      "     |              the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.EncryptionConfiguration:\n",
      "     |              An encryption configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  kms_key_name\n",
      "     |      str: Resource ID of Cloud KMS key\n",
      "     |\n",
      "     |      Resource ID of Cloud KMS key or :data:`None` if using default\n",
      "     |      encryption.\n",
      "\n",
      "    class ExternalConfig(builtins.object)\n",
      "     |  ExternalConfig(source_format) -> None\n",
      "     |\n",
      "     |  Description of an external data source.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      source_format (ExternalSourceFormat):\n",
      "     |          See :attr:`source_format`.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, source_format) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]:\n",
      "     |              A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'ExternalConfig' from builtins.type\n",
      "     |      Factory: construct an :class:`~.external_config.ExternalConfig`\n",
      "     |      instance given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of an :class:`~.external_config.ExternalConfig`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          ExternalConfig: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  options\n",
      "     |      Source-specific options.\n",
      "     |\n",
      "     |  source_format\n",
      "     |      :class:`~.external_config.ExternalSourceFormat`:\n",
      "     |      Format of external source.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.source_format\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  autodetect\n",
      "     |      bool: If :data:`True`, try to detect schema and format options\n",
      "     |      automatically.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.autodetect\n",
      "     |\n",
      "     |  avro_options\n",
      "     |      Additional properties to set if ``sourceFormat`` is set to AVRO.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.avro_options\n",
      "     |\n",
      "     |  bigtable_options\n",
      "     |      Additional properties to set if ``sourceFormat`` is set to BIGTABLE.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.bigtable_options\n",
      "     |\n",
      "     |  compression\n",
      "     |      str: The compression type of the data source.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.compression\n",
      "     |\n",
      "     |  connection_id\n",
      "     |      Optional[str]: [Experimental] ID of a BigQuery Connection API\n",
      "     |      resource.\n",
      "     |\n",
      "     |      .. WARNING::\n",
      "     |\n",
      "     |         This feature is experimental. Pre-GA features may have limited\n",
      "     |         support, and changes to pre-GA features may not be compatible with\n",
      "     |         other pre-GA versions.\n",
      "     |\n",
      "     |  csv_options\n",
      "     |      Additional properties to set if ``sourceFormat`` is set to CSV.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.csv_options\n",
      "     |\n",
      "     |  decimal_target_types\n",
      "     |      Possible SQL data types to which the source decimal values are converted.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.decimal_target_types\n",
      "     |\n",
      "     |      .. versionadded:: 2.21.0\n",
      "     |\n",
      "     |  google_sheets_options\n",
      "     |      Additional properties to set if ``sourceFormat`` is set to\n",
      "     |      GOOGLE_SHEETS.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.google_sheets_options\n",
      "     |\n",
      "     |  hive_partitioning\n",
      "     |      Optional[:class:`~.external_config.HivePartitioningOptions`]: [Beta] When set,         it configures hive partitioning support.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          **Experimental**. This feature is experimental and might change or\n",
      "     |          have limited support.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.hive_partitioning_options\n",
      "     |\n",
      "     |  ignore_unknown_values\n",
      "     |      bool: If :data:`True`, extra values that are not represented in the\n",
      "     |      table schema are ignored. Defaults to :data:`False`.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.ignore_unknown_values\n",
      "     |\n",
      "     |  max_bad_records\n",
      "     |      int: The maximum number of bad records that BigQuery can ignore when\n",
      "     |      reading data.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.max_bad_records\n",
      "     |\n",
      "     |  parquet_options\n",
      "     |      Additional properties to set if ``sourceFormat`` is set to PARQUET.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.parquet_options\n",
      "     |\n",
      "     |  reference_file_schema_uri\n",
      "     |      Optional[str]:\n",
      "     |      When creating an external table, the user can provide a reference file with the\n",
      "     |      table schema. This is enabled for the following formats:\n",
      "     |\n",
      "     |      AVRO, PARQUET, ORC\n",
      "     |\n",
      "     |  schema\n",
      "     |      List[:class:`~google.cloud.bigquery.schema.SchemaField`]: The schema\n",
      "     |      for the data.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.schema\n",
      "     |\n",
      "     |  source_uris\n",
      "     |      List[str]: URIs that point to your data in Google Cloud.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ExternalDataConfiguration.FIELDS.source_uris\n",
      "\n",
      "    class ExternalSourceFormat(builtins.object)\n",
      "     |  The format for external data files.\n",
      "     |\n",
      "     |  Note that the set of allowed values for external data sources is different\n",
      "     |  than the set used for loading data (see\n",
      "     |  :class:`~google.cloud.bigquery.job.SourceFormat`).\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  AVRO = 'AVRO'\n",
      "     |\n",
      "     |  BIGTABLE = 'BIGTABLE'\n",
      "     |\n",
      "     |  CSV = 'CSV'\n",
      "     |\n",
      "     |  DATASTORE_BACKUP = 'DATASTORE_BACKUP'\n",
      "     |\n",
      "     |  GOOGLE_SHEETS = 'GOOGLE_SHEETS'\n",
      "     |\n",
      "     |  NEWLINE_DELIMITED_JSON = 'NEWLINE_DELIMITED_JSON'\n",
      "     |\n",
      "     |  ORC = 'ORC'\n",
      "     |\n",
      "     |  PARQUET = 'PARQUET'\n",
      "\n",
      "    class ExtractJob(google.cloud.bigquery.job.base._AsyncJob)\n",
      "     |  ExtractJob(job_id, source, destination_uris, client, job_config=None)\n",
      "     |\n",
      "     |  Asynchronous job: extract data from a table into Cloud Storage.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      job_id (str): the job's ID.\n",
      "     |\n",
      "     |      source (Union[             google.cloud.bigquery.table.TableReference,             google.cloud.bigquery.model.ModelReference         ]):\n",
      "     |          Table or Model from which data is to be loaded or extracted.\n",
      "     |\n",
      "     |      destination_uris (List[str]):\n",
      "     |          URIs describing where the extracted data will be written in Cloud\n",
      "     |          Storage, using the format ``gs://<bucket_name>/<object_name_or_glob>``.\n",
      "     |\n",
      "     |      client (google.cloud.bigquery.client.Client):\n",
      "     |          A client which holds credentials and project configuration.\n",
      "     |\n",
      "     |      job_config (Optional[google.cloud.bigquery.job.ExtractJobConfig]):\n",
      "     |          Extra configuration options for the extract job.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ExtractJob\n",
      "     |      google.cloud.bigquery.job.base._AsyncJob\n",
      "     |      google.api_core.future.polling.PollingFuture\n",
      "     |      google.api_core.future.base.Future\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, job_id, source, destination_uris, client, job_config=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Generate a resource for :meth:`_begin`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict, client) -> 'ExtractJob' from abc.ABCMeta\n",
      "     |      Factory:  construct a job given its API representation\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         This method assumes that the project found in the resource matches\n",
      "     |         the client's project.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): dataset job representation returned from the API\n",
      "     |\n",
      "     |          client (google.cloud.bigquery.client.Client):\n",
      "     |              Client which holds credentials and project\n",
      "     |              configuration for the dataset.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.ExtractJob: Job parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  compression\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.ExtractJobConfig.compression`.\n",
      "     |\n",
      "     |  configuration\n",
      "     |      The configuration for this extract job.\n",
      "     |\n",
      "     |  destination_format\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.ExtractJobConfig.destination_format`.\n",
      "     |\n",
      "     |  destination_uri_file_counts\n",
      "     |      Return file counts from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics4.FIELDS.destination_uri_file_counts\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[int]:\n",
      "     |              A list of integer counts, each representing the number of files\n",
      "     |              per destination URI or URI pattern specified in the extract\n",
      "     |              configuration. These values will be in the same order as the URIs\n",
      "     |              specified in the 'destinationUris' field.  Returns None if job is\n",
      "     |              not yet complete.\n",
      "     |\n",
      "     |  destination_uris\n",
      "     |      List[str]: URIs describing where the extracted data will be\n",
      "     |      written in Cloud Storage, using the format\n",
      "     |      ``gs://<bucket_name>/<object_name_or_glob>``.\n",
      "     |\n",
      "     |  field_delimiter\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.ExtractJobConfig.field_delimiter`.\n",
      "     |\n",
      "     |  print_header\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.ExtractJobConfig.print_header`.\n",
      "     |\n",
      "     |  source\n",
      "     |      Union[             google.cloud.bigquery.table.TableReference,             google.cloud.bigquery.model.ModelReference         ]: Table or Model from which data is to be loaded or extracted.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  cancel(self, client=None, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  cancel job via a POST request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating that the cancel request was sent.\n",
      "     |\n",
      "     |  cancelled(self)\n",
      "     |      Check if the job has been cancelled.\n",
      "     |\n",
      "     |      This always returns False. It's not possible to check if a job was\n",
      "     |      cancelled in the API. This method is here to satisfy the interface\n",
      "     |      for :class:`google.api_core.future.Future`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: False\n",
      "     |\n",
      "     |  done(self, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, reload: bool = True) -> bool\n",
      "     |      Checks if the job is complete.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          reload (Optional[bool]):\n",
      "     |              If ``True``, make an API call to refresh the job state of\n",
      "     |              unfinished jobs before checking. Default ``True``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: True if the job is complete, False otherwise.\n",
      "     |\n",
      "     |  exists(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  test for the existence of the job via a GET request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating existence of the job.\n",
      "     |\n",
      "     |  reload(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None)\n",
      "     |      API call:  refresh job properties via a GET request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |  result(self, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> '_AsyncJob'\n",
      "     |      Start the job and wait for it to complete and get the result.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          _AsyncJob: This instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.GoogleAPICallError:\n",
      "     |              if the job failed.\n",
      "     |          concurrent.futures.TimeoutError:\n",
      "     |              if the job did not complete in the given timeout.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  created\n",
      "     |      Datetime at which the job was created.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the creation time (None until set from the server).\n",
      "     |\n",
      "     |  ended\n",
      "     |      Datetime at which the job finished.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the end time (None until set from the server).\n",
      "     |\n",
      "     |  error_result\n",
      "     |      Error information about the job as a whole.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[Mapping]: the error information (None until set from the server).\n",
      "     |\n",
      "     |  errors\n",
      "     |      Information about individual errors generated by the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[List[Mapping]]:\n",
      "     |              the error information (None until set from the server).\n",
      "     |\n",
      "     |  etag\n",
      "     |      ETag for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the ETag (None until set from the server).\n",
      "     |\n",
      "     |  job_id\n",
      "     |      str: ID of the job.\n",
      "     |\n",
      "     |  job_type\n",
      "     |      Type of job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: one of 'load', 'copy', 'extract', 'query'.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |  location\n",
      "     |      str: Location where the job runs.\n",
      "     |\n",
      "     |  num_child_jobs\n",
      "     |      The number of child jobs executed.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.num_child_jobs\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          int\n",
      "     |\n",
      "     |  parent_job_id\n",
      "     |      Return the ID of the parent job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.parent_job_id\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: parent job id.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the job's APIs.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the path based on project and job ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the project (derived from the client).\n",
      "     |\n",
      "     |  reservation_usage\n",
      "     |      Job resource usage breakdown by reservation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[google.cloud.bigquery.job.ReservationUsage]:\n",
      "     |              Reservation usage stats. Can be empty if not set from the server.\n",
      "     |\n",
      "     |  script_statistics\n",
      "     |      Statistics for a child job of a script.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      URL for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  session_info\n",
      "     |      [Preview] Information of the session if this job is part of one.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  started\n",
      "     |      Datetime at which the job was started.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the start time (None until set from the server).\n",
      "     |\n",
      "     |  state\n",
      "     |      Status of the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]:\n",
      "     |              the state (None until set from the server).\n",
      "     |\n",
      "     |  transaction_info\n",
      "     |      Information of the multi-statement transaction if this job is part of one.\n",
      "     |\n",
      "     |      Since a scripting query job can execute multiple transactions, this\n",
      "     |      property is only expected on child jobs. Use the\n",
      "     |      :meth:`google.cloud.bigquery.client.Client.list_jobs` method with the\n",
      "     |      ``parent_job`` parameter to iterate over child jobs.\n",
      "     |\n",
      "     |      .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  user_email\n",
      "     |      E-mail address of user who submitted the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.api_core.future.polling.PollingFuture:\n",
      "     |\n",
      "     |  add_done_callback(self, fn)\n",
      "     |      Add a callback to be executed when the operation is complete.\n",
      "     |\n",
      "     |      If the operation is not already complete, this will start a helper\n",
      "     |      thread to poll for the status of the operation in the background.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          fn (Callable[Future]): The callback to execute when the operation\n",
      "     |              is complete.\n",
      "     |\n",
      "     |  exception(self, timeout=<object object at 0x7202a04c6650>)\n",
      "     |      Get the exception from the operation, blocking if necessary.\n",
      "     |\n",
      "     |      See the documentation for the :meth:`result` method for details on how\n",
      "     |      this method operates, as both ``result`` and this method rely on the\n",
      "     |      exact same polling logic. The only difference is that this method does\n",
      "     |      not accept ``retry`` and ``polling`` arguments but relies on the default ones\n",
      "     |      instead.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          timeout (int): How long to wait for the operation to complete.\n",
      "     |          If None, wait indefinitely.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[google.api_core.GoogleAPICallError]: The operation's\n",
      "     |              error.\n",
      "     |\n",
      "     |  running(self)\n",
      "     |      True if the operation is currently running.\n",
      "     |\n",
      "     |  set_exception(self, exception)\n",
      "     |      Set the Future's exception.\n",
      "     |\n",
      "     |  set_result(self, result)\n",
      "     |      Set the Future's result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.api_core.future.base.Future:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class ExtractJobConfig(google.cloud.bigquery.job.base._JobConfig)\n",
      "     |  ExtractJobConfig(**kwargs)\n",
      "     |\n",
      "     |  Configuration options for extract jobs.\n",
      "     |\n",
      "     |  All properties in this class are optional. Values which are :data:`None` ->\n",
      "     |  server defaults. Set properties on the constructed configuration by using\n",
      "     |  the property name as the name of a keyword argument.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ExtractJobConfig\n",
      "     |      google.cloud.bigquery.job.base._JobConfig\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  compression\n",
      "     |      google.cloud.bigquery.job.Compression: Compression type to use for\n",
      "     |      exported files.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationExtract.FIELDS.compression\n",
      "     |\n",
      "     |  destination_format\n",
      "     |      google.cloud.bigquery.job.DestinationFormat: Exported file format.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationExtract.FIELDS.destination_format\n",
      "     |\n",
      "     |  field_delimiter\n",
      "     |      str: Delimiter to use between fields in the exported data.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationExtract.FIELDS.field_delimiter\n",
      "     |\n",
      "     |  print_header\n",
      "     |      bool: Print a header row in the exported data.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationExtract.FIELDS.print_header\n",
      "     |\n",
      "     |  use_avro_logical_types\n",
      "     |      bool: For loads of Avro data, governs whether Avro logical types are\n",
      "     |      converted to their corresponding BigQuery types (e.g. TIMESTAMP) rather than\n",
      "     |      raw types (e.g. INTEGER).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Override to be able to raise error if an unknown property is being set\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of the job config.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> '_JobConfig' from builtins.type\n",
      "     |      Factory: construct a job configuration given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict):\n",
      "     |              A job configuration in the same representation as is returned\n",
      "     |              from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job._JobConfig: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  job_timeout_ms\n",
      "     |      Optional parameter. Job timeout in milliseconds. If this time limit is exceeded, BigQuery might attempt to stop the job.\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfiguration.FIELDS.job_timeout_ms\n",
      "     |      e.g.\n",
      "     |\n",
      "     |          job_config = bigquery.QueryJobConfig( job_timeout_ms = 5000 )\n",
      "     |          or\n",
      "     |          job_config.job_timeout_ms = 5000\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |      This method always returns a dict. Once a job has been created on the\n",
      "     |      server, its labels cannot be modified anymore.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "\n",
      "    class FieldElementType(builtins.object)\n",
      "     |  FieldElementType(element_type: str)\n",
      "     |\n",
      "     |  Represents the type of a field element.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      element_type (str): The type of a field element.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, element_type: str)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this field element type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, str]: Field element type represented as an API resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(api_repr: Optional[dict]) -> Optional[ForwardRef('FieldElementType')] from builtins.type\n",
      "     |      Factory: construct a FieldElementType given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          api_repr (Dict[str, str]): field element type as returned from\n",
      "     |          the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.FieldElementType:\n",
      "     |              Python object, as parsed from ``api_repr``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  element_type\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class GoogleSheetsOptions(builtins.object)\n",
      "     |  Options that describe how to treat Google Sheets as BigQuery tables.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'GoogleSheetsOptions' from builtins.type\n",
      "     |      Factory: construct a :class:`~.external_config.GoogleSheetsOptions`\n",
      "     |      instance given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of a :class:`~.external_config.GoogleSheetsOptions`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          GoogleSheetsOptions: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  range\n",
      "     |      str: The range of a sheet that BigQuery will query from.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#GoogleSheetsOptions.FIELDS.range\n",
      "     |\n",
      "     |  skip_leading_rows\n",
      "     |      int: The number of rows at the top of a sheet that BigQuery will\n",
      "     |      skip when reading the data.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#GoogleSheetsOptions.FIELDS.skip_leading_rows\n",
      "\n",
      "    class HivePartitioningOptions(builtins.object)\n",
      "     |  HivePartitioningOptions() -> None\n",
      "     |\n",
      "     |  [Beta] Options that configure hive partitioning.\n",
      "     |\n",
      "     |  .. note::\n",
      "     |      **Experimental**. This feature is experimental and might change or\n",
      "     |      have limited support.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#HivePartitioningOptions\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, Any]: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'HivePartitioningOptions' from builtins.type\n",
      "     |      Factory: construct a :class:`~.external_config.HivePartitioningOptions`\n",
      "     |      instance given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, Any]):\n",
      "     |              Definition of a :class:`~.external_config.HivePartitioningOptions`\n",
      "     |              instance in the same representation as is returned from the\n",
      "     |              API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          HivePartitioningOptions: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  mode\n",
      "     |      Optional[str]: When set, what mode of hive partitioning to use when reading data.\n",
      "     |\n",
      "     |      Two modes are supported: \"AUTO\" and \"STRINGS\".\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#HivePartitioningOptions.FIELDS.mode\n",
      "     |\n",
      "     |  require_partition_filter\n",
      "     |      Optional[bool]: If set to true, queries over the partitioned table require a\n",
      "     |      partition filter that can be used for partition elimination to be\n",
      "     |      specified.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#HivePartitioningOptions.FIELDS.mode\n",
      "     |\n",
      "     |  source_uri_prefix\n",
      "     |      Optional[str]: When hive partition detection is requested, a common prefix for\n",
      "     |      all source URIs is required.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#HivePartitioningOptions.FIELDS.source_uri_prefix\n",
      "\n",
      "    class KeyResultStatementKind(builtins.object)\n",
      "     |  Determines which statement in the script represents the \"key result\".\n",
      "     |\n",
      "     |  The \"key result\" is used to populate the schema and query results of the script job.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#keyresultstatementkind\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  FIRST_SELECT = 'FIRST_SELECT'\n",
      "     |\n",
      "     |  KEY_RESULT_STATEMENT_KIND_UNSPECIFIED = 'KEY_RESULT_STATEMENT_KIND_UNS...\n",
      "     |\n",
      "     |  LAST = 'LAST'\n",
      "\n",
      "    class LegacyBigQueryStorageError(BigQueryError)\n",
      "     |  Raised when too old a version of BigQuery Storage extra is detected at runtime.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LegacyBigQueryStorageError\n",
      "     |      BigQueryError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors inherited from BigQueryError:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |\n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(...)\n",
      "     |\n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  add_note(...)\n",
      "     |      Exception.add_note(note) --\n",
      "     |      add a note to the exception\n",
      "     |\n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |\n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |\n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |\n",
      "     |  __dict__\n",
      "     |\n",
      "     |  __suppress_context__\n",
      "     |\n",
      "     |  __traceback__\n",
      "     |\n",
      "     |  args\n",
      "\n",
      "    class LegacyPyarrowError(BigQueryError)\n",
      "     |  Raised when too old a version of pyarrow package is detected at runtime.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LegacyPyarrowError\n",
      "     |      BigQueryError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Data descriptors inherited from BigQueryError:\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |\n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |\n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |\n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |\n",
      "     |  __setstate__(...)\n",
      "     |\n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  add_note(...)\n",
      "     |      Exception.add_note(note) --\n",
      "     |      add a note to the exception\n",
      "     |\n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |\n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |\n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |\n",
      "     |  __dict__\n",
      "     |\n",
      "     |  __suppress_context__\n",
      "     |\n",
      "     |  __traceback__\n",
      "     |\n",
      "     |  args\n",
      "\n",
      "    class LoadJob(google.cloud.bigquery.job.base._AsyncJob)\n",
      "     |  LoadJob(job_id, source_uris, destination, client, job_config=None)\n",
      "     |\n",
      "     |  Asynchronous job for loading data into a table.\n",
      "     |\n",
      "     |  Can load from Google Cloud Storage URIs or from a file.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      job_id (str): the job's ID\n",
      "     |\n",
      "     |      source_uris (Optional[Sequence[str]]):\n",
      "     |          URIs of one or more data files to be loaded.  See\n",
      "     |          https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.source_uris\n",
      "     |          for supported URI formats. Pass None for jobs that load from a file.\n",
      "     |\n",
      "     |      destination (google.cloud.bigquery.table.TableReference): reference to table into which data is to be loaded.\n",
      "     |\n",
      "     |      client (google.cloud.bigquery.client.Client):\n",
      "     |          A client which holds credentials and project configuration\n",
      "     |          for the dataset (which requires a project).\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LoadJob\n",
      "     |      google.cloud.bigquery.job.base._AsyncJob\n",
      "     |      google.api_core.future.polling.PollingFuture\n",
      "     |      google.api_core.future.base.Future\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, job_id, source_uris, destination, client, job_config=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Generate a resource for :meth:`_begin`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict, client) -> 'LoadJob' from abc.ABCMeta\n",
      "     |      Factory:  construct a job given its API representation\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         This method assumes that the project found in the resource matches\n",
      "     |         the client's project.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): dataset job representation returned from the API\n",
      "     |\n",
      "     |          client (google.cloud.bigquery.client.Client):\n",
      "     |              Client which holds credentials and project\n",
      "     |              configuration for the dataset.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.LoadJob: Job parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  allow_jagged_rows\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.allow_jagged_rows`.\n",
      "     |\n",
      "     |  allow_quoted_newlines\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.allow_quoted_newlines`.\n",
      "     |\n",
      "     |  autodetect\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.autodetect`.\n",
      "     |\n",
      "     |  clustering_fields\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.clustering_fields`.\n",
      "     |\n",
      "     |  configuration\n",
      "     |      The configuration for this load job.\n",
      "     |\n",
      "     |  connection_properties\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.connection_properties`.\n",
      "     |\n",
      "     |      .. versionadded:: 3.7.0\n",
      "     |\n",
      "     |  create_disposition\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.create_disposition`.\n",
      "     |\n",
      "     |  create_session\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.create_session`.\n",
      "     |\n",
      "     |      .. versionadded:: 3.7.0\n",
      "     |\n",
      "     |  destination\n",
      "     |      google.cloud.bigquery.table.TableReference: table where loaded rows are written\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.destination_table\n",
      "     |\n",
      "     |  destination_encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for the destination table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys)\n",
      "     |      or :data:`None` if using default encryption.\n",
      "     |\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.destination_encryption_configuration`.\n",
      "     |\n",
      "     |  destination_table_description\n",
      "     |      Optional[str] name given to destination table.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#DestinationTableProperties.FIELDS.description\n",
      "     |\n",
      "     |  destination_table_friendly_name\n",
      "     |      Optional[str] name given to destination table.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#DestinationTableProperties.FIELDS.friendly_name\n",
      "     |\n",
      "     |  encoding\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.encoding`.\n",
      "     |\n",
      "     |  field_delimiter\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.field_delimiter`.\n",
      "     |\n",
      "     |  ignore_unknown_values\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.ignore_unknown_values`.\n",
      "     |\n",
      "     |  input_file_bytes\n",
      "     |      Count of bytes loaded from source files.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]: the count (None until set from the server).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: for invalid value types.\n",
      "     |\n",
      "     |  input_files\n",
      "     |      Count of source files.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]: the count (None until set from the server).\n",
      "     |\n",
      "     |  max_bad_records\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.max_bad_records`.\n",
      "     |\n",
      "     |  null_marker\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.null_marker`.\n",
      "     |\n",
      "     |  output_bytes\n",
      "     |      Count of bytes saved to destination table.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]: the count (None until set from the server).\n",
      "     |\n",
      "     |  output_rows\n",
      "     |      Count of rows saved to destination table.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]: the count (None until set from the server).\n",
      "     |\n",
      "     |  quote_character\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.quote_character`.\n",
      "     |\n",
      "     |  range_partitioning\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.range_partitioning`.\n",
      "     |\n",
      "     |  reference_file_schema_uri\n",
      "     |      See:\n",
      "     |      attr:`google.cloud.bigquery.job.LoadJobConfig.reference_file_schema_uri`.\n",
      "     |\n",
      "     |  schema\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.schema`.\n",
      "     |\n",
      "     |  schema_update_options\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.schema_update_options`.\n",
      "     |\n",
      "     |  skip_leading_rows\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.skip_leading_rows`.\n",
      "     |\n",
      "     |  source_format\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.source_format`.\n",
      "     |\n",
      "     |  source_uris\n",
      "     |      Optional[Sequence[str]]: URIs of data files to be loaded. See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.source_uris\n",
      "     |      for supported URI formats. None for jobs that load from a file.\n",
      "     |\n",
      "     |  time_partitioning\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.time_partitioning`.\n",
      "     |\n",
      "     |  use_avro_logical_types\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.use_avro_logical_types`.\n",
      "     |\n",
      "     |  write_disposition\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.write_disposition`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  cancel(self, client=None, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  cancel job via a POST request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating that the cancel request was sent.\n",
      "     |\n",
      "     |  cancelled(self)\n",
      "     |      Check if the job has been cancelled.\n",
      "     |\n",
      "     |      This always returns False. It's not possible to check if a job was\n",
      "     |      cancelled in the API. This method is here to satisfy the interface\n",
      "     |      for :class:`google.api_core.future.Future`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: False\n",
      "     |\n",
      "     |  done(self, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, reload: bool = True) -> bool\n",
      "     |      Checks if the job is complete.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          reload (Optional[bool]):\n",
      "     |              If ``True``, make an API call to refresh the job state of\n",
      "     |              unfinished jobs before checking. Default ``True``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: True if the job is complete, False otherwise.\n",
      "     |\n",
      "     |  exists(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  test for the existence of the job via a GET request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating existence of the job.\n",
      "     |\n",
      "     |  reload(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None)\n",
      "     |      API call:  refresh job properties via a GET request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |  result(self, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> '_AsyncJob'\n",
      "     |      Start the job and wait for it to complete and get the result.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          _AsyncJob: This instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.GoogleAPICallError:\n",
      "     |              if the job failed.\n",
      "     |          concurrent.futures.TimeoutError:\n",
      "     |              if the job did not complete in the given timeout.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  created\n",
      "     |      Datetime at which the job was created.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the creation time (None until set from the server).\n",
      "     |\n",
      "     |  ended\n",
      "     |      Datetime at which the job finished.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the end time (None until set from the server).\n",
      "     |\n",
      "     |  error_result\n",
      "     |      Error information about the job as a whole.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[Mapping]: the error information (None until set from the server).\n",
      "     |\n",
      "     |  errors\n",
      "     |      Information about individual errors generated by the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[List[Mapping]]:\n",
      "     |              the error information (None until set from the server).\n",
      "     |\n",
      "     |  etag\n",
      "     |      ETag for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the ETag (None until set from the server).\n",
      "     |\n",
      "     |  job_id\n",
      "     |      str: ID of the job.\n",
      "     |\n",
      "     |  job_type\n",
      "     |      Type of job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: one of 'load', 'copy', 'extract', 'query'.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |  location\n",
      "     |      str: Location where the job runs.\n",
      "     |\n",
      "     |  num_child_jobs\n",
      "     |      The number of child jobs executed.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.num_child_jobs\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          int\n",
      "     |\n",
      "     |  parent_job_id\n",
      "     |      Return the ID of the parent job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.parent_job_id\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: parent job id.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the job's APIs.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the path based on project and job ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the project (derived from the client).\n",
      "     |\n",
      "     |  reservation_usage\n",
      "     |      Job resource usage breakdown by reservation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[google.cloud.bigquery.job.ReservationUsage]:\n",
      "     |              Reservation usage stats. Can be empty if not set from the server.\n",
      "     |\n",
      "     |  script_statistics\n",
      "     |      Statistics for a child job of a script.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      URL for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  session_info\n",
      "     |      [Preview] Information of the session if this job is part of one.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  started\n",
      "     |      Datetime at which the job was started.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the start time (None until set from the server).\n",
      "     |\n",
      "     |  state\n",
      "     |      Status of the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]:\n",
      "     |              the state (None until set from the server).\n",
      "     |\n",
      "     |  transaction_info\n",
      "     |      Information of the multi-statement transaction if this job is part of one.\n",
      "     |\n",
      "     |      Since a scripting query job can execute multiple transactions, this\n",
      "     |      property is only expected on child jobs. Use the\n",
      "     |      :meth:`google.cloud.bigquery.client.Client.list_jobs` method with the\n",
      "     |      ``parent_job`` parameter to iterate over child jobs.\n",
      "     |\n",
      "     |      .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  user_email\n",
      "     |      E-mail address of user who submitted the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.api_core.future.polling.PollingFuture:\n",
      "     |\n",
      "     |  add_done_callback(self, fn)\n",
      "     |      Add a callback to be executed when the operation is complete.\n",
      "     |\n",
      "     |      If the operation is not already complete, this will start a helper\n",
      "     |      thread to poll for the status of the operation in the background.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          fn (Callable[Future]): The callback to execute when the operation\n",
      "     |              is complete.\n",
      "     |\n",
      "     |  exception(self, timeout=<object object at 0x7202a04c6650>)\n",
      "     |      Get the exception from the operation, blocking if necessary.\n",
      "     |\n",
      "     |      See the documentation for the :meth:`result` method for details on how\n",
      "     |      this method operates, as both ``result`` and this method rely on the\n",
      "     |      exact same polling logic. The only difference is that this method does\n",
      "     |      not accept ``retry`` and ``polling`` arguments but relies on the default ones\n",
      "     |      instead.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          timeout (int): How long to wait for the operation to complete.\n",
      "     |          If None, wait indefinitely.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[google.api_core.GoogleAPICallError]: The operation's\n",
      "     |              error.\n",
      "     |\n",
      "     |  running(self)\n",
      "     |      True if the operation is currently running.\n",
      "     |\n",
      "     |  set_exception(self, exception)\n",
      "     |      Set the Future's exception.\n",
      "     |\n",
      "     |  set_result(self, result)\n",
      "     |      Set the Future's result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.api_core.future.base.Future:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class LoadJobConfig(google.cloud.bigquery.job.base._JobConfig)\n",
      "     |  LoadJobConfig(**kwargs) -> None\n",
      "     |\n",
      "     |  Configuration options for load jobs.\n",
      "     |\n",
      "     |  Set properties on the constructed configuration by using the property name\n",
      "     |  as the name of a keyword argument. Values which are unset or :data:`None`\n",
      "     |  use the BigQuery REST API default values. See the `BigQuery REST API\n",
      "     |  reference documentation\n",
      "     |  <https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad>`_\n",
      "     |  for a list of default values.\n",
      "     |\n",
      "     |  Required options differ based on the\n",
      "     |  :attr:`~google.cloud.bigquery.job.LoadJobConfig.source_format` value.\n",
      "     |  For example, the BigQuery API's default value for\n",
      "     |  :attr:`~google.cloud.bigquery.job.LoadJobConfig.source_format` is ``\"CSV\"``.\n",
      "     |  When loading a CSV file, either\n",
      "     |  :attr:`~google.cloud.bigquery.job.LoadJobConfig.schema` must be set or\n",
      "     |  :attr:`~google.cloud.bigquery.job.LoadJobConfig.autodetect` must be set to\n",
      "     |  :data:`True`.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LoadJobConfig\n",
      "     |      google.cloud.bigquery.job.base._JobConfig\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, **kwargs) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  allow_jagged_rows\n",
      "     |      Optional[bool]: Allow missing trailing optional columns (CSV only).\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.allow_jagged_rows\n",
      "     |\n",
      "     |  allow_quoted_newlines\n",
      "     |      Optional[bool]: Allow quoted data containing newline characters (CSV only).\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.allow_quoted_newlines\n",
      "     |\n",
      "     |  autodetect\n",
      "     |      Optional[bool]: Automatically infer the schema from a sample of the data.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.autodetect\n",
      "     |\n",
      "     |  clustering_fields\n",
      "     |      Optional[List[str]]: Fields defining clustering for the table\n",
      "     |\n",
      "     |      (Defaults to :data:`None`).\n",
      "     |\n",
      "     |      Clustering fields are immutable after table creation.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         BigQuery supports clustering for both partitioned and\n",
      "     |         non-partitioned tables.\n",
      "     |\n",
      "     |  connection_properties\n",
      "     |      Connection properties.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.connection_properties\n",
      "     |\n",
      "     |      .. versionadded:: 3.7.0\n",
      "     |\n",
      "     |  create_disposition\n",
      "     |      Optional[google.cloud.bigquery.job.CreateDisposition]: Specifies behavior\n",
      "     |      for creating tables.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.create_disposition\n",
      "     |\n",
      "     |  create_session\n",
      "     |      [Preview] If :data:`True`, creates a new session, where\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJob.session_info` will contain a\n",
      "     |      random server generated session id.\n",
      "     |\n",
      "     |      If :data:`False`, runs load job with an existing ``session_id`` passed in\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.connection_properties`,\n",
      "     |      otherwise runs load job in non-session mode.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.create_session\n",
      "     |\n",
      "     |      .. versionadded:: 3.7.0\n",
      "     |\n",
      "     |  decimal_target_types\n",
      "     |      Possible SQL data types to which the source decimal values are converted.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.decimal_target_types\n",
      "     |\n",
      "     |      .. versionadded:: 2.21.0\n",
      "     |\n",
      "     |  destination_encryption_configuration\n",
      "     |      Optional[google.cloud.bigquery.encryption_configuration.EncryptionConfiguration]: Custom\n",
      "     |      encryption configuration for the destination table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.destination_encryption_configuration\n",
      "     |\n",
      "     |  destination_table_description\n",
      "     |      Optional[str]: Description of the destination table.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#DestinationTableProperties.FIELDS.description\n",
      "     |\n",
      "     |  destination_table_friendly_name\n",
      "     |      Optional[str]: Name given to destination table.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#DestinationTableProperties.FIELDS.friendly_name\n",
      "     |\n",
      "     |  encoding\n",
      "     |      Optional[google.cloud.bigquery.job.Encoding]: The character encoding of the\n",
      "     |      data.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.encoding\n",
      "     |\n",
      "     |  field_delimiter\n",
      "     |      Optional[str]: The separator for fields in a CSV file.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.field_delimiter\n",
      "     |\n",
      "     |  hive_partitioning\n",
      "     |      Optional[:class:`~.external_config.HivePartitioningOptions`]: [Beta] When set,         it configures hive partitioning support.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          **Experimental**. This feature is experimental and might change or\n",
      "     |          have limited support.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.hive_partitioning_options\n",
      "     |\n",
      "     |  ignore_unknown_values\n",
      "     |      Optional[bool]: Ignore extra values not represented in the table schema.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.ignore_unknown_values\n",
      "     |\n",
      "     |  json_extension\n",
      "     |      Optional[str]: The extension to use for writing JSON data to BigQuery. Only supports GeoJSON currently.\n",
      "     |\n",
      "     |      See: https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.json_extension\n",
      "     |\n",
      "     |  max_bad_records\n",
      "     |      Optional[int]: Number of invalid rows to ignore.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.max_bad_records\n",
      "     |\n",
      "     |  null_marker\n",
      "     |      Optional[str]: Represents a null value (CSV only).\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.null_marker\n",
      "     |\n",
      "     |  parquet_options\n",
      "     |      Optional[google.cloud.bigquery.format_options.ParquetOptions]: Additional\n",
      "     |          properties to set if ``sourceFormat`` is set to PARQUET.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.parquet_options\n",
      "     |\n",
      "     |  preserve_ascii_control_characters\n",
      "     |      Optional[bool]: Preserves the embedded ASCII control characters when sourceFormat is set to CSV.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.preserve_ascii_control_characters\n",
      "     |\n",
      "     |  projection_fields\n",
      "     |      Optional[List[str]]: If\n",
      "     |      :attr:`google.cloud.bigquery.job.LoadJobConfig.source_format` is set to\n",
      "     |      \"DATASTORE_BACKUP\", indicates which entity properties to load into\n",
      "     |      BigQuery from a Cloud Datastore backup.\n",
      "     |\n",
      "     |      Property names are case sensitive and must be top-level properties. If\n",
      "     |      no properties are specified, BigQuery loads all properties. If any\n",
      "     |      named property isn't found in the Cloud Datastore backup, an invalid\n",
      "     |      error is returned in the job result.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.projection_fields\n",
      "     |\n",
      "     |  quote_character\n",
      "     |      Optional[str]: Character used to quote data sections (CSV only).\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.quote\n",
      "     |\n",
      "     |  range_partitioning\n",
      "     |      Optional[google.cloud.bigquery.table.RangePartitioning]:\n",
      "     |      Configures range-based partitioning for destination table.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          **Beta**. The integer range partitioning feature is in a\n",
      "     |          pre-release state and might change or have limited support.\n",
      "     |\n",
      "     |      Only specify at most one of\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.time_partitioning` or\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.range_partitioning`.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not\n",
      "     |              :class:`~google.cloud.bigquery.table.RangePartitioning` or\n",
      "     |              :data:`None`.\n",
      "     |\n",
      "     |  reference_file_schema_uri\n",
      "     |      Optional[str]:\n",
      "     |      When creating an external table, the user can provide a reference file with the\n",
      "     |      table schema. This is enabled for the following formats:\n",
      "     |\n",
      "     |      AVRO, PARQUET, ORC\n",
      "     |\n",
      "     |  schema\n",
      "     |      Optional[Sequence[Union[             :class:`~google.cloud.bigquery.schema.SchemaField`,             Mapping[str, Any]         ]]]: Schema of the destination table.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.schema\n",
      "     |\n",
      "     |  schema_update_options\n",
      "     |      Optional[List[google.cloud.bigquery.job.SchemaUpdateOption]]: Specifies\n",
      "     |      updates to the destination table schema to allow as a side effect of\n",
      "     |      the load job.\n",
      "     |\n",
      "     |  skip_leading_rows\n",
      "     |      Optional[int]: Number of rows to skip when reading data (CSV only).\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.skip_leading_rows\n",
      "     |\n",
      "     |  source_format\n",
      "     |      Optional[google.cloud.bigquery.job.SourceFormat]: File format of the data.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.source_format\n",
      "     |\n",
      "     |  time_partitioning\n",
      "     |      Optional[google.cloud.bigquery.table.TimePartitioning]: Specifies time-based\n",
      "     |      partitioning for the destination table.\n",
      "     |\n",
      "     |      Only specify at most one of\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.time_partitioning` or\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.range_partitioning`.\n",
      "     |\n",
      "     |  use_avro_logical_types\n",
      "     |      Optional[bool]: For loads of Avro data, governs whether Avro logical types are\n",
      "     |      converted to their corresponding BigQuery types (e.g. TIMESTAMP) rather than\n",
      "     |      raw types (e.g. INTEGER).\n",
      "     |\n",
      "     |  write_disposition\n",
      "     |      Optional[google.cloud.bigquery.job.WriteDisposition]: Action that occurs if\n",
      "     |      the destination table already exists.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationLoad.FIELDS.write_disposition\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Override to be able to raise error if an unknown property is being set\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of the job config.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> '_JobConfig' from builtins.type\n",
      "     |      Factory: construct a job configuration given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict):\n",
      "     |              A job configuration in the same representation as is returned\n",
      "     |              from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job._JobConfig: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  job_timeout_ms\n",
      "     |      Optional parameter. Job timeout in milliseconds. If this time limit is exceeded, BigQuery might attempt to stop the job.\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfiguration.FIELDS.job_timeout_ms\n",
      "     |      e.g.\n",
      "     |\n",
      "     |          job_config = bigquery.QueryJobConfig( job_timeout_ms = 5000 )\n",
      "     |          or\n",
      "     |          job_config.job_timeout_ms = 5000\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |      This method always returns a dict. Once a job has been created on the\n",
      "     |      server, its labels cannot be modified anymore.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "\n",
      "    class Model(builtins.object)\n",
      "     |  Model(model_ref: \"Union['ModelReference', str, None]\")\n",
      "     |\n",
      "     |  Model represents a machine learning model resource.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/models\n",
      "     |\n",
      "     |  Args:\n",
      "     |      model_ref:\n",
      "     |          A pointer to a model. If ``model_ref`` is a string, it must\n",
      "     |          included a project ID, dataset ID, and model ID, each separated\n",
      "     |          by ``.``.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, model_ref: \"Union['ModelReference', str, None]\")\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> 'Dict[str, Any]'\n",
      "     |      Construct the API resource representation of this model.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Model reference represented as an API resource\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: 'Dict[str, Any]') -> \"'Model'\" from builtins.type\n",
      "     |      Factory: construct a model resource given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource:\n",
      "     |              Model resource representation from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Model parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  best_trial_id\n",
      "     |      The best trial_id across all training runs.\n",
      "     |\n",
      "     |      .. deprecated::\n",
      "     |          This property is deprecated!\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  created\n",
      "     |      Datetime at which the model was created (:data:`None` until set from the server).\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      ID of dataset containing the model.\n",
      "     |\n",
      "     |  etag\n",
      "     |      ETag for the model resource (:data:`None` until set from the server).\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  feature_columns\n",
      "     |      Input feature columns that were used to train this model.\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  label_columns\n",
      "     |      Label columns that were used to train this model.\n",
      "     |\n",
      "     |      The output of the model will have a ``predicted_`` prefix to these columns.\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  location\n",
      "     |      The geographic location where the model resides.\n",
      "     |\n",
      "     |      This value is inherited from the dataset.\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  model_id\n",
      "     |      The model ID.\n",
      "     |\n",
      "     |  model_type\n",
      "     |      Type of the model resource.\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  modified\n",
      "     |      Datetime at which the model was last modified (:data:`None` until set from the server).\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the model's APIs.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the model.\n",
      "     |\n",
      "     |  reference\n",
      "     |      A model reference pointing to this model.\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  training_runs\n",
      "     |      Information for all training runs in increasing order of start time.\n",
      "     |\n",
      "     |      Dictionaries are in REST API format. See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/models#trainingrun\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  transform_columns\n",
      "     |      The input feature columns that were used to train this model.\n",
      "     |      The output transform columns used to train this model.\n",
      "     |\n",
      "     |      See REST API:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/models#transformcolumn\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  description\n",
      "     |      Description of the model (defaults to :data:`None`).\n",
      "     |\n",
      "     |  encryption_configuration\n",
      "     |      Custom encryption configuration for the model.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See `protecting data with Cloud KMS keys\n",
      "     |      <https://cloud.google.com/bigquery/docs/customer-managed-encryption>`_\n",
      "     |      in the BigQuery documentation.\n",
      "     |\n",
      "     |  expires\n",
      "     |      The datetime when this model expires.\n",
      "     |\n",
      "     |      If not present, the model will persist indefinitely. Expired models will be\n",
      "     |      deleted and their storage reclaimed.\n",
      "     |\n",
      "     |  friendly_name\n",
      "     |      Title of the table (defaults to :data:`None`).\n",
      "     |\n",
      "     |  labels\n",
      "     |      Labels for the table.\n",
      "     |\n",
      "     |      This method always returns a dict. To change a model's labels, modify the dict,\n",
      "     |      then call ``Client.update_model``. To delete a label, set its value to\n",
      "     |      :data:`None` before updating.\n",
      "\n",
      "    class ModelReference(builtins.object)\n",
      "     |  ModelReferences are pointers to models.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/models#modelreference\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> 'Dict[str, Any]'\n",
      "     |      Construct the API resource representation of this model reference.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Model reference represented as an API resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: 'Dict[str, Any]') -> \"'ModelReference'\" from builtins.type\n",
      "     |      Factory: construct a model reference given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource:\n",
      "     |              Model reference representation returned from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Model reference parsed from ``resource``.\n",
      "     |\n",
      "     |  from_string(model_id: 'str', default_project: 'Optional[str]' = None) -> \"'ModelReference'\" from builtins.type\n",
      "     |      Construct a model reference from model ID string.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          model_id:\n",
      "     |              A model ID in standard SQL format. If ``default_project``\n",
      "     |              is not specified, this must included a project ID, dataset\n",
      "     |              ID, and model ID, each separated by ``.``.\n",
      "     |          default_project:\n",
      "     |              The project ID to use when ``model_id`` does not include\n",
      "     |              a project ID.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Model reference parsed from ``model_id``.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``model_id`` is not a fully-qualified table ID in\n",
      "     |              standard SQL format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      str: ID of dataset containing the model.\n",
      "     |\n",
      "     |  model_id\n",
      "     |      str: The model ID.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the model's APIs.\n",
      "     |\n",
      "     |  project\n",
      "     |      str: Project bound to the model\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class OperationType(builtins.object)\n",
      "     |  Different operation types supported in table copy job.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#operationtype\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  CLONE = 'CLONE'\n",
      "     |\n",
      "     |  COPY = 'COPY'\n",
      "     |\n",
      "     |  OPERATION_TYPE_UNSPECIFIED = 'OPERATION_TYPE_UNSPECIFIED'\n",
      "     |\n",
      "     |  RESTORE = 'RESTORE'\n",
      "     |\n",
      "     |  SNAPSHOT = 'SNAPSHOT'\n",
      "\n",
      "    class ParquetOptions(builtins.object)\n",
      "     |  Additional options if the PARQUET source format is used.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of this object.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, bool]:\n",
      "     |              A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, bool]) -> 'ParquetOptions' from builtins.type\n",
      "     |      Factory: construct an instance from a resource dict.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, bool]):\n",
      "     |              Definition of a :class:`~.format_options.ParquetOptions` instance in\n",
      "     |              the same representation as is returned from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          :class:`~.format_options.ParquetOptions`:\n",
      "     |              Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  enable_list_inference\n",
      "     |      Indicates whether to use schema inference specifically for Parquet LIST\n",
      "     |      logical type.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ParquetOptions.FIELDS.enable_list_inference\n",
      "     |\n",
      "     |  enum_as_string\n",
      "     |      Indicates whether to infer Parquet ENUM logical type as STRING instead of\n",
      "     |      BYTES by default.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#ParquetOptions.FIELDS.enum_as_string\n",
      "\n",
      "    class PartitionRange(builtins.object)\n",
      "     |  PartitionRange(start=None, end=None, interval=None, _properties=None) -> None\n",
      "     |\n",
      "     |  Definition of the ranges for range partitioning.\n",
      "     |\n",
      "     |  .. note::\n",
      "     |      **Beta**. The integer range partitioning feature is in a pre-release\n",
      "     |      state and might change or have limited support.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      start (Optional[int]):\n",
      "     |          Sets the\n",
      "     |          :attr:`~google.cloud.bigquery.table.PartitionRange.start`\n",
      "     |          property.\n",
      "     |      end (Optional[int]):\n",
      "     |          Sets the\n",
      "     |          :attr:`~google.cloud.bigquery.table.PartitionRange.end`\n",
      "     |          property.\n",
      "     |      interval (Optional[int]):\n",
      "     |          Sets the\n",
      "     |          :attr:`~google.cloud.bigquery.table.PartitionRange.interval`\n",
      "     |          property.\n",
      "     |      _properties (Optional[dict]):\n",
      "     |          Private. Used to construct object from API resource.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, start=None, end=None, interval=None, _properties=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  end\n",
      "     |      int: The end of range partitioning, exclusive.\n",
      "     |\n",
      "     |  interval\n",
      "     |      int: The width of each interval.\n",
      "     |\n",
      "     |  start\n",
      "     |      int: The start of range partitioning, inclusive.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class PolicyTagList(builtins.object)\n",
      "     |  PolicyTagList(names: Iterable[str] = ())\n",
      "     |\n",
      "     |  Define Policy Tags for a column.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      names (\n",
      "     |          Optional[Tuple[str]]): list of policy tags to associate with\n",
      "     |          the column.  Policy tag identifiers are of the form\n",
      "     |          `projects/*/locations/*/taxonomies/*/policyTags/*`.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self, names: Iterable[str] = ())\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Return a dictionary representing this object.\n",
      "     |\n",
      "     |      This method returns the properties dict of the ``PolicyTagList``\n",
      "     |      instance rather than making a copy. This means that when a\n",
      "     |      ``PolicyTagList`` instance is stored as a property of another\n",
      "     |      object, any changes made at the higher level will also appear here.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          dict:\n",
      "     |              A dictionary representing the PolicyTagList object in\n",
      "     |              serialized form.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(api_repr: dict) -> 'PolicyTagList' from builtins.type\n",
      "     |      Return a :class:`PolicyTagList` object deserialized from a dict.\n",
      "     |\n",
      "     |      This method creates a new ``PolicyTagList`` instance that points to\n",
      "     |      the ``api_repr`` parameter as its internal properties dict. This means\n",
      "     |      that when a ``PolicyTagList`` instance is stored as a property of\n",
      "     |      another object, any changes made at the higher level will also appear\n",
      "     |      here.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          api_repr (Mapping[str, str]):\n",
      "     |              The serialized representation of the PolicyTagList, such as\n",
      "     |              what is output by :meth:`to_api_repr`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[google.cloud.bigquery.schema.PolicyTagList]:\n",
      "     |              The ``PolicyTagList`` object or None.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  names\n",
      "     |      Tuple[str]: Policy tags associated with this definition.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class QueryJob(google.cloud.bigquery.job.base._AsyncJob)\n",
      "     |  QueryJob(job_id, query, client, job_config=None)\n",
      "     |\n",
      "     |  Asynchronous job: query tables.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      job_id (str): the job's ID, within the project belonging to ``client``.\n",
      "     |\n",
      "     |      query (str): SQL query string.\n",
      "     |\n",
      "     |      client (google.cloud.bigquery.client.Client):\n",
      "     |          A client which holds credentials and project configuration\n",
      "     |          for the dataset (which requires a project).\n",
      "     |\n",
      "     |      job_config (Optional[google.cloud.bigquery.job.QueryJobConfig]):\n",
      "     |          Extra configuration options for the query job.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      QueryJob\n",
      "     |      google.cloud.bigquery.job.base._AsyncJob\n",
      "     |      google.api_core.future.polling.PollingFuture\n",
      "     |      google.api_core.future.base.Future\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, job_id, query, client, job_config=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __iter__(self)\n",
      "     |\n",
      "     |  result(self, page_size: Optional[int] = None, max_results: Optional[int] = None, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, start_index: Optional[int] = None, job_retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c196a0>) -> Union[ForwardRef('RowIterator'), google.cloud.bigquery.table._EmptyRowIterator]\n",
      "     |      Start the job and wait for it to complete and get the result.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          page_size (Optional[int]):\n",
      "     |              The maximum number of rows in each page of results from this\n",
      "     |              request. Non-positive values are ignored.\n",
      "     |          max_results (Optional[int]):\n",
      "     |              The maximum total number of rows from this request.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the call that retrieves rows.  This only\n",
      "     |              applies to making RPC calls.  It isn't used to retry\n",
      "     |              failed jobs.  This has a reasonable default that\n",
      "     |              should only be overridden with care. If the job state\n",
      "     |              is ``DONE``, retrying is aborted early even if the\n",
      "     |              results are not available, as this will not change\n",
      "     |              anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |          start_index (Optional[int]):\n",
      "     |              The zero-based index of the starting row to read.\n",
      "     |          job_retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry failed jobs.  The default retries\n",
      "     |              rate-limit-exceeded errors. Passing ``None`` disables\n",
      "     |              job retry.\n",
      "     |\n",
      "     |              Not all jobs can be retried.  If ``job_id`` was\n",
      "     |              provided to the query that created this job, then the\n",
      "     |              job returned by the query will not be retryable, and\n",
      "     |              an exception will be raised if non-``None``\n",
      "     |              non-default ``job_retry`` is also provided.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.RowIterator:\n",
      "     |              Iterator of row data\n",
      "     |              :class:`~google.cloud.bigquery.table.Row`-s. During each\n",
      "     |              page, the iterator will have the ``total_rows`` attribute\n",
      "     |              set, which counts the total number of rows **in the result\n",
      "     |              set** (this is distinct from the total number of rows in the\n",
      "     |              current page: ``iterator.page.num_items``).\n",
      "     |\n",
      "     |              If the query is a special query that produces no results, e.g.\n",
      "     |              a DDL query, an ``_EmptyRowIterator`` instance is returned.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.GoogleAPICallError:\n",
      "     |              If the job failed and retries aren't successful.\n",
      "     |          concurrent.futures.TimeoutError:\n",
      "     |              If the job did not complete in the given timeout.\n",
      "     |          TypeError:\n",
      "     |              If Non-``None`` and non-default ``job_retry`` is\n",
      "     |              provided and the job is not retryable.\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Generate a resource for :meth:`_begin`.\n",
      "     |\n",
      "     |  to_arrow(self, progress_bar_type: Optional[str] = None, bqstorage_client: Optional[ForwardRef('bigquery_storage.BigQueryReadClient')] = None, create_bqstorage_client: bool = True, max_results: Optional[int] = None) -> 'pyarrow.Table'\n",
      "     |      [Beta] Create a class:`pyarrow.Table` by loading all pages of a\n",
      "     |      table or query.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          progress_bar_type (Optional[str]):\n",
      "     |              If set, use the `tqdm <https://tqdm.github.io/>`_ library to\n",
      "     |              display a progress bar while the data downloads. Install the\n",
      "     |              ``tqdm`` package to use this feature.\n",
      "     |\n",
      "     |              Possible values of ``progress_bar_type`` include:\n",
      "     |\n",
      "     |              ``None``\n",
      "     |                No progress bar.\n",
      "     |              ``'tqdm'``\n",
      "     |                Use the :func:`tqdm.tqdm` function to print a progress bar\n",
      "     |                to :data:`sys.stdout`.\n",
      "     |              ``'tqdm_notebook'``\n",
      "     |                Use the :func:`tqdm.notebook.tqdm` function to display a\n",
      "     |                progress bar as a Jupyter notebook widget.\n",
      "     |              ``'tqdm_gui'``\n",
      "     |                Use the :func:`tqdm.tqdm_gui` function to display a\n",
      "     |                progress bar as a graphical dialog box.\n",
      "     |          bqstorage_client (Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]):\n",
      "     |              A BigQuery Storage API client. If supplied, use the faster\n",
      "     |              BigQuery Storage API to fetch rows from BigQuery. This API\n",
      "     |              is a billable API.\n",
      "     |\n",
      "     |              This method requires ``google-cloud-bigquery-storage`` library.\n",
      "     |\n",
      "     |              Reading from a specific partition or snapshot is not\n",
      "     |              currently supported by this method.\n",
      "     |          create_bqstorage_client (Optional[bool]):\n",
      "     |              If ``True`` (default), create a BigQuery Storage API client\n",
      "     |              using the default API settings. The BigQuery Storage API\n",
      "     |              is a faster way to fetch rows from BigQuery. See the\n",
      "     |              ``bqstorage_client`` parameter for more information.\n",
      "     |\n",
      "     |              This argument does nothing if ``bqstorage_client`` is supplied.\n",
      "     |\n",
      "     |              .. versionadded:: 1.24.0\n",
      "     |\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of rows to include in the result. No limit by default.\n",
      "     |\n",
      "     |              .. versionadded:: 2.21.0\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          pyarrow.Table\n",
      "     |              A :class:`pyarrow.Table` populated with row data and column\n",
      "     |              headers from the query results. The column headers are derived\n",
      "     |              from the destination table's schema.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the :mod:`pyarrow` library cannot be imported.\n",
      "     |\n",
      "     |      .. versionadded:: 1.17.0\n",
      "     |\n",
      "     |  to_dataframe(self, bqstorage_client: Optional[ForwardRef('bigquery_storage.BigQueryReadClient')] = None, dtypes: Optional[Dict[str, Any]] = None, progress_bar_type: Optional[str] = None, create_bqstorage_client: bool = True, max_results: Optional[int] = None, geography_as_object: bool = False, bool_dtype: Optional[Any] = <DefaultPandasDTypes.BOOL_DTYPE: <object object at 0x7202a04c6680>>, int_dtype: Optional[Any] = <DefaultPandasDTypes.INT_DTYPE: <object object at 0x7202a04c6690>>, float_dtype: Optional[Any] = None, string_dtype: Optional[Any] = None, date_dtype: Optional[Any] = <DefaultPandasDTypes.DATE_DTYPE: <object object at 0x7202a04c6660>>, datetime_dtype: Optional[Any] = None, time_dtype: Optional[Any] = <DefaultPandasDTypes.TIME_DTYPE: <object object at 0x7202a04c66a0>>, timestamp_dtype: Optional[Any] = None) -> 'pandas.DataFrame'\n",
      "     |      Return a pandas DataFrame from a QueryJob\n",
      "     |\n",
      "     |      Args:\n",
      "     |          bqstorage_client (Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]):\n",
      "     |              A BigQuery Storage API client. If supplied, use the faster\n",
      "     |              BigQuery Storage API to fetch rows from BigQuery. This\n",
      "     |              API is a billable API.\n",
      "     |\n",
      "     |              This method requires the ``fastavro`` and\n",
      "     |              ``google-cloud-bigquery-storage`` libraries.\n",
      "     |\n",
      "     |              Reading from a specific partition or snapshot is not\n",
      "     |              currently supported by this method.\n",
      "     |\n",
      "     |          dtypes (Optional[Map[str, Union[str, pandas.Series.dtype]]]):\n",
      "     |              A dictionary of column names pandas ``dtype``s. The provided\n",
      "     |              ``dtype`` is used when constructing the series for the column\n",
      "     |              specified. Otherwise, the default pandas behavior is used.\n",
      "     |\n",
      "     |          progress_bar_type (Optional[str]):\n",
      "     |              If set, use the `tqdm <https://tqdm.github.io/>`_ library to\n",
      "     |              display a progress bar while the data downloads. Install the\n",
      "     |              ``tqdm`` package to use this feature.\n",
      "     |\n",
      "     |              See\n",
      "     |              :func:`~google.cloud.bigquery.table.RowIterator.to_dataframe`\n",
      "     |              for details.\n",
      "     |\n",
      "     |              .. versionadded:: 1.11.0\n",
      "     |          create_bqstorage_client (Optional[bool]):\n",
      "     |              If ``True`` (default), create a BigQuery Storage API client\n",
      "     |              using the default API settings. The BigQuery Storage API\n",
      "     |              is a faster way to fetch rows from BigQuery. See the\n",
      "     |              ``bqstorage_client`` parameter for more information.\n",
      "     |\n",
      "     |              This argument does nothing if ``bqstorage_client`` is supplied.\n",
      "     |\n",
      "     |              .. versionadded:: 1.24.0\n",
      "     |\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of rows to include in the result. No limit by default.\n",
      "     |\n",
      "     |              .. versionadded:: 2.21.0\n",
      "     |\n",
      "     |          geography_as_object (Optional[bool]):\n",
      "     |              If ``True``, convert GEOGRAPHY data to :mod:`shapely`\n",
      "     |              geometry objects.  If ``False`` (default), don't cast\n",
      "     |              geography data to :mod:`shapely` geometry objects.\n",
      "     |\n",
      "     |              .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |          bool_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g. ``pandas.BooleanDtype()``)\n",
      "     |              to convert BigQuery Boolean type, instead of relying on the default\n",
      "     |              ``pandas.BooleanDtype()``. If you explicitly set the value to ``None``,\n",
      "     |              then the data type will be ``numpy.dtype(\"bool\")``. BigQuery Boolean\n",
      "     |              type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#boolean_type\n",
      "     |\n",
      "     |              .. versionadded:: 3.8.0\n",
      "     |\n",
      "     |          int_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g. ``pandas.Int64Dtype()``)\n",
      "     |              to convert BigQuery Integer types, instead of relying on the default\n",
      "     |              ``pandas.Int64Dtype()``. If you explicitly set the value to ``None``,\n",
      "     |              then the data type will be ``numpy.dtype(\"int64\")``. A list of BigQuery\n",
      "     |              Integer types can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#integer_types\n",
      "     |\n",
      "     |              .. versionadded:: 3.8.0\n",
      "     |\n",
      "     |          float_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g. ``pandas.Float32Dtype()``)\n",
      "     |              to convert BigQuery Float type, instead of relying on the default\n",
      "     |              ``numpy.dtype(\"float64\")``. If you explicitly set the value to ``None``,\n",
      "     |              then the data type will be ``numpy.dtype(\"float64\")``. BigQuery Float\n",
      "     |              type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#floating_point_types\n",
      "     |\n",
      "     |              .. versionadded:: 3.8.0\n",
      "     |\n",
      "     |          string_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g. ``pandas.StringDtype()``) to\n",
      "     |              convert BigQuery String type, instead of relying on the default\n",
      "     |              ``numpy.dtype(\"object\")``. If you explicitly set the value to ``None``,\n",
      "     |              then the data type will be ``numpy.dtype(\"object\")``. BigQuery String\n",
      "     |              type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#string_type\n",
      "     |\n",
      "     |              .. versionadded:: 3.8.0\n",
      "     |\n",
      "     |          date_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g.\n",
      "     |              ``pandas.ArrowDtype(pyarrow.date32())``) to convert BigQuery Date\n",
      "     |              type, instead of relying on the default ``db_dtypes.DateDtype()``.\n",
      "     |              If you explicitly set the value to ``None``, then the data type will be\n",
      "     |              ``numpy.dtype(\"datetime64[ns]\")`` or ``object`` if out of bound. BigQuery\n",
      "     |              Date type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#date_type\n",
      "     |\n",
      "     |              .. versionadded:: 3.10.0\n",
      "     |\n",
      "     |          datetime_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g.\n",
      "     |              ``pandas.ArrowDtype(pyarrow.timestamp(\"us\"))``) to convert BigQuery Datetime\n",
      "     |              type, instead of relying on the default ``numpy.dtype(\"datetime64[ns]``.\n",
      "     |              If you explicitly set the value to ``None``, then the data type will be\n",
      "     |              ``numpy.dtype(\"datetime64[ns]\")`` or ``object`` if out of bound. BigQuery\n",
      "     |              Datetime type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#datetime_type\n",
      "     |\n",
      "     |              .. versionadded:: 3.10.0\n",
      "     |\n",
      "     |          time_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g.\n",
      "     |              ``pandas.ArrowDtype(pyarrow.time64(\"us\"))``) to convert BigQuery Time\n",
      "     |              type, instead of relying on the default ``db_dtypes.TimeDtype()``.\n",
      "     |              If you explicitly set the value to ``None``, then the data type will be\n",
      "     |              ``numpy.dtype(\"object\")``. BigQuery Time type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#time_type\n",
      "     |\n",
      "     |              .. versionadded:: 3.10.0\n",
      "     |\n",
      "     |          timestamp_dtype (Optional[pandas.Series.dtype, None]):\n",
      "     |              If set, indicate a pandas ExtensionDtype (e.g.\n",
      "     |              ``pandas.ArrowDtype(pyarrow.timestamp(\"us\", tz=\"UTC\"))``) to convert BigQuery Timestamp\n",
      "     |              type, instead of relying on the default ``numpy.dtype(\"datetime64[ns, UTC]\")``.\n",
      "     |              If you explicitly set the value to ``None``, then the data type will be\n",
      "     |              ``numpy.dtype(\"datetime64[ns, UTC]\")`` or ``object`` if out of bound. BigQuery\n",
      "     |              Datetime type can be found at:\n",
      "     |              https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#timestamp_type\n",
      "     |\n",
      "     |              .. versionadded:: 3.10.0\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          pandas.DataFrame:\n",
      "     |              A :class:`~pandas.DataFrame` populated with row data\n",
      "     |              and column headers from the query results. The column\n",
      "     |              headers are derived from the destination table's\n",
      "     |              schema.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the :mod:`pandas` library cannot be imported, or\n",
      "     |              the :mod:`google.cloud.bigquery_storage_v1` module is\n",
      "     |              required but cannot be imported.  Also if\n",
      "     |              `geography_as_object` is `True`, but the\n",
      "     |              :mod:`shapely` library cannot be imported.\n",
      "     |\n",
      "     |  to_geodataframe(self, bqstorage_client: Optional[ForwardRef('bigquery_storage.BigQueryReadClient')] = None, dtypes: Optional[Dict[str, Any]] = None, progress_bar_type: Optional[str] = None, create_bqstorage_client: bool = True, max_results: Optional[int] = None, geography_column: Optional[str] = None) -> 'geopandas.GeoDataFrame'\n",
      "     |      Return a GeoPandas GeoDataFrame from a QueryJob\n",
      "     |\n",
      "     |      Args:\n",
      "     |          bqstorage_client (Optional[google.cloud.bigquery_storage_v1.BigQueryReadClient]):\n",
      "     |              A BigQuery Storage API client. If supplied, use the faster\n",
      "     |              BigQuery Storage API to fetch rows from BigQuery. This\n",
      "     |              API is a billable API.\n",
      "     |\n",
      "     |              This method requires the ``fastavro`` and\n",
      "     |              ``google-cloud-bigquery-storage`` libraries.\n",
      "     |\n",
      "     |              Reading from a specific partition or snapshot is not\n",
      "     |              currently supported by this method.\n",
      "     |\n",
      "     |          dtypes (Optional[Map[str, Union[str, pandas.Series.dtype]]]):\n",
      "     |              A dictionary of column names pandas ``dtype``s. The provided\n",
      "     |              ``dtype`` is used when constructing the series for the column\n",
      "     |              specified. Otherwise, the default pandas behavior is used.\n",
      "     |\n",
      "     |          progress_bar_type (Optional[str]):\n",
      "     |              If set, use the `tqdm <https://tqdm.github.io/>`_ library to\n",
      "     |              display a progress bar while the data downloads. Install the\n",
      "     |              ``tqdm`` package to use this feature.\n",
      "     |\n",
      "     |              See\n",
      "     |              :func:`~google.cloud.bigquery.table.RowIterator.to_dataframe`\n",
      "     |              for details.\n",
      "     |\n",
      "     |              .. versionadded:: 1.11.0\n",
      "     |          create_bqstorage_client (Optional[bool]):\n",
      "     |              If ``True`` (default), create a BigQuery Storage API client\n",
      "     |              using the default API settings. The BigQuery Storage API\n",
      "     |              is a faster way to fetch rows from BigQuery. See the\n",
      "     |              ``bqstorage_client`` parameter for more information.\n",
      "     |\n",
      "     |              This argument does nothing if ``bqstorage_client`` is supplied.\n",
      "     |\n",
      "     |              .. versionadded:: 1.24.0\n",
      "     |\n",
      "     |          max_results (Optional[int]):\n",
      "     |              Maximum number of rows to include in the result. No limit by default.\n",
      "     |\n",
      "     |              .. versionadded:: 2.21.0\n",
      "     |\n",
      "     |          geography_column (Optional[str]):\n",
      "     |              If there are more than one GEOGRAPHY column,\n",
      "     |              identifies which one to use to construct a GeoPandas\n",
      "     |              GeoDataFrame.  This option can be ommitted if there's\n",
      "     |              only one GEOGRAPHY column.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          geopandas.GeoDataFrame:\n",
      "     |              A :class:`geopandas.GeoDataFrame` populated with row\n",
      "     |              data and column headers from the query results. The\n",
      "     |              column headers are derived from the destination\n",
      "     |              table's schema.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |             If the :mod:`geopandas` library cannot be imported, or the\n",
      "     |              :mod:`google.cloud.bigquery_storage_v1` module is\n",
      "     |              required but cannot be imported.\n",
      "     |\n",
      "     |      .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict, client: 'Client') -> 'QueryJob' from abc.ABCMeta\n",
      "     |      Factory:  construct a job given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): dataset job representation returned from the API\n",
      "     |\n",
      "     |          client (google.cloud.bigquery.client.Client):\n",
      "     |              Client which holds credentials and project\n",
      "     |              configuration for the dataset.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job.QueryJob: Job parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  allow_large_results\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.allow_large_results`.\n",
      "     |\n",
      "     |  bi_engine_stats\n",
      "     |\n",
      "     |  billing_tier\n",
      "     |      Return billing tier from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.billing_tier\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]:\n",
      "     |              Billing tier used by the job, or None if job is not\n",
      "     |              yet complete.\n",
      "     |\n",
      "     |  cache_hit\n",
      "     |      Return whether or not query results were served from cache.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.cache_hit\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[bool]:\n",
      "     |              whether the query results were returned from cache, or None\n",
      "     |              if job is not yet complete.\n",
      "     |\n",
      "     |  clustering_fields\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.clustering_fields`.\n",
      "     |\n",
      "     |  configuration\n",
      "     |      The configuration for this query job.\n",
      "     |\n",
      "     |  connection_properties\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.connection_properties`.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  create_disposition\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.create_disposition`.\n",
      "     |\n",
      "     |  create_session\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.create_session`.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  ddl_operation_performed\n",
      "     |      Optional[str]: Return the DDL operation performed.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.ddl_operation_performed\n",
      "     |\n",
      "     |  ddl_target_routine\n",
      "     |      Optional[google.cloud.bigquery.routine.RoutineReference]: Return the DDL target routine, present\n",
      "     |          for CREATE/DROP FUNCTION/PROCEDURE  queries.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.ddl_target_routine\n",
      "     |\n",
      "     |  ddl_target_table\n",
      "     |      Optional[google.cloud.bigquery.table.TableReference]: Return the DDL target table, present\n",
      "     |          for CREATE/DROP TABLE/VIEW queries.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.ddl_target_table\n",
      "     |\n",
      "     |  default_dataset\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.default_dataset`.\n",
      "     |\n",
      "     |  destination\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.destination`.\n",
      "     |\n",
      "     |  destination_encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for the destination table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.destination_encryption_configuration`.\n",
      "     |\n",
      "     |  dml_stats\n",
      "     |\n",
      "     |  dry_run\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.dry_run`.\n",
      "     |\n",
      "     |  estimated_bytes_processed\n",
      "     |      Return the estimated number of bytes processed by the query.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.estimated_bytes_processed\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]:\n",
      "     |              number of DML rows affected by the job, or None if job is not\n",
      "     |              yet complete.\n",
      "     |\n",
      "     |  flatten_results\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.flatten_results`.\n",
      "     |\n",
      "     |  maximum_billing_tier\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.maximum_billing_tier`.\n",
      "     |\n",
      "     |  maximum_bytes_billed\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.maximum_bytes_billed`.\n",
      "     |\n",
      "     |  num_dml_affected_rows\n",
      "     |      Return the number of DML rows affected by the job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.num_dml_affected_rows\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]:\n",
      "     |              number of DML rows affected by the job, or None if job is not\n",
      "     |              yet complete.\n",
      "     |\n",
      "     |  priority\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.priority`.\n",
      "     |\n",
      "     |  query\n",
      "     |      str: The query text used in this query job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.query\n",
      "     |\n",
      "     |  query_id\n",
      "     |      [Preview] ID of a completed query.\n",
      "     |\n",
      "     |      This ID is auto-generated and not guaranteed to be populated.\n",
      "     |\n",
      "     |  query_parameters\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.query_parameters`.\n",
      "     |\n",
      "     |  query_plan\n",
      "     |      Return query plan from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.query_plan\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[google.cloud.bigquery.job.QueryPlanEntry]:\n",
      "     |              mappings describing the query plan, or an empty list\n",
      "     |              if the query has not yet completed.\n",
      "     |\n",
      "     |  range_partitioning\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.range_partitioning`.\n",
      "     |\n",
      "     |  referenced_tables\n",
      "     |      Return referenced tables from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.referenced_tables\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[Dict]:\n",
      "     |              mappings describing the query plan, or an empty list\n",
      "     |              if the query has not yet completed.\n",
      "     |\n",
      "     |  schema\n",
      "     |      The schema of the results.\n",
      "     |\n",
      "     |      Present only for successful dry run of non-legacy SQL queries.\n",
      "     |\n",
      "     |  schema_update_options\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.schema_update_options`.\n",
      "     |\n",
      "     |  search_stats\n",
      "     |      Returns a SearchStats object.\n",
      "     |\n",
      "     |  slot_millis\n",
      "     |      Union[int, None]: Slot-milliseconds used by this query job.\n",
      "     |\n",
      "     |  statement_type\n",
      "     |      Return statement type from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.statement_type\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]:\n",
      "     |              type of statement used by the job, or None if job is not\n",
      "     |              yet complete.\n",
      "     |\n",
      "     |  table_definitions\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.table_definitions`.\n",
      "     |\n",
      "     |  time_partitioning\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.time_partitioning`.\n",
      "     |\n",
      "     |  timeline\n",
      "     |      List(TimelineEntry): Return the query execution timeline\n",
      "     |      from job statistics.\n",
      "     |\n",
      "     |  total_bytes_billed\n",
      "     |      Return total bytes billed from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.total_bytes_billed\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]:\n",
      "     |              Total bytes processed by the job, or None if job is not\n",
      "     |              yet complete.\n",
      "     |\n",
      "     |  total_bytes_processed\n",
      "     |      Return total bytes processed from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.total_bytes_processed\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[int]:\n",
      "     |              Total bytes processed by the job, or None if job is not\n",
      "     |              yet complete.\n",
      "     |\n",
      "     |  udf_resources\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.udf_resources`.\n",
      "     |\n",
      "     |  undeclared_query_parameters\n",
      "     |      Return undeclared query parameters from job statistics, if present.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics2.FIELDS.undeclared_query_parameters\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[Union[                 google.cloud.bigquery.query.ArrayQueryParameter,                 google.cloud.bigquery.query.ScalarQueryParameter,                 google.cloud.bigquery.query.StructQueryParameter             ]]:\n",
      "     |              Undeclared parameters, or an empty list if the query has\n",
      "     |              not yet completed.\n",
      "     |\n",
      "     |  use_legacy_sql\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.use_legacy_sql`.\n",
      "     |\n",
      "     |  use_query_cache\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.use_query_cache`.\n",
      "     |\n",
      "     |  write_disposition\n",
      "     |      See\n",
      "     |      :attr:`google.cloud.bigquery.job.QueryJobConfig.write_disposition`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  cancel(self, client=None, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  cancel job via a POST request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating that the cancel request was sent.\n",
      "     |\n",
      "     |  cancelled(self)\n",
      "     |      Check if the job has been cancelled.\n",
      "     |\n",
      "     |      This always returns False. It's not possible to check if a job was\n",
      "     |      cancelled in the API. This method is here to satisfy the interface\n",
      "     |      for :class:`google.api_core.future.Future`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: False\n",
      "     |\n",
      "     |  done(self, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, reload: bool = True) -> bool\n",
      "     |      Checks if the job is complete.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          reload (Optional[bool]):\n",
      "     |              If ``True``, make an API call to refresh the job state of\n",
      "     |              unfinished jobs before checking. Default ``True``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: True if the job is complete, False otherwise.\n",
      "     |\n",
      "     |  exists(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  test for the existence of the job via a GET request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating existence of the job.\n",
      "     |\n",
      "     |  reload(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None)\n",
      "     |      API call:  refresh job properties via a GET request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from google.cloud.bigquery.job.base._AsyncJob:\n",
      "     |\n",
      "     |  created\n",
      "     |      Datetime at which the job was created.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the creation time (None until set from the server).\n",
      "     |\n",
      "     |  ended\n",
      "     |      Datetime at which the job finished.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the end time (None until set from the server).\n",
      "     |\n",
      "     |  error_result\n",
      "     |      Error information about the job as a whole.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[Mapping]: the error information (None until set from the server).\n",
      "     |\n",
      "     |  errors\n",
      "     |      Information about individual errors generated by the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[List[Mapping]]:\n",
      "     |              the error information (None until set from the server).\n",
      "     |\n",
      "     |  etag\n",
      "     |      ETag for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the ETag (None until set from the server).\n",
      "     |\n",
      "     |  job_id\n",
      "     |      str: ID of the job.\n",
      "     |\n",
      "     |  job_type\n",
      "     |      Type of job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: one of 'load', 'copy', 'extract', 'query'.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |  location\n",
      "     |      str: Location where the job runs.\n",
      "     |\n",
      "     |  num_child_jobs\n",
      "     |      The number of child jobs executed.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.num_child_jobs\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          int\n",
      "     |\n",
      "     |  parent_job_id\n",
      "     |      Return the ID of the parent job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.parent_job_id\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: parent job id.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the job's APIs.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the path based on project and job ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the project (derived from the client).\n",
      "     |\n",
      "     |  reservation_usage\n",
      "     |      Job resource usage breakdown by reservation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[google.cloud.bigquery.job.ReservationUsage]:\n",
      "     |              Reservation usage stats. Can be empty if not set from the server.\n",
      "     |\n",
      "     |  script_statistics\n",
      "     |      Statistics for a child job of a script.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      URL for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  session_info\n",
      "     |      [Preview] Information of the session if this job is part of one.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  started\n",
      "     |      Datetime at which the job was started.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the start time (None until set from the server).\n",
      "     |\n",
      "     |  state\n",
      "     |      Status of the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]:\n",
      "     |              the state (None until set from the server).\n",
      "     |\n",
      "     |  transaction_info\n",
      "     |      Information of the multi-statement transaction if this job is part of one.\n",
      "     |\n",
      "     |      Since a scripting query job can execute multiple transactions, this\n",
      "     |      property is only expected on child jobs. Use the\n",
      "     |      :meth:`google.cloud.bigquery.client.Client.list_jobs` method with the\n",
      "     |      ``parent_job`` parameter to iterate over child jobs.\n",
      "     |\n",
      "     |      .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  user_email\n",
      "     |      E-mail address of user who submitted the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.api_core.future.polling.PollingFuture:\n",
      "     |\n",
      "     |  add_done_callback(self, fn)\n",
      "     |      Add a callback to be executed when the operation is complete.\n",
      "     |\n",
      "     |      If the operation is not already complete, this will start a helper\n",
      "     |      thread to poll for the status of the operation in the background.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          fn (Callable[Future]): The callback to execute when the operation\n",
      "     |              is complete.\n",
      "     |\n",
      "     |  exception(self, timeout=<object object at 0x7202a04c6650>)\n",
      "     |      Get the exception from the operation, blocking if necessary.\n",
      "     |\n",
      "     |      See the documentation for the :meth:`result` method for details on how\n",
      "     |      this method operates, as both ``result`` and this method rely on the\n",
      "     |      exact same polling logic. The only difference is that this method does\n",
      "     |      not accept ``retry`` and ``polling`` arguments but relies on the default ones\n",
      "     |      instead.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          timeout (int): How long to wait for the operation to complete.\n",
      "     |          If None, wait indefinitely.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[google.api_core.GoogleAPICallError]: The operation's\n",
      "     |              error.\n",
      "     |\n",
      "     |  running(self)\n",
      "     |      True if the operation is currently running.\n",
      "     |\n",
      "     |  set_exception(self, exception)\n",
      "     |      Set the Future's exception.\n",
      "     |\n",
      "     |  set_result(self, result)\n",
      "     |      Set the Future's result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.api_core.future.base.Future:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class QueryJobConfig(google.cloud.bigquery.job.base._JobConfig)\n",
      "     |  QueryJobConfig(**kwargs) -> None\n",
      "     |\n",
      "     |  Configuration options for query jobs.\n",
      "     |\n",
      "     |  All properties in this class are optional. Values which are :data:`None` ->\n",
      "     |  server defaults. Set properties on the constructed configuration by using\n",
      "     |  the property name as the name of a keyword argument.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      QueryJobConfig\n",
      "     |      google.cloud.bigquery.job.base._JobConfig\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, **kwargs) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Build an API representation of the query job config.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: A dictionary in the format used by the BigQuery API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  allow_large_results\n",
      "     |      bool: Allow large query results tables (legacy SQL, only)\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.allow_large_results\n",
      "     |\n",
      "     |  clustering_fields\n",
      "     |      Optional[List[str]]: Fields defining clustering for the table\n",
      "     |\n",
      "     |      (Defaults to :data:`None`).\n",
      "     |\n",
      "     |      Clustering fields are immutable after table creation.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         BigQuery supports clustering for both partitioned and\n",
      "     |         non-partitioned tables.\n",
      "     |\n",
      "     |  connection_properties\n",
      "     |      Connection properties.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.connection_properties\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  create_disposition\n",
      "     |      google.cloud.bigquery.job.CreateDisposition: Specifies behavior\n",
      "     |      for creating tables.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.create_disposition\n",
      "     |\n",
      "     |  create_session\n",
      "     |      [Preview] If :data:`True`, creates a new session, where\n",
      "     |      :attr:`~google.cloud.bigquery.job.QueryJob.session_info` will contain a\n",
      "     |      random server generated session id.\n",
      "     |\n",
      "     |      If :data:`False`, runs query with an existing ``session_id`` passed in\n",
      "     |      :attr:`~google.cloud.bigquery.job.QueryJobConfig.connection_properties`,\n",
      "     |      otherwise runs query in non-session mode.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.create_session\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  default_dataset\n",
      "     |      google.cloud.bigquery.dataset.DatasetReference: the default dataset\n",
      "     |      to use for unqualified table names in the query or :data:`None` if not\n",
      "     |      set.\n",
      "     |\n",
      "     |      The ``default_dataset`` setter accepts:\n",
      "     |\n",
      "     |      - a :class:`~google.cloud.bigquery.dataset.Dataset`, or\n",
      "     |      - a :class:`~google.cloud.bigquery.dataset.DatasetReference`, or\n",
      "     |      - a :class:`str` of the fully-qualified dataset ID in standard SQL\n",
      "     |        format. The value must included a project ID and dataset ID\n",
      "     |        separated by ``.``. For example: ``your-project.your_dataset``.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.default_dataset\n",
      "     |\n",
      "     |  destination\n",
      "     |      google.cloud.bigquery.table.TableReference: table where results are\n",
      "     |      written or :data:`None` if not set.\n",
      "     |\n",
      "     |      The ``destination`` setter accepts:\n",
      "     |\n",
      "     |      - a :class:`~google.cloud.bigquery.table.Table`, or\n",
      "     |      - a :class:`~google.cloud.bigquery.table.TableReference`, or\n",
      "     |      - a :class:`str` of the fully-qualified table ID in standard SQL\n",
      "     |        format. The value must included a project ID, dataset ID, and table\n",
      "     |        ID, each separated by ``.``. For example:\n",
      "     |        ``your-project.your_dataset.your_table``.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.destination_table\n",
      "     |\n",
      "     |  destination_encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for the destination table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.destination_encryption_configuration\n",
      "     |\n",
      "     |  dry_run\n",
      "     |      bool: :data:`True` if this query should be a dry run to estimate\n",
      "     |      costs.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfiguration.FIELDS.dry_run\n",
      "     |\n",
      "     |  flatten_results\n",
      "     |      bool: Flatten nested/repeated fields in results. (Legacy SQL only)\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.flatten_results\n",
      "     |\n",
      "     |  maximum_billing_tier\n",
      "     |      int: Deprecated. Changes the billing tier to allow high-compute\n",
      "     |      queries.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.maximum_billing_tier\n",
      "     |\n",
      "     |  maximum_bytes_billed\n",
      "     |      int: Maximum bytes to be billed for this job or :data:`None` if not set.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.maximum_bytes_billed\n",
      "     |\n",
      "     |  priority\n",
      "     |      google.cloud.bigquery.job.QueryPriority: Priority of the query.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.priority\n",
      "     |\n",
      "     |  query_parameters\n",
      "     |      List[Union[google.cloud.bigquery.query.ArrayQueryParameter,         google.cloud.bigquery.query.ScalarQueryParameter,         google.cloud.bigquery.query.StructQueryParameter]]: list of parameters\n",
      "     |      for parameterized query (empty by default)\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.query_parameters\n",
      "     |\n",
      "     |  range_partitioning\n",
      "     |      Optional[google.cloud.bigquery.table.RangePartitioning]:\n",
      "     |      Configures range-based partitioning for destination table.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          **Beta**. The integer range partitioning feature is in a\n",
      "     |          pre-release state and might change or have limited support.\n",
      "     |\n",
      "     |      Only specify at most one of\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.time_partitioning` or\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.range_partitioning`.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not\n",
      "     |              :class:`~google.cloud.bigquery.table.RangePartitioning` or\n",
      "     |              :data:`None`.\n",
      "     |\n",
      "     |  schema_update_options\n",
      "     |      List[google.cloud.bigquery.job.SchemaUpdateOption]: Specifies\n",
      "     |      updates to the destination table schema to allow as a side effect of\n",
      "     |      the query job.\n",
      "     |\n",
      "     |  script_options\n",
      "     |      Options controlling the execution of scripts.\n",
      "     |\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#scriptoptions\n",
      "     |\n",
      "     |  table_definitions\n",
      "     |      Dict[str, google.cloud.bigquery.external_config.ExternalConfig]:\n",
      "     |      Definitions for external tables or :data:`None` if not set.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.external_table_definitions\n",
      "     |\n",
      "     |  time_partitioning\n",
      "     |      Optional[google.cloud.bigquery.table.TimePartitioning]: Specifies\n",
      "     |      time-based partitioning for the destination table.\n",
      "     |\n",
      "     |      Only specify at most one of\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.time_partitioning` or\n",
      "     |      :attr:`~google.cloud.bigquery.job.LoadJobConfig.range_partitioning`.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not\n",
      "     |              :class:`~google.cloud.bigquery.table.TimePartitioning` or\n",
      "     |              :data:`None`.\n",
      "     |\n",
      "     |  udf_resources\n",
      "     |      List[google.cloud.bigquery.query.UDFResource]: user\n",
      "     |      defined function resources (empty by default)\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.user_defined_function_resources\n",
      "     |\n",
      "     |  use_legacy_sql\n",
      "     |      bool: Use legacy SQL syntax.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.use_legacy_sql\n",
      "     |\n",
      "     |  use_query_cache\n",
      "     |      bool: Look for the query result in the cache.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.use_query_cache\n",
      "     |\n",
      "     |  write_disposition\n",
      "     |      google.cloud.bigquery.job.WriteDisposition: Action that occurs if\n",
      "     |      the destination table already exists.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfigurationQuery.FIELDS.write_disposition\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Override to be able to raise error if an unknown property is being set\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> '_JobConfig' from builtins.type\n",
      "     |      Factory: construct a job configuration given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict):\n",
      "     |              A job configuration in the same representation as is returned\n",
      "     |              from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.job._JobConfig: Configuration parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.cloud.bigquery.job.base._JobConfig:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  job_timeout_ms\n",
      "     |      Optional parameter. Job timeout in milliseconds. If this time limit is exceeded, BigQuery might attempt to stop the job.\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobConfiguration.FIELDS.job_timeout_ms\n",
      "     |      e.g.\n",
      "     |\n",
      "     |          job_config = bigquery.QueryJobConfig( job_timeout_ms = 5000 )\n",
      "     |          or\n",
      "     |          job_config.job_timeout_ms = 5000\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |      This method always returns a dict. Once a job has been created on the\n",
      "     |      server, its labels cannot be modified anymore.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "\n",
      "    class QueryPriority(builtins.object)\n",
      "     |  Specifies a priority for the query. The default value is\n",
      "     |  :attr:`INTERACTIVE`.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  BATCH = 'BATCH'\n",
      "     |\n",
      "     |  INTERACTIVE = 'INTERACTIVE'\n",
      "\n",
      "    class RangePartitioning(builtins.object)\n",
      "     |  RangePartitioning(range_=None, field=None, _properties=None) -> None\n",
      "     |\n",
      "     |  Range-based partitioning configuration for a table.\n",
      "     |\n",
      "     |  .. note::\n",
      "     |      **Beta**. The integer range partitioning feature is in a pre-release\n",
      "     |      state and might change or have limited support.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      range_ (Optional[google.cloud.bigquery.table.PartitionRange]):\n",
      "     |          Sets the\n",
      "     |          :attr:`google.cloud.bigquery.table.RangePartitioning.range_`\n",
      "     |          property.\n",
      "     |      field (Optional[str]):\n",
      "     |          Sets the\n",
      "     |          :attr:`google.cloud.bigquery.table.RangePartitioning.field`\n",
      "     |          property.\n",
      "     |      _properties (Optional[dict]):\n",
      "     |          Private. Used to construct object from API resource.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, range_=None, field=None, _properties=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  field\n",
      "     |      str: The table is partitioned by this field.\n",
      "     |\n",
      "     |      The field must be a top-level ``NULLABLE`` / ``REQUIRED`` field. The\n",
      "     |      only supported type is ``INTEGER`` / ``INT64``.\n",
      "     |\n",
      "     |  range_\n",
      "     |      google.cloud.bigquery.table.PartitionRange: Defines the\n",
      "     |      ranges for range partitioning.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not a :class:`PartitionRange`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class RangeQueryParameter(_AbstractQueryParameter)\n",
      "     |  RangeQueryParameter(range_element_type, start=None, end=None, name=None)\n",
      "     |\n",
      "     |  Named / positional query parameters for range values.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      range_element_type (Union[str, RangeQueryParameterType]):\n",
      "     |          The type of range elements. It must be one of 'TIMESTAMP',\n",
      "     |          'DATE', or 'DATETIME'.\n",
      "     |\n",
      "     |      start (Optional[Union[ScalarQueryParameter, str]]):\n",
      "     |          The start of the range value. Must be the same type as\n",
      "     |          range_element_type. If not provided, it's interpreted as UNBOUNDED.\n",
      "     |\n",
      "     |      end (Optional[Union[ScalarQueryParameter, str]]):\n",
      "     |          The end of the range value. Must be the same type as\n",
      "     |          range_element_type. If not provided, it's interpreted as UNBOUNDED.\n",
      "     |\n",
      "     |      name (Optional[str]):\n",
      "     |          Parameter name, used via ``@foo`` syntax.  If None, the\n",
      "     |          parameter can only be addressed via position (``?``).\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RangeQueryParameter\n",
      "     |      _AbstractQueryParameter\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, range_element_type, start=None, end=None, name=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct JSON API representation for the parameter.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'RangeQueryParameter' from builtins.type\n",
      "     |      Factory: construct parameter from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.RangeQueryParameter: Instance\n",
      "     |\n",
      "     |  positional(range_element_type, start=None, end=None) -> 'RangeQueryParameter' from builtins.type\n",
      "     |      Factory for positional parameters.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          range_element_type (Union[str, RangeQueryParameterType]):\n",
      "     |              The type of range elements. It must be one of `'TIMESTAMP'`,\n",
      "     |              `'DATE'`, or `'DATETIME'`.\n",
      "     |\n",
      "     |          start (Optional[Union[ScalarQueryParameter, str]]):\n",
      "     |              The start of the range value. Must be the same type as\n",
      "     |              range_element_type. If not provided, it's interpreted as\n",
      "     |              UNBOUNDED.\n",
      "     |\n",
      "     |          end (Optional[Union[ScalarQueryParameter, str]]):\n",
      "     |              The end of the range value. Must be the same type as\n",
      "     |              range_element_type. If not provided, it's interpreted as\n",
      "     |              UNBOUNDED.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.RangeQueryParameter: Instance without\n",
      "     |          name.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameter:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class RangeQueryParameterType(_AbstractQueryParameterType)\n",
      "     |  RangeQueryParameterType(type_, *, name=None, description=None)\n",
      "     |\n",
      "     |  Type representation for range query parameters.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      type_ (Union[ScalarQueryParameterType, str]):\n",
      "     |          Type of range element, must be one of 'TIMESTAMP', 'DATETIME', or\n",
      "     |          'DATE'.\n",
      "     |      name (Optional[str]):\n",
      "     |          The name of the query parameter. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |      description (Optional[str]):\n",
      "     |          The query parameter description. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RangeQueryParameterType\n",
      "     |      _AbstractQueryParameterType\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, type_, *, name=None, description=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Construct JSON API representation for the parameter type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  with_name(self, new_name: Optional[str])\n",
      "     |      Return a copy of the instance with ``name`` set to ``new_name``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          name (Union[str, None]):\n",
      "     |              The new name of the range query parameter type. If ``None``,\n",
      "     |              the existing name is cleared.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.RangeQueryParameterType:\n",
      "     |             A new instance with updated name.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource) from builtins.type\n",
      "     |      Factory: construct parameter type from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.RangeQueryParameterType: Instance\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameterType:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class RemoteFunctionOptions(builtins.object)\n",
      "     |  RemoteFunctionOptions(endpoint=None, connection=None, max_batching_rows=None, user_defined_context=None, _properties=None) -> None\n",
      "     |\n",
      "     |  Configuration options for controlling remote BigQuery functions.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, endpoint=None, connection=None, max_batching_rows=None, user_defined_context=None, _properties=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this RemoteFunctionOptions.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Remote function options represented as an API resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'RemoteFunctionOptions' from builtins.type\n",
      "     |      Factory: construct remote function options given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]): Resource, as returned from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.RemoteFunctionOptions:\n",
      "     |              Python object, as parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  connection\n",
      "     |      string: Fully qualified name of the user-provided connection object which holds the authentication information to send requests to the remote service.\n",
      "     |\n",
      "     |      Format is  \"projects/{projectId}/locations/{locationId}/connections/{connectionId}\"\n",
      "     |\n",
      "     |  endpoint\n",
      "     |      string: Endpoint of the user-provided remote service\n",
      "     |\n",
      "     |      Example: \"https://us-east1-my_gcf_project.cloudfunctions.net/remote_add\"\n",
      "     |\n",
      "     |  max_batching_rows\n",
      "     |      int64: Max number of rows in each batch sent to the remote service.\n",
      "     |\n",
      "     |      If absent or if 0, BigQuery dynamically decides the number of rows in a batch.\n",
      "     |\n",
      "     |  user_defined_context\n",
      "     |      Dict[str, str]: User-defined context as a set of key/value pairs,\n",
      "     |          which will be sent as function invocation context together with\n",
      "     |      batched arguments in the requests to the remote service. The total\n",
      "     |          number of bytes of keys and values must be less than 8KB.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class Routine(builtins.object)\n",
      "     |  Routine(routine_ref, **kwargs) -> None\n",
      "     |\n",
      "     |  Resource representing a user-defined routine.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/routines\n",
      "     |\n",
      "     |  Args:\n",
      "     |      routine_ref (Union[str, google.cloud.bigquery.routine.RoutineReference]):\n",
      "     |          A pointer to a routine. If ``routine_ref`` is a string, it must\n",
      "     |          included a project ID, dataset ID, and routine ID, each separated\n",
      "     |          by ``.``.\n",
      "     |      ``**kwargs`` (Dict):\n",
      "     |          Initial property values.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, routine_ref, **kwargs) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this routine.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Routine represented as an API resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'Routine' from builtins.type\n",
      "     |      Factory: construct a routine given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]):\n",
      "     |              Resource, as returned from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.Routine:\n",
      "     |              Python object, as parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  created\n",
      "     |      Optional[datetime.datetime]: Datetime at which the routine was\n",
      "     |      created (:data:`None` until set from the server).\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      str: ID of dataset containing the routine.\n",
      "     |\n",
      "     |  etag\n",
      "     |      str: ETag for the resource (:data:`None` until set from the\n",
      "     |      server).\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  modified\n",
      "     |      Optional[datetime.datetime]: Datetime at which the routine was\n",
      "     |      last modified (:data:`None` until set from the server).\n",
      "     |\n",
      "     |      Read-only.\n",
      "     |\n",
      "     |  path\n",
      "     |      str: URL path for the routine's APIs.\n",
      "     |\n",
      "     |  project\n",
      "     |      str: ID of the project containing the routine.\n",
      "     |\n",
      "     |  reference\n",
      "     |      google.cloud.bigquery.routine.RoutineReference: Reference\n",
      "     |      describing the ID of this routine.\n",
      "     |\n",
      "     |  routine_id\n",
      "     |      str: The routine ID.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  arguments\n",
      "     |      List[google.cloud.bigquery.routine.RoutineArgument]: Input/output\n",
      "     |      argument of a function or a stored procedure.\n",
      "     |\n",
      "     |      In-place modification is not supported. To set, replace the entire\n",
      "     |      property value with the modified list of\n",
      "     |      :class:`~google.cloud.bigquery.routine.RoutineArgument` objects.\n",
      "     |\n",
      "     |  body\n",
      "     |      str: The body of the routine.\n",
      "     |\n",
      "     |  data_governance_type\n",
      "     |      Optional[str]: If set to ``DATA_MASKING``, the function is validated\n",
      "     |      and made available as a masking function.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not :data:`string` or :data:`None`.\n",
      "     |\n",
      "     |  description\n",
      "     |      Optional[str]: Description of the routine (defaults to\n",
      "     |      :data:`None`).\n",
      "     |\n",
      "     |  determinism_level\n",
      "     |      Optional[str]: (experimental) The determinism level of the JavaScript UDF\n",
      "     |      if defined.\n",
      "     |\n",
      "     |  imported_libraries\n",
      "     |      List[str]: The path of the imported JavaScript libraries.\n",
      "     |\n",
      "     |      The :attr:`~google.cloud.bigquery.routine.Routine.language` must\n",
      "     |      equal ``JAVACRIPT``.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |          Set the ``imported_libraries`` to a list of Google Cloud Storage\n",
      "     |          URIs.\n",
      "     |\n",
      "     |          .. code-block:: python\n",
      "     |\n",
      "     |             routine = bigquery.Routine(\"proj.dataset.routine_id\")\n",
      "     |             routine.imported_libraries = [\n",
      "     |                 \"gs://cloud-samples-data/bigquery/udfs/max-value.js\",\n",
      "     |             ]\n",
      "     |\n",
      "     |  language\n",
      "     |      Optional[str]: The language of the routine.\n",
      "     |\n",
      "     |      Defaults to ``SQL``.\n",
      "     |\n",
      "     |  remote_function_options\n",
      "     |      Optional[google.cloud.bigquery.routine.RemoteFunctionOptions]:\n",
      "     |      Configures remote function options for a routine.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not\n",
      "     |              :class:`~google.cloud.bigquery.routine.RemoteFunctionOptions` or\n",
      "     |              :data:`None`.\n",
      "     |\n",
      "     |  return_table_type\n",
      "     |      The return type of a Table Valued Function (TVF) routine.\n",
      "     |\n",
      "     |      .. versionadded:: 2.22.0\n",
      "     |\n",
      "     |  return_type\n",
      "     |      google.cloud.bigquery.StandardSqlDataType: Return type of\n",
      "     |      the routine.\n",
      "     |\n",
      "     |      If absent, the return type is inferred from\n",
      "     |      :attr:`~google.cloud.bigquery.routine.Routine.body` at query time in\n",
      "     |      each query that references this routine. If present, then the\n",
      "     |      evaluated result will be cast to the specified returned type at query\n",
      "     |      time.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#Routine.FIELDS.return_type\n",
      "     |\n",
      "     |  type_\n",
      "     |      str: The fine-grained type of the routine.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#RoutineType\n",
      "\n",
      "    class RoutineArgument(builtins.object)\n",
      "     |  RoutineArgument(**kwargs) -> None\n",
      "     |\n",
      "     |  Input/output argument of a function or a stored procedure.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#argument\n",
      "     |\n",
      "     |  Args:\n",
      "     |      ``**kwargs`` (Dict):\n",
      "     |          Initial property values.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, **kwargs) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this routine argument.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Routine argument represented as an API resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'RoutineArgument' from builtins.type\n",
      "     |      Factory: construct a routine argument given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]): Resource, as returned from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.RoutineArgument:\n",
      "     |              Python object, as parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  data_type\n",
      "     |      Optional[google.cloud.bigquery.StandardSqlDataType]: Type\n",
      "     |      of a variable, e.g., a function argument.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#Argument.FIELDS.data_type\n",
      "     |\n",
      "     |  kind\n",
      "     |      Optional[str]: The kind of argument, for example ``FIXED_TYPE`` or\n",
      "     |      ``ANY_TYPE``.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#Argument.FIELDS.argument_kind\n",
      "     |\n",
      "     |  mode\n",
      "     |      Optional[str]: The input/output mode of the argument.\n",
      "     |\n",
      "     |  name\n",
      "     |      Optional[str]: Name of this argument.\n",
      "     |\n",
      "     |      Can be absent for function return argument.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class RoutineReference(builtins.object)\n",
      "     |  A pointer to a routine.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#routinereference\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Two RoutineReferences are equal if they point to the same routine.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      String representation of the reference.\n",
      "     |\n",
      "     |      This is a fully-qualified ID, including the project ID and dataset ID.\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this routine reference.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Routine reference represented as an API resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'RoutineReference' from builtins.type\n",
      "     |      Factory: construct a routine reference given its API representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]):\n",
      "     |              Routine reference representation returned from the API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.RoutineReference:\n",
      "     |              Routine reference parsed from ``resource``.\n",
      "     |\n",
      "     |  from_string(routine_id: str, default_project: Optional[str] = None) -> 'RoutineReference' from builtins.type\n",
      "     |      Factory: construct a routine reference from routine ID string.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          routine_id (str):\n",
      "     |              A routine ID in standard SQL format. If ``default_project``\n",
      "     |              is not specified, this must included a project ID, dataset\n",
      "     |              ID, and routine ID, each separated by ``.``.\n",
      "     |          default_project (Optional[str]):\n",
      "     |              The project ID to use when ``routine_id`` does not\n",
      "     |              include a project ID.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.routine.RoutineReference:\n",
      "     |              Routine reference parsed from ``routine_id``.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``routine_id`` is not a fully-qualified routine ID in\n",
      "     |              standard SQL format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      str: ID of dataset containing the routine.\n",
      "     |\n",
      "     |  path\n",
      "     |      str: URL path for the routine's APIs.\n",
      "     |\n",
      "     |  project\n",
      "     |      str: ID of the project containing the routine.\n",
      "     |\n",
      "     |  routine_id\n",
      "     |      str: The routine ID.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class RoutineType(builtins.object)\n",
      "     |  The fine-grained type of the routine.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/routines#routinetype\n",
      "     |\n",
      "     |  .. versionadded:: 2.22.0\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  PROCEDURE = 'PROCEDURE'\n",
      "     |\n",
      "     |  ROUTINE_TYPE_UNSPECIFIED = 'ROUTINE_TYPE_UNSPECIFIED'\n",
      "     |\n",
      "     |  SCALAR_FUNCTION = 'SCALAR_FUNCTION'\n",
      "     |\n",
      "     |  TABLE_VALUED_FUNCTION = 'TABLE_VALUED_FUNCTION'\n",
      "\n",
      "    class Row(builtins.object)\n",
      "     |  Row(values, field_to_index) -> None\n",
      "     |\n",
      "     |  A BigQuery row.\n",
      "     |\n",
      "     |  Values can be accessed by position (index), by key like a dict,\n",
      "     |  or as properties.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      values (Sequence[object]): The row values\n",
      "     |      field_to_index (Dict[str, int]):\n",
      "     |          A mapping from schema field names to indexes\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __getattr__(self, name)\n",
      "     |\n",
      "     |  __getitem__(self, key)\n",
      "     |\n",
      "     |  __init__(self, values, field_to_index) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __len__(self)\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  get(self, key: str, default: Any = None) -> Any\n",
      "     |      Return a value for key, with a default value if it does not exist.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          key (str): The key of the column to access\n",
      "     |          default (object):\n",
      "     |              The default value to use if the key does not exist. (Defaults\n",
      "     |              to :data:`None`.)\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          object:\n",
      "     |              The value associated with the provided key, or a default value.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |          When the key exists, the value associated with it is returned.\n",
      "     |\n",
      "     |          >>> Row(('a', 'b'), {'x': 0, 'y': 1}).get('x')\n",
      "     |          'a'\n",
      "     |\n",
      "     |          The default value is :data:`None` when the key does not exist.\n",
      "     |\n",
      "     |          >>> Row(('a', 'b'), {'x': 0, 'y': 1}).get('z')\n",
      "     |          None\n",
      "     |\n",
      "     |          The default value can be overridden with the ``default`` parameter.\n",
      "     |\n",
      "     |          >>> Row(('a', 'b'), {'x': 0, 'y': 1}).get('z', '')\n",
      "     |          ''\n",
      "     |\n",
      "     |          >>> Row(('a', 'b'), {'x': 0, 'y': 1}).get('z', default = '')\n",
      "     |          ''\n",
      "     |\n",
      "     |  items(self) -> Iterable[Tuple[str, Any]]\n",
      "     |      Return items as ``(key, value)`` pairs.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Iterable[Tuple[str, object]]:\n",
      "     |              The ``(key, value)`` pairs representing this row.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |\n",
      "     |          >>> list(Row(('a', 'b'), {'x': 0, 'y': 1}).items())\n",
      "     |          [('x', 'a'), ('y', 'b')]\n",
      "     |\n",
      "     |  keys(self) -> Iterable[str]\n",
      "     |      Return the keys for using a row as a dict.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Iterable[str]: The keys corresponding to the columns of a row\n",
      "     |\n",
      "     |      Examples:\n",
      "     |\n",
      "     |          >>> list(Row(('a', 'b'), {'x': 0, 'y': 1}).keys())\n",
      "     |          ['x', 'y']\n",
      "     |\n",
      "     |  values(self)\n",
      "     |      Return the values included in this row.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Sequence[object]: A sequence of length ``len(row)``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class ScalarQueryParameter(_AbstractQueryParameter)\n",
      "     |  ScalarQueryParameter(name: Optional[str], type_: Union[str, google.cloud.bigquery.query.ScalarQueryParameterType, NoneType], value: Union[str, int, float, decimal.Decimal, bool, datetime.datetime, datetime.date, NoneType])\n",
      "     |\n",
      "     |  Named / positional query parameters for scalar values.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      name:\n",
      "     |          Parameter name, used via ``@foo`` syntax.  If None, the\n",
      "     |          parameter can only be addressed via position (``?``).\n",
      "     |\n",
      "     |      type_:\n",
      "     |          Name of parameter type. See\n",
      "     |          :class:`google.cloud.bigquery.enums.SqlTypeNames` and\n",
      "     |          :class:`google.cloud.bigquery.query.SqlParameterScalarTypes` for\n",
      "     |          supported types.\n",
      "     |\n",
      "     |      value:\n",
      "     |          The scalar parameter value.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ScalarQueryParameter\n",
      "     |      _AbstractQueryParameter\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, name: Optional[str], type_: Union[str, google.cloud.bigquery.query.ScalarQueryParameterType, NoneType], value: Union[str, int, float, decimal.Decimal, bool, datetime.datetime, datetime.date, NoneType])\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct JSON API representation for the parameter.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'ScalarQueryParameter' from builtins.type\n",
      "     |      Factory: construct parameter from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ScalarQueryParameter: Instance\n",
      "     |\n",
      "     |  positional(type_: Union[str, google.cloud.bigquery.query.ScalarQueryParameterType], value: Union[str, int, float, decimal.Decimal, bool, datetime.datetime, datetime.date, NoneType]) -> 'ScalarQueryParameter' from builtins.type\n",
      "     |      Factory for positional paramater.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          type_:\n",
      "     |              Name of parameter type.  One of 'STRING', 'INT64',\n",
      "     |              'FLOAT64', 'NUMERIC', 'BIGNUMERIC', 'BOOL', 'TIMESTAMP', 'DATETIME', or\n",
      "     |              'DATE'.\n",
      "     |\n",
      "     |          value:\n",
      "     |              The scalar parameter value.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ScalarQueryParameter: Instance without name\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameter:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class ScalarQueryParameterType(_AbstractQueryParameterType)\n",
      "     |  ScalarQueryParameterType(type_, *, name=None, description=None)\n",
      "     |\n",
      "     |  Type representation for scalar query parameters.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      type_ (str):\n",
      "     |          One of 'STRING', 'INT64', 'FLOAT64', 'NUMERIC', 'BOOL', 'TIMESTAMP',\n",
      "     |          'DATETIME', or 'DATE'.\n",
      "     |      name (Optional[str]):\n",
      "     |          The name of the query parameter. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |      description (Optional[str]):\n",
      "     |          The query parameter description. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ScalarQueryParameterType\n",
      "     |      _AbstractQueryParameterType\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, type_, *, name=None, description=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Construct JSON API representation for the parameter type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  with_name(self, new_name: Optional[str])\n",
      "     |      Return a copy of the instance with ``name`` set to ``new_name``.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          name (Union[str, None]):\n",
      "     |              The new name of the query parameter type. If ``None``, the existing\n",
      "     |              name is cleared.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ScalarQueryParameterType:\n",
      "     |             A new instance with updated name.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource) from builtins.type\n",
      "     |      Factory: construct parameter type from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.ScalarQueryParameterType: Instance\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameterType:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SchemaField(builtins.object)\n",
      "     |  SchemaField(name: str, field_type: str, mode: str = 'NULLABLE', default_value_expression: Optional[str] = None, description: Union[str, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, fields: Iterable[ForwardRef('SchemaField')] = (), policy_tags: Union[ForwardRef('PolicyTagList'), NoneType, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, precision: Union[int, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, scale: Union[int, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, max_length: Union[int, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, range_element_type: Union[google.cloud.bigquery.schema.FieldElementType, str, NoneType] = None)\n",
      "     |\n",
      "     |  Describe a single field within a table schema.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      name: The name of the field.\n",
      "     |\n",
      "     |      field_type:\n",
      "     |          The type of the field. See\n",
      "     |          https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema.FIELDS.type\n",
      "     |\n",
      "     |      mode:\n",
      "     |          Defaults to ``'NULLABLE'``. The mode of the field. See\n",
      "     |          https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema.FIELDS.mode\n",
      "     |\n",
      "     |      description: Description for the field.\n",
      "     |\n",
      "     |      fields: Subfields (requires ``field_type`` of 'RECORD').\n",
      "     |\n",
      "     |      policy_tags: The policy tag list for the field.\n",
      "     |\n",
      "     |      precision:\n",
      "     |          Precison (number of digits) of fields with NUMERIC or BIGNUMERIC type.\n",
      "     |\n",
      "     |      scale:\n",
      "     |          Scale (digits after decimal) of fields with NUMERIC or BIGNUMERIC type.\n",
      "     |\n",
      "     |      max_length: Maximum length of fields with STRING or BYTES type.\n",
      "     |\n",
      "     |      default_value_expression: str, Optional\n",
      "     |          Used to specify the default value of a field using a SQL expression. It can only be set for\n",
      "     |          top level fields (columns).\n",
      "     |\n",
      "     |          You can use a struct or array expression to specify default value for the entire struct or\n",
      "     |          array. The valid SQL expressions are:\n",
      "     |\n",
      "     |          - Literals for all data types, including STRUCT and ARRAY.\n",
      "     |\n",
      "     |          - The following functions:\n",
      "     |\n",
      "     |              `CURRENT_TIMESTAMP`\n",
      "     |              `CURRENT_TIME`\n",
      "     |              `CURRENT_DATE`\n",
      "     |              `CURRENT_DATETIME`\n",
      "     |              `GENERATE_UUID`\n",
      "     |              `RAND`\n",
      "     |              `SESSION_USER`\n",
      "     |              `ST_GEOPOINT`\n",
      "     |\n",
      "     |          - Struct or array composed with the above allowed functions, for example:\n",
      "     |\n",
      "     |              \"[CURRENT_DATE(), DATE '2020-01-01'\"]\n",
      "     |\n",
      "     |      range_element_type: FieldElementType, str, Optional\n",
      "     |          The subtype of the RANGE, if the type of this field is RANGE. If\n",
      "     |          the type is RANGE, this field is required. Possible values for the\n",
      "     |          field element type of a RANGE include `DATE`, `DATETIME` and\n",
      "     |          `TIMESTAMP`.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self, name: str, field_type: str, mode: str = 'NULLABLE', default_value_expression: Optional[str] = None, description: Union[str, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, fields: Iterable[ForwardRef('SchemaField')] = (), policy_tags: Union[ForwardRef('PolicyTagList'), NoneType, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, precision: Union[int, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, scale: Union[int, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, max_length: Union[int, google.cloud.bigquery.schema._DefaultSentinel] = <_DefaultSentinel.DEFAULT_VALUE: <object object at 0x7202a04c6940>>, range_element_type: Union[google.cloud.bigquery.schema.FieldElementType, str, NoneType] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Return a dictionary representing this schema field.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: A dictionary representing the SchemaField in a serialized form.\n",
      "     |\n",
      "     |  to_standard_sql(self) -> google.cloud.bigquery.standard_sql.StandardSqlField\n",
      "     |      Return the field as the standard SQL field representation object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(api_repr: dict) -> 'SchemaField' from builtins.type\n",
      "     |      Return a ``SchemaField`` object deserialized from a dictionary.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          api_repr (Mapping[str, str]): The serialized representation\n",
      "     |              of the SchemaField, such as what is output by\n",
      "     |              :meth:`to_api_repr`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.schema.SchemaField: The ``SchemaField`` object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  default_value_expression\n",
      "     |      Optional[str] default value of a field, using an SQL expression\n",
      "     |\n",
      "     |  description\n",
      "     |      Optional[str]: description for the field.\n",
      "     |\n",
      "     |  field_type\n",
      "     |      str: The type of the field.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema.FIELDS.type\n",
      "     |\n",
      "     |  fields\n",
      "     |      Optional[tuple]: Subfields contained in this field.\n",
      "     |\n",
      "     |      Must be empty unset if ``field_type`` is not 'RECORD'.\n",
      "     |\n",
      "     |  is_nullable\n",
      "     |      bool: whether 'mode' is 'nullable'.\n",
      "     |\n",
      "     |  max_length\n",
      "     |      Optional[int]: Maximum length for the STRING or BYTES field.\n",
      "     |\n",
      "     |  mode\n",
      "     |      Optional[str]: The mode of the field.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema.FIELDS.mode\n",
      "     |\n",
      "     |  name\n",
      "     |      str: The name of the field.\n",
      "     |\n",
      "     |  policy_tags\n",
      "     |      Optional[google.cloud.bigquery.schema.PolicyTagList]: Policy tag list\n",
      "     |      definition for this field.\n",
      "     |\n",
      "     |  precision\n",
      "     |      Optional[int]: Precision (number of digits) for the NUMERIC field.\n",
      "     |\n",
      "     |  range_element_type\n",
      "     |      Optional[FieldElementType]: The subtype of the RANGE, if the\n",
      "     |      type of this field is RANGE.\n",
      "     |\n",
      "     |      Must be set when ``type`` is `\"RANGE\"`. Must be one of `\"DATE\"`,\n",
      "     |      `\"DATETIME\"` or `\"TIMESTAMP\"`.\n",
      "     |\n",
      "     |  scale\n",
      "     |      Optional[int]: Scale (digits after decimal) for the NUMERIC field.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SchemaUpdateOption(builtins.object)\n",
      "     |  Specifies an update to the destination table schema as a side effect of\n",
      "     |  a load job.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  ALLOW_FIELD_ADDITION = 'ALLOW_FIELD_ADDITION'\n",
      "     |\n",
      "     |  ALLOW_FIELD_RELAXATION = 'ALLOW_FIELD_RELAXATION'\n",
      "\n",
      "    class ScriptOptions(builtins.object)\n",
      "     |  ScriptOptions(statement_timeout_ms: Optional[int] = None, statement_byte_budget: Optional[int] = None, key_result_statement: Optional[google.cloud.bigquery.enums.KeyResultStatementKind] = None)\n",
      "     |\n",
      "     |  Options controlling the execution of scripts.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#ScriptOptions\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, statement_timeout_ms: Optional[int] = None, statement_byte_budget: Optional[int] = None, key_result_statement: Optional[google.cloud.bigquery.enums.KeyResultStatementKind] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> Dict[str, Any]\n",
      "     |      Construct the API resource representation.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, Any]) -> 'ScriptOptions' from builtins.type\n",
      "     |      Factory: construct instance from the JSON repr.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource(Dict[str: Any]):\n",
      "     |              ScriptOptions representation returned from API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.ScriptOptions:\n",
      "     |              ScriptOptions sample parsed from ``resource``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  key_result_statement\n",
      "     |      Determines which statement in the script represents the \"key result\".\n",
      "     |\n",
      "     |      This is used to populate the schema and query results of the script job.\n",
      "     |      Default is ``KeyResultStatementKind.LAST``.\n",
      "     |\n",
      "     |  statement_byte_budget\n",
      "     |      Limit on the number of bytes billed per statement.\n",
      "     |\n",
      "     |      Exceeding this budget results in an error.\n",
      "     |\n",
      "     |  statement_timeout_ms\n",
      "     |      Timeout period for each statement in a script.\n",
      "\n",
      "    class SessionInfo(builtins.object)\n",
      "     |  SessionInfo(resource)\n",
      "     |\n",
      "     |  [Preview] Information of the session if this job is part of one.\n",
      "     |\n",
      "     |  .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  Args:\n",
      "     |      resource (Map[str, Any]): JSON representation of object.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, resource)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  session_id\n",
      "     |      The ID of the session.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SnapshotDefinition(builtins.object)\n",
      "     |  SnapshotDefinition(resource: Dict[str, Any])\n",
      "     |\n",
      "     |  Information about base table and snapshot time of the snapshot.\n",
      "     |\n",
      "     |  See https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#snapshotdefinition\n",
      "     |\n",
      "     |  Args:\n",
      "     |      resource: Snapshot definition representation returned from the API.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, resource: Dict[str, Any])\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SourceFormat(builtins.object)\n",
      "     |  The format of the data files. The default value is :attr:`CSV`.\n",
      "     |\n",
      "     |  Note that the set of allowed values for loading data is different\n",
      "     |  than the set used for external data sources (see\n",
      "     |  :class:`~google.cloud.bigquery.external_config.ExternalSourceFormat`).\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  AVRO = 'AVRO'\n",
      "     |\n",
      "     |  CSV = 'CSV'\n",
      "     |\n",
      "     |  DATASTORE_BACKUP = 'DATASTORE_BACKUP'\n",
      "     |\n",
      "     |  NEWLINE_DELIMITED_JSON = 'NEWLINE_DELIMITED_JSON'\n",
      "     |\n",
      "     |  ORC = 'ORC'\n",
      "     |\n",
      "     |  PARQUET = 'PARQUET'\n",
      "\n",
      "    class SqlParameterScalarTypes(builtins.object)\n",
      "     |  Supported scalar SQL query parameter types as type objects.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  BIGDECIMAL = ScalarQueryParameterType('BIGNUMERIC')\n",
      "     |\n",
      "     |  BIGNUMERIC = ScalarQueryParameterType('BIGNUMERIC')\n",
      "     |\n",
      "     |  BOOL = ScalarQueryParameterType('BOOL')\n",
      "     |\n",
      "     |  BOOLEAN = ScalarQueryParameterType('BOOL')\n",
      "     |\n",
      "     |  BYTES = ScalarQueryParameterType('BYTES')\n",
      "     |\n",
      "     |  DATE = ScalarQueryParameterType('DATE')\n",
      "     |\n",
      "     |  DATETIME = ScalarQueryParameterType('DATETIME')\n",
      "     |\n",
      "     |  DECIMAL = ScalarQueryParameterType('NUMERIC')\n",
      "     |\n",
      "     |  FLOAT = ScalarQueryParameterType('FLOAT64')\n",
      "     |\n",
      "     |  FLOAT64 = ScalarQueryParameterType('FLOAT64')\n",
      "     |\n",
      "     |  GEOGRAPHY = ScalarQueryParameterType('GEOGRAPHY')\n",
      "     |\n",
      "     |  INT64 = ScalarQueryParameterType('INT64')\n",
      "     |\n",
      "     |  INTEGER = ScalarQueryParameterType('INT64')\n",
      "     |\n",
      "     |  NUMERIC = ScalarQueryParameterType('NUMERIC')\n",
      "     |\n",
      "     |  STRING = ScalarQueryParameterType('STRING')\n",
      "     |\n",
      "     |  TIME = ScalarQueryParameterType('TIME')\n",
      "     |\n",
      "     |  TIMESTAMP = ScalarQueryParameterType('TIMESTAMP')\n",
      "\n",
      "    class SqlTypeNames(builtins.str, enum.Enum)\n",
      "     |  SqlTypeNames(*values)\n",
      "     |\n",
      "     |  Enum of allowed SQL type names in schema.SchemaField.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SqlTypeNames\n",
      "     |      builtins.str\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |\n",
      "     |      Return str(self) if format_spec is empty. Raise TypeError otherwise.\n",
      "     |\n",
      "     |  __new__(cls, value)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  BIGDECIMAL = <SqlTypeNames.BIGDECIMAL: 'BIGNUMERIC'>\n",
      "     |\n",
      "     |  BOOLEAN = <SqlTypeNames.BOOLEAN: 'BOOLEAN'>\n",
      "     |\n",
      "     |  BYTES = <SqlTypeNames.BYTES: 'BYTES'>\n",
      "     |\n",
      "     |  DATE = <SqlTypeNames.DATE: 'DATE'>\n",
      "     |\n",
      "     |  DATETIME = <SqlTypeNames.DATETIME: 'DATETIME'>\n",
      "     |\n",
      "     |  DECIMAL = <SqlTypeNames.DECIMAL: 'NUMERIC'>\n",
      "     |\n",
      "     |  FLOAT = <SqlTypeNames.FLOAT: 'FLOAT'>\n",
      "     |\n",
      "     |  GEOGRAPHY = <SqlTypeNames.GEOGRAPHY: 'GEOGRAPHY'>\n",
      "     |\n",
      "     |  INTEGER = <SqlTypeNames.INTEGER: 'INTEGER'>\n",
      "     |\n",
      "     |  INTERVAL = <SqlTypeNames.INTERVAL: 'INTERVAL'>\n",
      "     |\n",
      "     |  RANGE = <SqlTypeNames.RANGE: 'RANGE'>\n",
      "     |\n",
      "     |  RECORD = <SqlTypeNames.RECORD: 'RECORD'>\n",
      "     |\n",
      "     |  STRING = <SqlTypeNames.STRING: 'STRING'>\n",
      "     |\n",
      "     |  TIME = <SqlTypeNames.TIME: 'TIME'>\n",
      "     |\n",
      "     |  TIMESTAMP = <SqlTypeNames.TIMESTAMP: 'TIMESTAMP'>\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.str:\n",
      "     |\n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return bool(key in self).\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __getnewargs__(...)\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |\n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |\n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |\n",
      "     |  __sizeof__(self, /)\n",
      "     |      Return the size of the string in memory, in bytes.\n",
      "     |\n",
      "     |  capitalize(self, /)\n",
      "     |      Return a capitalized version of the string.\n",
      "     |\n",
      "     |      More specifically, make the first character have upper case and the rest lower\n",
      "     |      case.\n",
      "     |\n",
      "     |  casefold(self, /)\n",
      "     |      Return a version of the string suitable for caseless comparisons.\n",
      "     |\n",
      "     |  center(self, width, fillchar=' ', /)\n",
      "     |      Return a centered string of length width.\n",
      "     |\n",
      "     |      Padding is done using the specified fill character (default is a space).\n",
      "     |\n",
      "     |  count(...)\n",
      "     |      S.count(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the number of non-overlapping occurrences of substring sub in\n",
      "     |      string S[start:end].  Optional arguments start and end are\n",
      "     |      interpreted as in slice notation.\n",
      "     |\n",
      "     |  encode(self, /, encoding='utf-8', errors='strict')\n",
      "     |      Encode the string using the codec registered for encoding.\n",
      "     |\n",
      "     |      encoding\n",
      "     |        The encoding in which to encode the string.\n",
      "     |      errors\n",
      "     |        The error handling scheme to use for encoding errors.\n",
      "     |        The default is 'strict' meaning that encoding errors raise a\n",
      "     |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      "     |        'xmlcharrefreplace' as well as any other name registered with\n",
      "     |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      "     |\n",
      "     |  endswith(...)\n",
      "     |      S.endswith(suffix[, start[, end]]) -> bool\n",
      "     |\n",
      "     |      Return True if S ends with the specified suffix, False otherwise.\n",
      "     |      With optional start, test S beginning at that position.\n",
      "     |      With optional end, stop comparing S at that position.\n",
      "     |      suffix can also be a tuple of strings to try.\n",
      "     |\n",
      "     |  expandtabs(self, /, tabsize=8)\n",
      "     |      Return a copy where all tab characters are expanded using spaces.\n",
      "     |\n",
      "     |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      "     |\n",
      "     |  find(...)\n",
      "     |      S.find(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the lowest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Return -1 on failure.\n",
      "     |\n",
      "     |  format(...)\n",
      "     |      S.format(*args, **kwargs) -> str\n",
      "     |\n",
      "     |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      "     |      The substitutions are identified by braces ('{' and '}').\n",
      "     |\n",
      "     |  format_map(...)\n",
      "     |      S.format_map(mapping) -> str\n",
      "     |\n",
      "     |      Return a formatted version of S, using substitutions from mapping.\n",
      "     |      The substitutions are identified by braces ('{' and '}').\n",
      "     |\n",
      "     |  index(...)\n",
      "     |      S.index(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the lowest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Raises ValueError when the substring is not found.\n",
      "     |\n",
      "     |  isalnum(self, /)\n",
      "     |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      "     |\n",
      "     |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      "     |      there is at least one character in the string.\n",
      "     |\n",
      "     |  isalpha(self, /)\n",
      "     |      Return True if the string is an alphabetic string, False otherwise.\n",
      "     |\n",
      "     |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      "     |      is at least one character in the string.\n",
      "     |\n",
      "     |  isascii(self, /)\n",
      "     |      Return True if all characters in the string are ASCII, False otherwise.\n",
      "     |\n",
      "     |      ASCII characters have code points in the range U+0000-U+007F.\n",
      "     |      Empty string is ASCII too.\n",
      "     |\n",
      "     |  isdecimal(self, /)\n",
      "     |      Return True if the string is a decimal string, False otherwise.\n",
      "     |\n",
      "     |      A string is a decimal string if all characters in the string are decimal and\n",
      "     |      there is at least one character in the string.\n",
      "     |\n",
      "     |  isdigit(self, /)\n",
      "     |      Return True if the string is a digit string, False otherwise.\n",
      "     |\n",
      "     |      A string is a digit string if all characters in the string are digits and there\n",
      "     |      is at least one character in the string.\n",
      "     |\n",
      "     |  isidentifier(self, /)\n",
      "     |      Return True if the string is a valid Python identifier, False otherwise.\n",
      "     |\n",
      "     |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,\n",
      "     |      such as \"def\" or \"class\".\n",
      "     |\n",
      "     |  islower(self, /)\n",
      "     |      Return True if the string is a lowercase string, False otherwise.\n",
      "     |\n",
      "     |      A string is lowercase if all cased characters in the string are lowercase and\n",
      "     |      there is at least one cased character in the string.\n",
      "     |\n",
      "     |  isnumeric(self, /)\n",
      "     |      Return True if the string is a numeric string, False otherwise.\n",
      "     |\n",
      "     |      A string is numeric if all characters in the string are numeric and there is at\n",
      "     |      least one character in the string.\n",
      "     |\n",
      "     |  isprintable(self, /)\n",
      "     |      Return True if the string is printable, False otherwise.\n",
      "     |\n",
      "     |      A string is printable if all of its characters are considered printable in\n",
      "     |      repr() or if it is empty.\n",
      "     |\n",
      "     |  isspace(self, /)\n",
      "     |      Return True if the string is a whitespace string, False otherwise.\n",
      "     |\n",
      "     |      A string is whitespace if all characters in the string are whitespace and there\n",
      "     |      is at least one character in the string.\n",
      "     |\n",
      "     |  istitle(self, /)\n",
      "     |      Return True if the string is a title-cased string, False otherwise.\n",
      "     |\n",
      "     |      In a title-cased string, upper- and title-case characters may only\n",
      "     |      follow uncased characters and lowercase characters only cased ones.\n",
      "     |\n",
      "     |  isupper(self, /)\n",
      "     |      Return True if the string is an uppercase string, False otherwise.\n",
      "     |\n",
      "     |      A string is uppercase if all cased characters in the string are uppercase and\n",
      "     |      there is at least one cased character in the string.\n",
      "     |\n",
      "     |  join(self, iterable, /)\n",
      "     |      Concatenate any number of strings.\n",
      "     |\n",
      "     |      The string whose method is called is inserted in between each given string.\n",
      "     |      The result is returned as a new string.\n",
      "     |\n",
      "     |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      "     |\n",
      "     |  ljust(self, width, fillchar=' ', /)\n",
      "     |      Return a left-justified string of length width.\n",
      "     |\n",
      "     |      Padding is done using the specified fill character (default is a space).\n",
      "     |\n",
      "     |  lower(self, /)\n",
      "     |      Return a copy of the string converted to lowercase.\n",
      "     |\n",
      "     |  lstrip(self, chars=None, /)\n",
      "     |      Return a copy of the string with leading whitespace removed.\n",
      "     |\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |\n",
      "     |  partition(self, sep, /)\n",
      "     |      Partition the string into three parts using the given separator.\n",
      "     |\n",
      "     |      This will search for the separator in the string.  If the separator is found,\n",
      "     |      returns a 3-tuple containing the part before the separator, the separator\n",
      "     |      itself, and the part after it.\n",
      "     |\n",
      "     |      If the separator is not found, returns a 3-tuple containing the original string\n",
      "     |      and two empty strings.\n",
      "     |\n",
      "     |  removeprefix(self, prefix, /)\n",
      "     |      Return a str with the given prefix string removed if present.\n",
      "     |\n",
      "     |      If the string starts with the prefix string, return string[len(prefix):].\n",
      "     |      Otherwise, return a copy of the original string.\n",
      "     |\n",
      "     |  removesuffix(self, suffix, /)\n",
      "     |      Return a str with the given suffix string removed if present.\n",
      "     |\n",
      "     |      If the string ends with the suffix string and that suffix is not empty,\n",
      "     |      return string[:-len(suffix)]. Otherwise, return a copy of the original\n",
      "     |      string.\n",
      "     |\n",
      "     |  replace(self, old, new, count=-1, /)\n",
      "     |      Return a copy with all occurrences of substring old replaced by new.\n",
      "     |\n",
      "     |        count\n",
      "     |          Maximum number of occurrences to replace.\n",
      "     |          -1 (the default value) means replace all occurrences.\n",
      "     |\n",
      "     |      If the optional argument count is given, only the first count occurrences are\n",
      "     |      replaced.\n",
      "     |\n",
      "     |  rfind(...)\n",
      "     |      S.rfind(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the highest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Return -1 on failure.\n",
      "     |\n",
      "     |  rindex(...)\n",
      "     |      S.rindex(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the highest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Raises ValueError when the substring is not found.\n",
      "     |\n",
      "     |  rjust(self, width, fillchar=' ', /)\n",
      "     |      Return a right-justified string of length width.\n",
      "     |\n",
      "     |      Padding is done using the specified fill character (default is a space).\n",
      "     |\n",
      "     |  rpartition(self, sep, /)\n",
      "     |      Partition the string into three parts using the given separator.\n",
      "     |\n",
      "     |      This will search for the separator in the string, starting at the end. If\n",
      "     |      the separator is found, returns a 3-tuple containing the part before the\n",
      "     |      separator, the separator itself, and the part after it.\n",
      "     |\n",
      "     |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      "     |      and the original string.\n",
      "     |\n",
      "     |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      "     |      Return a list of the substrings in the string, using sep as the separator string.\n",
      "     |\n",
      "     |        sep\n",
      "     |          The separator used to split the string.\n",
      "     |\n",
      "     |          When set to None (the default value), will split on any whitespace\n",
      "     |          character (including \\n \\r \\t \\f and spaces) and will discard\n",
      "     |          empty strings from the result.\n",
      "     |        maxsplit\n",
      "     |          Maximum number of splits.\n",
      "     |          -1 (the default value) means no limit.\n",
      "     |\n",
      "     |      Splitting starts at the end of the string and works to the front.\n",
      "     |\n",
      "     |  rstrip(self, chars=None, /)\n",
      "     |      Return a copy of the string with trailing whitespace removed.\n",
      "     |\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |\n",
      "     |  split(self, /, sep=None, maxsplit=-1)\n",
      "     |      Return a list of the substrings in the string, using sep as the separator string.\n",
      "     |\n",
      "     |        sep\n",
      "     |          The separator used to split the string.\n",
      "     |\n",
      "     |          When set to None (the default value), will split on any whitespace\n",
      "     |          character (including \\n \\r \\t \\f and spaces) and will discard\n",
      "     |          empty strings from the result.\n",
      "     |        maxsplit\n",
      "     |          Maximum number of splits.\n",
      "     |          -1 (the default value) means no limit.\n",
      "     |\n",
      "     |      Splitting starts at the front of the string and works to the end.\n",
      "     |\n",
      "     |      Note, str.split() is mainly useful for data that has been intentionally\n",
      "     |      delimited.  With natural text that includes punctuation, consider using\n",
      "     |      the regular expression module.\n",
      "     |\n",
      "     |  splitlines(self, /, keepends=False)\n",
      "     |      Return a list of the lines in the string, breaking at line boundaries.\n",
      "     |\n",
      "     |      Line breaks are not included in the resulting list unless keepends is given and\n",
      "     |      true.\n",
      "     |\n",
      "     |  startswith(...)\n",
      "     |      S.startswith(prefix[, start[, end]]) -> bool\n",
      "     |\n",
      "     |      Return True if S starts with the specified prefix, False otherwise.\n",
      "     |      With optional start, test S beginning at that position.\n",
      "     |      With optional end, stop comparing S at that position.\n",
      "     |      prefix can also be a tuple of strings to try.\n",
      "     |\n",
      "     |  strip(self, chars=None, /)\n",
      "     |      Return a copy of the string with leading and trailing whitespace removed.\n",
      "     |\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |\n",
      "     |  swapcase(self, /)\n",
      "     |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      "     |\n",
      "     |  title(self, /)\n",
      "     |      Return a version of the string where each word is titlecased.\n",
      "     |\n",
      "     |      More specifically, words start with uppercased characters and all remaining\n",
      "     |      cased characters have lower case.\n",
      "     |\n",
      "     |  translate(self, table, /)\n",
      "     |      Replace each character in the string using the given translation table.\n",
      "     |\n",
      "     |        table\n",
      "     |          Translation table, which must be a mapping of Unicode ordinals to\n",
      "     |          Unicode ordinals, strings, or None.\n",
      "     |\n",
      "     |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      "     |      dictionary or list.  If this operation raises LookupError, the character is\n",
      "     |      left untouched.  Characters mapped to None are deleted.\n",
      "     |\n",
      "     |  upper(self, /)\n",
      "     |      Return a copy of the string converted to uppercase.\n",
      "     |\n",
      "     |  zfill(self, width, /)\n",
      "     |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      "     |\n",
      "     |      The string is never truncated.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.str:\n",
      "     |\n",
      "     |  maketrans(...)\n",
      "     |      Return a translation table usable for str.translate().\n",
      "     |\n",
      "     |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      "     |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      "     |      Character keys will be then converted to ordinals.\n",
      "     |      If there are two arguments, they must be strings of equal length, and\n",
      "     |      in the resulting dictionary, each character in x will be mapped to the\n",
      "     |      character at the same position in y. If there is a third argument, it\n",
      "     |      must be a string, whose characters will be mapped to None in the result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.Enum:\n",
      "     |\n",
      "     |  __dir__(self)\n",
      "     |      Returns public methods and other interesting attributes.\n",
      "     |\n",
      "     |  __init__(self, *args, **kwds)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |\n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |\n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |\n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |\n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "\n",
      "    class StandardSqlDataType(builtins.object)\n",
      "     |  StandardSqlDataType(type_kind: Optional[google.cloud.bigquery.enums.StandardSqlTypeNames] = <StandardSqlTypeNames.TYPE_KIND_UNSPECIFIED: 'TYPE_KIND_UNSPECIFIED'>, array_element_type: Optional[ForwardRef('StandardSqlDataType')] = None, struct_type: Optional[ForwardRef('StandardSqlStructType')] = None, range_element_type: Optional[ForwardRef('StandardSqlDataType')] = None)\n",
      "     |\n",
      "     |  The type of a variable, e.g., a function argument.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/StandardSqlDataType\n",
      "     |\n",
      "     |  Examples:\n",
      "     |\n",
      "     |  .. code-block:: text\n",
      "     |\n",
      "     |      INT64: {type_kind=\"INT64\"}\n",
      "     |      ARRAY: {type_kind=\"ARRAY\", array_element_type=\"STRING\"}\n",
      "     |      STRUCT<x STRING, y ARRAY>: {\n",
      "     |          type_kind=\"STRUCT\",\n",
      "     |          struct_type={\n",
      "     |              fields=[\n",
      "     |                  {name=\"x\", type={type_kind=\"STRING\"}},\n",
      "     |                  {\n",
      "     |                      name=\"y\",\n",
      "     |                      type={type_kind=\"ARRAY\", array_element_type=\"DATE\"}\n",
      "     |                  }\n",
      "     |              ]\n",
      "     |          }\n",
      "     |      }\n",
      "     |      RANGE: {type_kind=\"RANGE\", range_element_type=\"DATETIME\"}\n",
      "     |\n",
      "     |  Args:\n",
      "     |      type_kind:\n",
      "     |          The top level type of this field. Can be any standard SQL data type,\n",
      "     |          e.g. INT64, DATE, ARRAY.\n",
      "     |      array_element_type:\n",
      "     |          The type of the array's elements, if type_kind is ARRAY.\n",
      "     |      struct_type:\n",
      "     |          The fields of this struct, in order, if type_kind is STRUCT.\n",
      "     |      range_element_type:\n",
      "     |          The type of the range's elements, if type_kind is RANGE.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, type_kind: Optional[google.cloud.bigquery.enums.StandardSqlTypeNames] = <StandardSqlTypeNames.TYPE_KIND_UNSPECIFIED: 'TYPE_KIND_UNSPECIFIED'>, array_element_type: Optional[ForwardRef('StandardSqlDataType')] = None, struct_type: Optional[ForwardRef('StandardSqlStructType')] = None, range_element_type: Optional[ForwardRef('StandardSqlDataType')] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> Dict[str, Any]\n",
      "     |      Construct the API resource representation of this SQL data type.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, Any]) from builtins.type\n",
      "     |      Construct an SQL data type instance given its API representation.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  array_element_type\n",
      "     |      The type of the array's elements, if type_kind is ARRAY.\n",
      "     |\n",
      "     |  range_element_type\n",
      "     |      The type of the range's elements, if type_kind = \"RANGE\". Must be\n",
      "     |      one of DATETIME, DATE, or TIMESTAMP.\n",
      "     |\n",
      "     |  struct_type\n",
      "     |      The fields of this struct, in order, if type_kind is STRUCT.\n",
      "     |\n",
      "     |  type_kind\n",
      "     |      The top level type of this field.\n",
      "     |\n",
      "     |      Can be any standard SQL data type, e.g. INT64, DATE, ARRAY.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class StandardSqlField(builtins.object)\n",
      "     |  StandardSqlField(name: Optional[str] = None, type: Optional[google.cloud.bigquery.standard_sql.StandardSqlDataType] = None)\n",
      "     |\n",
      "     |  A field or a column.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/StandardSqlField\n",
      "     |\n",
      "     |  Args:\n",
      "     |      name:\n",
      "     |          The name of this field. Can be absent for struct fields.\n",
      "     |      type:\n",
      "     |          The type of this parameter. Absent if not explicitly specified.\n",
      "     |\n",
      "     |          For example, CREATE FUNCTION statement can omit the return type; in this\n",
      "     |          case the output parameter does not have this \"type\" field).\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, name: Optional[str] = None, type: Optional[google.cloud.bigquery.standard_sql.StandardSqlDataType] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> Dict[str, Any]\n",
      "     |      Construct the API resource representation of this SQL field.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, Any]) from builtins.type\n",
      "     |      Construct an SQL field instance given its API representation.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  name\n",
      "     |      The name of this field. Can be absent for struct fields.\n",
      "     |\n",
      "     |  type\n",
      "     |      The type of this parameter. Absent if not explicitly specified.\n",
      "     |\n",
      "     |      For example, CREATE FUNCTION statement can omit the return type; in this\n",
      "     |      case the output parameter does not have this \"type\" field).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class StandardSqlStructType(builtins.object)\n",
      "     |  StandardSqlStructType(fields: Optional[Iterable[google.cloud.bigquery.standard_sql.StandardSqlField]] = None)\n",
      "     |\n",
      "     |  Type of a struct field.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/StandardSqlDataType#StandardSqlStructType\n",
      "     |\n",
      "     |  Args:\n",
      "     |      fields: The fields in this struct.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, fields: Optional[Iterable[google.cloud.bigquery.standard_sql.StandardSqlField]] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> Dict[str, Any]\n",
      "     |      Construct the API resource representation of this SQL struct type.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, Any]) -> 'StandardSqlStructType' from builtins.type\n",
      "     |      Construct an SQL struct type instance given its API representation.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  fields\n",
      "     |      The fields in this struct.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class StandardSqlTableType(builtins.object)\n",
      "     |  StandardSqlTableType(columns: Iterable[google.cloud.bigquery.standard_sql.StandardSqlField])\n",
      "     |\n",
      "     |  A table type.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/workflows/docs/reference/googleapis/bigquery/v2/Overview#StandardSqlTableType\n",
      "     |\n",
      "     |  Args:\n",
      "     |      columns: The columns in this table type.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, columns: Iterable[google.cloud.bigquery.standard_sql.StandardSqlField])\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  to_api_repr(self) -> Dict[str, Any]\n",
      "     |      Construct the API resource representation of this SQL table type.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: Dict[str, Any]) -> 'StandardSqlTableType' from builtins.type\n",
      "     |      Construct an SQL table type instance given its API representation.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  columns\n",
      "     |      The columns in this table type.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class StandardSqlTypeNames(builtins.str, enum.Enum)\n",
      "     |  StandardSqlTypeNames(*values)\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      StandardSqlTypeNames\n",
      "     |      builtins.str\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __format__(self, format_spec)\n",
      "     |      Default object formatter.\n",
      "     |\n",
      "     |      Return str(self) if format_spec is empty. Raise TypeError otherwise.\n",
      "     |\n",
      "     |  __new__(cls, value)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  ARRAY = <StandardSqlTypeNames.ARRAY: 'ARRAY'>\n",
      "     |\n",
      "     |  BIGNUMERIC = <StandardSqlTypeNames.BIGNUMERIC: 'BIGNUMERIC'>\n",
      "     |\n",
      "     |  BOOL = <StandardSqlTypeNames.BOOL: 'BOOL'>\n",
      "     |\n",
      "     |  BYTES = <StandardSqlTypeNames.BYTES: 'BYTES'>\n",
      "     |\n",
      "     |  DATE = <StandardSqlTypeNames.DATE: 'DATE'>\n",
      "     |\n",
      "     |  DATETIME = <StandardSqlTypeNames.DATETIME: 'DATETIME'>\n",
      "     |\n",
      "     |  FLOAT64 = <StandardSqlTypeNames.FLOAT64: 'FLOAT64'>\n",
      "     |\n",
      "     |  GEOGRAPHY = <StandardSqlTypeNames.GEOGRAPHY: 'GEOGRAPHY'>\n",
      "     |\n",
      "     |  INT64 = <StandardSqlTypeNames.INT64: 'INT64'>\n",
      "     |\n",
      "     |  INTERVAL = <StandardSqlTypeNames.INTERVAL: 'INTERVAL'>\n",
      "     |\n",
      "     |  JSON = <StandardSqlTypeNames.JSON: 'JSON'>\n",
      "     |\n",
      "     |  NUMERIC = <StandardSqlTypeNames.NUMERIC: 'NUMERIC'>\n",
      "     |\n",
      "     |  RANGE = <StandardSqlTypeNames.RANGE: 'RANGE'>\n",
      "     |\n",
      "     |  STRING = <StandardSqlTypeNames.STRING: 'STRING'>\n",
      "     |\n",
      "     |  STRUCT = <StandardSqlTypeNames.STRUCT: 'STRUCT'>\n",
      "     |\n",
      "     |  TIME = <StandardSqlTypeNames.TIME: 'TIME'>\n",
      "     |\n",
      "     |  TIMESTAMP = <StandardSqlTypeNames.TIMESTAMP: 'TIMESTAMP'>\n",
      "     |\n",
      "     |  TYPE_KIND_UNSPECIFIED = <StandardSqlTypeNames.TYPE_KIND_UNSPECIFIED: '...\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.str:\n",
      "     |\n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return bool(key in self).\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __getnewargs__(...)\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |\n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |\n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |\n",
      "     |  __sizeof__(self, /)\n",
      "     |      Return the size of the string in memory, in bytes.\n",
      "     |\n",
      "     |  capitalize(self, /)\n",
      "     |      Return a capitalized version of the string.\n",
      "     |\n",
      "     |      More specifically, make the first character have upper case and the rest lower\n",
      "     |      case.\n",
      "     |\n",
      "     |  casefold(self, /)\n",
      "     |      Return a version of the string suitable for caseless comparisons.\n",
      "     |\n",
      "     |  center(self, width, fillchar=' ', /)\n",
      "     |      Return a centered string of length width.\n",
      "     |\n",
      "     |      Padding is done using the specified fill character (default is a space).\n",
      "     |\n",
      "     |  count(...)\n",
      "     |      S.count(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the number of non-overlapping occurrences of substring sub in\n",
      "     |      string S[start:end].  Optional arguments start and end are\n",
      "     |      interpreted as in slice notation.\n",
      "     |\n",
      "     |  encode(self, /, encoding='utf-8', errors='strict')\n",
      "     |      Encode the string using the codec registered for encoding.\n",
      "     |\n",
      "     |      encoding\n",
      "     |        The encoding in which to encode the string.\n",
      "     |      errors\n",
      "     |        The error handling scheme to use for encoding errors.\n",
      "     |        The default is 'strict' meaning that encoding errors raise a\n",
      "     |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
      "     |        'xmlcharrefreplace' as well as any other name registered with\n",
      "     |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
      "     |\n",
      "     |  endswith(...)\n",
      "     |      S.endswith(suffix[, start[, end]]) -> bool\n",
      "     |\n",
      "     |      Return True if S ends with the specified suffix, False otherwise.\n",
      "     |      With optional start, test S beginning at that position.\n",
      "     |      With optional end, stop comparing S at that position.\n",
      "     |      suffix can also be a tuple of strings to try.\n",
      "     |\n",
      "     |  expandtabs(self, /, tabsize=8)\n",
      "     |      Return a copy where all tab characters are expanded using spaces.\n",
      "     |\n",
      "     |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      "     |\n",
      "     |  find(...)\n",
      "     |      S.find(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the lowest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Return -1 on failure.\n",
      "     |\n",
      "     |  format(...)\n",
      "     |      S.format(*args, **kwargs) -> str\n",
      "     |\n",
      "     |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      "     |      The substitutions are identified by braces ('{' and '}').\n",
      "     |\n",
      "     |  format_map(...)\n",
      "     |      S.format_map(mapping) -> str\n",
      "     |\n",
      "     |      Return a formatted version of S, using substitutions from mapping.\n",
      "     |      The substitutions are identified by braces ('{' and '}').\n",
      "     |\n",
      "     |  index(...)\n",
      "     |      S.index(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the lowest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Raises ValueError when the substring is not found.\n",
      "     |\n",
      "     |  isalnum(self, /)\n",
      "     |      Return True if the string is an alpha-numeric string, False otherwise.\n",
      "     |\n",
      "     |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
      "     |      there is at least one character in the string.\n",
      "     |\n",
      "     |  isalpha(self, /)\n",
      "     |      Return True if the string is an alphabetic string, False otherwise.\n",
      "     |\n",
      "     |      A string is alphabetic if all characters in the string are alphabetic and there\n",
      "     |      is at least one character in the string.\n",
      "     |\n",
      "     |  isascii(self, /)\n",
      "     |      Return True if all characters in the string are ASCII, False otherwise.\n",
      "     |\n",
      "     |      ASCII characters have code points in the range U+0000-U+007F.\n",
      "     |      Empty string is ASCII too.\n",
      "     |\n",
      "     |  isdecimal(self, /)\n",
      "     |      Return True if the string is a decimal string, False otherwise.\n",
      "     |\n",
      "     |      A string is a decimal string if all characters in the string are decimal and\n",
      "     |      there is at least one character in the string.\n",
      "     |\n",
      "     |  isdigit(self, /)\n",
      "     |      Return True if the string is a digit string, False otherwise.\n",
      "     |\n",
      "     |      A string is a digit string if all characters in the string are digits and there\n",
      "     |      is at least one character in the string.\n",
      "     |\n",
      "     |  isidentifier(self, /)\n",
      "     |      Return True if the string is a valid Python identifier, False otherwise.\n",
      "     |\n",
      "     |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,\n",
      "     |      such as \"def\" or \"class\".\n",
      "     |\n",
      "     |  islower(self, /)\n",
      "     |      Return True if the string is a lowercase string, False otherwise.\n",
      "     |\n",
      "     |      A string is lowercase if all cased characters in the string are lowercase and\n",
      "     |      there is at least one cased character in the string.\n",
      "     |\n",
      "     |  isnumeric(self, /)\n",
      "     |      Return True if the string is a numeric string, False otherwise.\n",
      "     |\n",
      "     |      A string is numeric if all characters in the string are numeric and there is at\n",
      "     |      least one character in the string.\n",
      "     |\n",
      "     |  isprintable(self, /)\n",
      "     |      Return True if the string is printable, False otherwise.\n",
      "     |\n",
      "     |      A string is printable if all of its characters are considered printable in\n",
      "     |      repr() or if it is empty.\n",
      "     |\n",
      "     |  isspace(self, /)\n",
      "     |      Return True if the string is a whitespace string, False otherwise.\n",
      "     |\n",
      "     |      A string is whitespace if all characters in the string are whitespace and there\n",
      "     |      is at least one character in the string.\n",
      "     |\n",
      "     |  istitle(self, /)\n",
      "     |      Return True if the string is a title-cased string, False otherwise.\n",
      "     |\n",
      "     |      In a title-cased string, upper- and title-case characters may only\n",
      "     |      follow uncased characters and lowercase characters only cased ones.\n",
      "     |\n",
      "     |  isupper(self, /)\n",
      "     |      Return True if the string is an uppercase string, False otherwise.\n",
      "     |\n",
      "     |      A string is uppercase if all cased characters in the string are uppercase and\n",
      "     |      there is at least one cased character in the string.\n",
      "     |\n",
      "     |  join(self, iterable, /)\n",
      "     |      Concatenate any number of strings.\n",
      "     |\n",
      "     |      The string whose method is called is inserted in between each given string.\n",
      "     |      The result is returned as a new string.\n",
      "     |\n",
      "     |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
      "     |\n",
      "     |  ljust(self, width, fillchar=' ', /)\n",
      "     |      Return a left-justified string of length width.\n",
      "     |\n",
      "     |      Padding is done using the specified fill character (default is a space).\n",
      "     |\n",
      "     |  lower(self, /)\n",
      "     |      Return a copy of the string converted to lowercase.\n",
      "     |\n",
      "     |  lstrip(self, chars=None, /)\n",
      "     |      Return a copy of the string with leading whitespace removed.\n",
      "     |\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |\n",
      "     |  partition(self, sep, /)\n",
      "     |      Partition the string into three parts using the given separator.\n",
      "     |\n",
      "     |      This will search for the separator in the string.  If the separator is found,\n",
      "     |      returns a 3-tuple containing the part before the separator, the separator\n",
      "     |      itself, and the part after it.\n",
      "     |\n",
      "     |      If the separator is not found, returns a 3-tuple containing the original string\n",
      "     |      and two empty strings.\n",
      "     |\n",
      "     |  removeprefix(self, prefix, /)\n",
      "     |      Return a str with the given prefix string removed if present.\n",
      "     |\n",
      "     |      If the string starts with the prefix string, return string[len(prefix):].\n",
      "     |      Otherwise, return a copy of the original string.\n",
      "     |\n",
      "     |  removesuffix(self, suffix, /)\n",
      "     |      Return a str with the given suffix string removed if present.\n",
      "     |\n",
      "     |      If the string ends with the suffix string and that suffix is not empty,\n",
      "     |      return string[:-len(suffix)]. Otherwise, return a copy of the original\n",
      "     |      string.\n",
      "     |\n",
      "     |  replace(self, old, new, count=-1, /)\n",
      "     |      Return a copy with all occurrences of substring old replaced by new.\n",
      "     |\n",
      "     |        count\n",
      "     |          Maximum number of occurrences to replace.\n",
      "     |          -1 (the default value) means replace all occurrences.\n",
      "     |\n",
      "     |      If the optional argument count is given, only the first count occurrences are\n",
      "     |      replaced.\n",
      "     |\n",
      "     |  rfind(...)\n",
      "     |      S.rfind(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the highest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Return -1 on failure.\n",
      "     |\n",
      "     |  rindex(...)\n",
      "     |      S.rindex(sub[, start[, end]]) -> int\n",
      "     |\n",
      "     |      Return the highest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |\n",
      "     |      Raises ValueError when the substring is not found.\n",
      "     |\n",
      "     |  rjust(self, width, fillchar=' ', /)\n",
      "     |      Return a right-justified string of length width.\n",
      "     |\n",
      "     |      Padding is done using the specified fill character (default is a space).\n",
      "     |\n",
      "     |  rpartition(self, sep, /)\n",
      "     |      Partition the string into three parts using the given separator.\n",
      "     |\n",
      "     |      This will search for the separator in the string, starting at the end. If\n",
      "     |      the separator is found, returns a 3-tuple containing the part before the\n",
      "     |      separator, the separator itself, and the part after it.\n",
      "     |\n",
      "     |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
      "     |      and the original string.\n",
      "     |\n",
      "     |  rsplit(self, /, sep=None, maxsplit=-1)\n",
      "     |      Return a list of the substrings in the string, using sep as the separator string.\n",
      "     |\n",
      "     |        sep\n",
      "     |          The separator used to split the string.\n",
      "     |\n",
      "     |          When set to None (the default value), will split on any whitespace\n",
      "     |          character (including \\n \\r \\t \\f and spaces) and will discard\n",
      "     |          empty strings from the result.\n",
      "     |        maxsplit\n",
      "     |          Maximum number of splits.\n",
      "     |          -1 (the default value) means no limit.\n",
      "     |\n",
      "     |      Splitting starts at the end of the string and works to the front.\n",
      "     |\n",
      "     |  rstrip(self, chars=None, /)\n",
      "     |      Return a copy of the string with trailing whitespace removed.\n",
      "     |\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |\n",
      "     |  split(self, /, sep=None, maxsplit=-1)\n",
      "     |      Return a list of the substrings in the string, using sep as the separator string.\n",
      "     |\n",
      "     |        sep\n",
      "     |          The separator used to split the string.\n",
      "     |\n",
      "     |          When set to None (the default value), will split on any whitespace\n",
      "     |          character (including \\n \\r \\t \\f and spaces) and will discard\n",
      "     |          empty strings from the result.\n",
      "     |        maxsplit\n",
      "     |          Maximum number of splits.\n",
      "     |          -1 (the default value) means no limit.\n",
      "     |\n",
      "     |      Splitting starts at the front of the string and works to the end.\n",
      "     |\n",
      "     |      Note, str.split() is mainly useful for data that has been intentionally\n",
      "     |      delimited.  With natural text that includes punctuation, consider using\n",
      "     |      the regular expression module.\n",
      "     |\n",
      "     |  splitlines(self, /, keepends=False)\n",
      "     |      Return a list of the lines in the string, breaking at line boundaries.\n",
      "     |\n",
      "     |      Line breaks are not included in the resulting list unless keepends is given and\n",
      "     |      true.\n",
      "     |\n",
      "     |  startswith(...)\n",
      "     |      S.startswith(prefix[, start[, end]]) -> bool\n",
      "     |\n",
      "     |      Return True if S starts with the specified prefix, False otherwise.\n",
      "     |      With optional start, test S beginning at that position.\n",
      "     |      With optional end, stop comparing S at that position.\n",
      "     |      prefix can also be a tuple of strings to try.\n",
      "     |\n",
      "     |  strip(self, chars=None, /)\n",
      "     |      Return a copy of the string with leading and trailing whitespace removed.\n",
      "     |\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |\n",
      "     |  swapcase(self, /)\n",
      "     |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
      "     |\n",
      "     |  title(self, /)\n",
      "     |      Return a version of the string where each word is titlecased.\n",
      "     |\n",
      "     |      More specifically, words start with uppercased characters and all remaining\n",
      "     |      cased characters have lower case.\n",
      "     |\n",
      "     |  translate(self, table, /)\n",
      "     |      Replace each character in the string using the given translation table.\n",
      "     |\n",
      "     |        table\n",
      "     |          Translation table, which must be a mapping of Unicode ordinals to\n",
      "     |          Unicode ordinals, strings, or None.\n",
      "     |\n",
      "     |      The table must implement lookup/indexing via __getitem__, for instance a\n",
      "     |      dictionary or list.  If this operation raises LookupError, the character is\n",
      "     |      left untouched.  Characters mapped to None are deleted.\n",
      "     |\n",
      "     |  upper(self, /)\n",
      "     |      Return a copy of the string converted to uppercase.\n",
      "     |\n",
      "     |  zfill(self, width, /)\n",
      "     |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
      "     |\n",
      "     |      The string is never truncated.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.str:\n",
      "     |\n",
      "     |  maketrans(...)\n",
      "     |      Return a translation table usable for str.translate().\n",
      "     |\n",
      "     |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      "     |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      "     |      Character keys will be then converted to ordinals.\n",
      "     |      If there are two arguments, they must be strings of equal length, and\n",
      "     |      in the resulting dictionary, each character in x will be mapped to the\n",
      "     |      character at the same position in y. If there is a third argument, it\n",
      "     |      must be a string, whose characters will be mapped to None in the result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from enum.Enum:\n",
      "     |\n",
      "     |  __dir__(self)\n",
      "     |      Returns public methods and other interesting attributes.\n",
      "     |\n",
      "     |  __init__(self, *args, **kwds)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |\n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |\n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumType:\n",
      "     |\n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |\n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "\n",
      "    class StructQueryParameter(_AbstractQueryParameter)\n",
      "     |  StructQueryParameter(name, *sub_params) -> None\n",
      "     |\n",
      "     |  Named / positional query parameters for struct values.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      name (Optional[str]):\n",
      "     |          Parameter name, used via ``@foo`` syntax.  If None, the\n",
      "     |          parameter can only be addressed via position (``?``).\n",
      "     |\n",
      "     |      sub_params (Union[Tuple[\n",
      "     |          google.cloud.bigquery.query.ScalarQueryParameter,\n",
      "     |          google.cloud.bigquery.query.ArrayQueryParameter,\n",
      "     |          google.cloud.bigquery.query.StructQueryParameter\n",
      "     |      ]]): The sub-parameters for the struct\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      StructQueryParameter\n",
      "     |      _AbstractQueryParameter\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, name, *sub_params) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct JSON API representation for the parameter.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'StructQueryParameter' from builtins.type\n",
      "     |      Factory: construct parameter from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.StructQueryParameter: Instance\n",
      "     |\n",
      "     |  positional(*sub_params) from builtins.type\n",
      "     |      Factory for positional parameters.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          sub_params (Union[Tuple[\n",
      "     |              google.cloud.bigquery.query.ScalarQueryParameter,\n",
      "     |              google.cloud.bigquery.query.ArrayQueryParameter,\n",
      "     |              google.cloud.bigquery.query.StructQueryParameter\n",
      "     |          ]]): The sub-parameters for the struct\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.StructQueryParameter: Instance without name\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameter:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class StructQueryParameterType(_AbstractQueryParameterType)\n",
      "     |  StructQueryParameterType(*fields, name=None, description=None)\n",
      "     |\n",
      "     |  Type representation for struct query parameters.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      fields (Iterable[Union[             ArrayQueryParameterType, ScalarQueryParameterType, StructQueryParameterType         ]]):\n",
      "     |          An non-empty iterable describing the struct's field types.\n",
      "     |      name (Optional[str]):\n",
      "     |          The name of the query parameter. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |      description (Optional[str]):\n",
      "     |          The query parameter description. Primarily used if the type is\n",
      "     |          one of the subfields in ``StructQueryParameterType`` instance.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      StructQueryParameterType\n",
      "     |      _AbstractQueryParameterType\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *fields, name=None, description=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Construct JSON API representation for the parameter type.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict: JSON mapping\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource) from builtins.type\n",
      "     |      Factory: construct parameter type from JSON resource.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON mapping of parameter\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.query.StructQueryParameterType: Instance\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  fields\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _AbstractQueryParameterType:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class Table(_TableBase)\n",
      "     |  Table(table_ref, schema=None) -> None\n",
      "     |\n",
      "     |  Tables represent a set of rows whose values correspond to a schema.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#resource-table\n",
      "     |\n",
      "     |  Args:\n",
      "     |      table_ref (Union[google.cloud.bigquery.table.TableReference, str]):\n",
      "     |          A pointer to a table. If ``table_ref`` is a string, it must\n",
      "     |          included a project ID, dataset ID, and table ID, each separated\n",
      "     |          by ``.``.\n",
      "     |      schema (Optional[Sequence[Union[                 :class:`~google.cloud.bigquery.schema.SchemaField`,                 Mapping[str, Any]         ]]]):\n",
      "     |          The table's schema. If any item is a mapping, its content must be\n",
      "     |          compatible with\n",
      "     |          :meth:`~google.cloud.bigquery.schema.SchemaField.from_api_repr`.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Table\n",
      "     |      _TableBase\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, table_ref, schema=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Constructs the API resource of this table\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Table represented as an API resource\n",
      "     |\n",
      "     |  to_bqstorage(self) -> str\n",
      "     |      Construct a BigQuery Storage API representation of this table.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: A reference to this table in the BigQuery Storage API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'Table' from builtins.type\n",
      "     |      Factory: construct a table given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]):\n",
      "     |              Table resource representation from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.Table: Table parsed from ``resource``.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          KeyError:\n",
      "     |              If the ``resource`` lacks the key ``'tableReference'``, or if\n",
      "     |              the ``dict`` stored within the key ``'tableReference'`` lacks\n",
      "     |              the keys ``'tableId'``, ``'projectId'``, or ``'datasetId'``.\n",
      "     |\n",
      "     |  from_string(full_table_id: str) -> 'Table' from builtins.type\n",
      "     |      Construct a table from fully-qualified table ID.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          full_table_id (str):\n",
      "     |              A fully-qualified table ID in standard SQL format. Must\n",
      "     |              included a project ID, dataset ID, and table ID, each\n",
      "     |              separated by ``.``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Table: Table parsed from ``full_table_id``.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |          >>> Table.from_string('my-project.mydataset.mytable')\n",
      "     |          Table(TableRef...(D...('my-project', 'mydataset'), 'mytable'))\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``full_table_id`` is not a fully-qualified table ID in\n",
      "     |              standard SQL format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  clone_definition\n",
      "     |      Information about the clone. This value is set via clone creation.\n",
      "     |\n",
      "     |      See: https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#Table.FIELDS.clone_definition\n",
      "     |\n",
      "     |  created\n",
      "     |      Union[datetime.datetime, None]: Datetime at which the table was\n",
      "     |      created (:data:`None` until set from the server).\n",
      "     |\n",
      "     |  etag\n",
      "     |      Union[str, None]: ETag for the table resource (:data:`None` until\n",
      "     |      set from the server).\n",
      "     |\n",
      "     |  full_table_id\n",
      "     |      Union[str, None]: ID for the table (:data:`None` until set from the\n",
      "     |      server).\n",
      "     |\n",
      "     |      In the format ``project-id:dataset_id.table_id``.\n",
      "     |\n",
      "     |  location\n",
      "     |      Union[str, None]: Location in which the table is hosted\n",
      "     |\n",
      "     |      Defaults to :data:`None`.\n",
      "     |\n",
      "     |  modified\n",
      "     |      Union[datetime.datetime, None]: Datetime at which the table was last\n",
      "     |      modified (:data:`None` until set from the server).\n",
      "     |\n",
      "     |  mview_last_refresh_time\n",
      "     |      Optional[datetime.datetime]: Datetime at which the materialized view was last\n",
      "     |      refreshed (:data:`None` until set from the server).\n",
      "     |\n",
      "     |  num_bytes\n",
      "     |      Union[int, None]: The size of the table in bytes (:data:`None` until\n",
      "     |      set from the server).\n",
      "     |\n",
      "     |  num_rows\n",
      "     |      Union[int, None]: The number of rows in the table (:data:`None`\n",
      "     |      until set from the server).\n",
      "     |\n",
      "     |  reference\n",
      "     |      A :class:`~google.cloud.bigquery.table.TableReference` pointing to\n",
      "     |      this table.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.TableReference: pointer to this table.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      Union[str, None]: URL for the table resource (:data:`None` until set\n",
      "     |      from the server).\n",
      "     |\n",
      "     |  snapshot_definition\n",
      "     |      Information about the snapshot. This value is set via snapshot creation.\n",
      "     |\n",
      "     |      See: https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#Table.FIELDS.snapshot_definition\n",
      "     |\n",
      "     |  streaming_buffer\n",
      "     |      google.cloud.bigquery.StreamingBuffer: Information about a table's\n",
      "     |      streaming buffer.\n",
      "     |\n",
      "     |  table_constraints\n",
      "     |      Tables Primary Key and Foreign Key information.\n",
      "     |\n",
      "     |  table_type\n",
      "     |      Union[str, None]: The type of the table (:data:`None` until set from\n",
      "     |      the server).\n",
      "     |\n",
      "     |      Possible values are ``'TABLE'``, ``'VIEW'``, ``'MATERIALIZED_VIEW'`` or\n",
      "     |      ``'EXTERNAL'``.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  clustering_fields\n",
      "     |      Union[List[str], None]: Fields defining clustering for the table\n",
      "     |\n",
      "     |      (Defaults to :data:`None`).\n",
      "     |\n",
      "     |      Clustering fields are immutable after table creation.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |\n",
      "     |         BigQuery supports clustering for both partitioned and\n",
      "     |         non-partitioned tables.\n",
      "     |\n",
      "     |  description\n",
      "     |      Union[str, None]: Description of the table (defaults to\n",
      "     |      :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  encryption_configuration\n",
      "     |      google.cloud.bigquery.encryption_configuration.EncryptionConfiguration: Custom\n",
      "     |      encryption configuration for the table.\n",
      "     |\n",
      "     |      Custom encryption configuration (e.g., Cloud KMS keys) or :data:`None`\n",
      "     |      if using default encryption.\n",
      "     |\n",
      "     |      See `protecting data with Cloud KMS keys\n",
      "     |      <https://cloud.google.com/bigquery/docs/customer-managed-encryption>`_\n",
      "     |      in the BigQuery documentation.\n",
      "     |\n",
      "     |  expires\n",
      "     |      Union[datetime.datetime, None]: Datetime at which the table will be\n",
      "     |      deleted.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  external_data_configuration\n",
      "     |      Union[google.cloud.bigquery.ExternalConfig, None]: Configuration for\n",
      "     |      an external data source (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  friendly_name\n",
      "     |      Union[str, None]: Title of the table (defaults to :data:`None`).\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the table.\n",
      "     |\n",
      "     |      This method always returns a dict. To change a table's labels,\n",
      "     |      modify the dict, then call ``Client.update_table``. To delete a\n",
      "     |      label, set its value to :data:`None` before updating.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: If ``value`` type is invalid.\n",
      "     |\n",
      "     |  mview_enable_refresh\n",
      "     |      Optional[bool]: Enable automatic refresh of the materialized view\n",
      "     |      when the base table is updated. The default value is :data:`True`.\n",
      "     |\n",
      "     |  mview_query\n",
      "     |      Optional[str]: SQL query defining the table as a materialized\n",
      "     |      view (defaults to :data:`None`).\n",
      "     |\n",
      "     |  mview_refresh_interval\n",
      "     |      Optional[datetime.timedelta]: The maximum frequency at which this\n",
      "     |      materialized view will be refreshed. The default value is 1800000\n",
      "     |      milliseconds (30 minutes).\n",
      "     |\n",
      "     |  partition_expiration\n",
      "     |      Union[int, None]: Expiration time in milliseconds for a partition.\n",
      "     |\n",
      "     |      If :attr:`partition_expiration` is set and :attr:`type_` is\n",
      "     |      not set, :attr:`type_` will default to\n",
      "     |      :attr:`~google.cloud.bigquery.table.TimePartitioningType.DAY`.\n",
      "     |\n",
      "     |  partitioning_type\n",
      "     |      Union[str, None]: Time partitioning of the table if it is\n",
      "     |      partitioned (Defaults to :data:`None`).\n",
      "     |\n",
      "     |  range_partitioning\n",
      "     |      Optional[google.cloud.bigquery.table.RangePartitioning]:\n",
      "     |      Configures range-based partitioning for a table.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          **Beta**. The integer range partitioning feature is in a\n",
      "     |          pre-release state and might change or have limited support.\n",
      "     |\n",
      "     |      Only specify at most one of\n",
      "     |      :attr:`~google.cloud.bigquery.table.Table.time_partitioning` or\n",
      "     |      :attr:`~google.cloud.bigquery.table.Table.range_partitioning`.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not\n",
      "     |              :class:`~google.cloud.bigquery.table.RangePartitioning` or\n",
      "     |              :data:`None`.\n",
      "     |\n",
      "     |  require_partition_filter\n",
      "     |      bool: If set to true, queries over the partitioned table require a\n",
      "     |      partition filter that can be used for partition elimination to be\n",
      "     |      specified.\n",
      "     |\n",
      "     |  schema\n",
      "     |      Sequence[Union[                 :class:`~google.cloud.bigquery.schema.SchemaField`,                 Mapping[str, Any]         ]]:\n",
      "     |          Table's schema.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          Exception:\n",
      "     |              If ``schema`` is not a sequence, or if any item in the sequence\n",
      "     |              is not a :class:`~google.cloud.bigquery.schema.SchemaField`\n",
      "     |              instance or a compatible mapping representation of the field.\n",
      "     |\n",
      "     |  time_partitioning\n",
      "     |      Optional[google.cloud.bigquery.table.TimePartitioning]: Configures time-based\n",
      "     |      partitioning for a table.\n",
      "     |\n",
      "     |      Only specify at most one of\n",
      "     |      :attr:`~google.cloud.bigquery.table.Table.time_partitioning` or\n",
      "     |      :attr:`~google.cloud.bigquery.table.Table.range_partitioning`.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If the value is not\n",
      "     |              :class:`~google.cloud.bigquery.table.TimePartitioning` or\n",
      "     |              :data:`None`.\n",
      "     |\n",
      "     |  view_query\n",
      "     |      Union[str, None]: SQL query defining the table as a view (defaults\n",
      "     |      to :data:`None`).\n",
      "     |\n",
      "     |      By default, the query is treated as Standard SQL. To use Legacy\n",
      "     |      SQL, set :attr:`view_use_legacy_sql` to :data:`True`.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  view_use_legacy_sql\n",
      "     |      bool: Specifies whether to execute the view with Legacy or Standard SQL.\n",
      "     |\n",
      "     |      This boolean specifies whether to execute the view with Legacy SQL\n",
      "     |      (:data:`True`) or Standard SQL (:data:`False`). The client side default is\n",
      "     |      :data:`False`. The server-side default is :data:`True`. If this table is\n",
      "     |      not a view, :data:`None` is returned.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError: For invalid value types.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _TableBase:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _TableBase:\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      ID of dataset containing the table.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the table's APIs.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the table.\n",
      "     |\n",
      "     |  table_id\n",
      "     |      The table ID.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _TableBase:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class TableReference(_TableBase)\n",
      "     |  TableReference(dataset_ref: 'DatasetReference', table_id: str)\n",
      "     |\n",
      "     |  TableReferences are pointers to tables.\n",
      "     |\n",
      "     |  See\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#tablereference\n",
      "     |\n",
      "     |  Args:\n",
      "     |      dataset_ref: A pointer to the dataset\n",
      "     |      table_id: The ID of the table\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      TableReference\n",
      "     |      _TableBase\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, dataset_ref: 'DatasetReference', table_id: str)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Construct the API resource representation of this table reference.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Dict[str, object]: Table reference represented as an API resource\n",
      "     |\n",
      "     |  to_bqstorage(self) -> str\n",
      "     |      Construct a BigQuery Storage API representation of this table.\n",
      "     |\n",
      "     |      Install the ``google-cloud-bigquery-storage`` package to use this\n",
      "     |      feature.\n",
      "     |\n",
      "     |      If the ``table_id`` contains a partition identifier (e.g.\n",
      "     |      ``my_table$201812``) or a snapshot identifier (e.g.\n",
      "     |      ``mytable@1234567890``), it is ignored. Use\n",
      "     |      :class:`google.cloud.bigquery_storage.types.ReadSession.TableReadOptions`\n",
      "     |      to filter rows by partition. Use\n",
      "     |      :class:`google.cloud.bigquery_storage.types.ReadSession.TableModifiers`\n",
      "     |      to select a specific snapshot to read from.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: A reference to this table in the BigQuery Storage API.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict) -> 'TableReference' from builtins.type\n",
      "     |      Factory:  construct a table reference given its API representation\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict[str, object]):\n",
      "     |              Table reference representation returned from the API\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.TableReference:\n",
      "     |              Table reference parsed from ``resource``.\n",
      "     |\n",
      "     |  from_string(table_id: str, default_project: Optional[str] = None) -> 'TableReference' from builtins.type\n",
      "     |      Construct a table reference from table ID string.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          table_id (str):\n",
      "     |              A table ID in standard SQL format. If ``default_project``\n",
      "     |              is not specified, this must included a project ID, dataset\n",
      "     |              ID, and table ID, each separated by ``.``.\n",
      "     |          default_project (Optional[str]):\n",
      "     |              The project ID to use when ``table_id`` does not\n",
      "     |              include a project ID.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          TableReference: Table reference parsed from ``table_id``.\n",
      "     |\n",
      "     |      Examples:\n",
      "     |          >>> TableReference.from_string('my-project.mydataset.mytable')\n",
      "     |          TableRef...(DatasetRef...('my-project', 'mydataset'), 'mytable')\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          ValueError:\n",
      "     |              If ``table_id`` is not a fully-qualified table ID in\n",
      "     |              standard SQL format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _TableBase:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _TableBase:\n",
      "     |\n",
      "     |  dataset_id\n",
      "     |      ID of dataset containing the table.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the table's APIs.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the table.\n",
      "     |\n",
      "     |  table_id\n",
      "     |      The table ID.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _TableBase:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class TimePartitioning(builtins.object)\n",
      "     |  TimePartitioning(type_=None, field=None, expiration_ms=None, require_partition_filter=None) -> None\n",
      "     |\n",
      "     |  Configures time-based partitioning for a table.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      type_ (Optional[google.cloud.bigquery.table.TimePartitioningType]):\n",
      "     |          Specifies the type of time partitioning to perform. Defaults to\n",
      "     |          :attr:`~google.cloud.bigquery.table.TimePartitioningType.DAY`.\n",
      "     |\n",
      "     |          Supported values are:\n",
      "     |\n",
      "     |          * :attr:`~google.cloud.bigquery.table.TimePartitioningType.HOUR`\n",
      "     |          * :attr:`~google.cloud.bigquery.table.TimePartitioningType.DAY`\n",
      "     |          * :attr:`~google.cloud.bigquery.table.TimePartitioningType.MONTH`\n",
      "     |          * :attr:`~google.cloud.bigquery.table.TimePartitioningType.YEAR`\n",
      "     |\n",
      "     |      field (Optional[str]):\n",
      "     |          If set, the table is partitioned by this field. If not set, the\n",
      "     |          table is partitioned by pseudo column ``_PARTITIONTIME``. The field\n",
      "     |          must be a top-level ``TIMESTAMP``, ``DATETIME``, or ``DATE``\n",
      "     |          field. Its mode must be ``NULLABLE`` or ``REQUIRED``.\n",
      "     |\n",
      "     |          See the `time-unit column-partitioned tables guide\n",
      "     |          <https://cloud.google.com/bigquery/docs/creating-column-partitions>`_\n",
      "     |          in the BigQuery documentation.\n",
      "     |      expiration_ms(Optional[int]):\n",
      "     |          Number of milliseconds for which to keep the storage for a\n",
      "     |          partition.\n",
      "     |      require_partition_filter (Optional[bool]):\n",
      "     |          DEPRECATED: Use\n",
      "     |          :attr:`~google.cloud.bigquery.table.Table.require_partition_filter`,\n",
      "     |          instead.\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __init__(self, type_=None, field=None, expiration_ms=None, require_partition_filter=None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  to_api_repr(self) -> dict\n",
      "     |      Return a dictionary representing this object.\n",
      "     |\n",
      "     |      This method returns the properties dict of the ``TimePartitioning``\n",
      "     |      instance rather than making a copy. This means that when a\n",
      "     |      ``TimePartitioning`` instance is stored as a property of another\n",
      "     |      object, any changes made at the higher level will also appear here.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          dict:\n",
      "     |              A dictionary representing the TimePartitioning object in\n",
      "     |              serialized form.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(api_repr: dict) -> 'TimePartitioning' from builtins.type\n",
      "     |      Return a :class:`TimePartitioning` object deserialized from a dict.\n",
      "     |\n",
      "     |      This method creates a new ``TimePartitioning`` instance that points to\n",
      "     |      the ``api_repr`` parameter as its internal properties dict. This means\n",
      "     |      that when a ``TimePartitioning`` instance is stored as a property of\n",
      "     |      another object, any changes made at the higher level will also appear\n",
      "     |      here::\n",
      "     |\n",
      "     |          >>> time_partitioning = TimePartitioning()\n",
      "     |          >>> table.time_partitioning = time_partitioning\n",
      "     |          >>> table.time_partitioning.field = 'timecolumn'\n",
      "     |          >>> time_partitioning.field\n",
      "     |          'timecolumn'\n",
      "     |\n",
      "     |      Args:\n",
      "     |          api_repr (Mapping[str, str]):\n",
      "     |              The serialized representation of the TimePartitioning, such as\n",
      "     |              what is output by :meth:`to_api_repr`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          google.cloud.bigquery.table.TimePartitioning:\n",
      "     |              The ``TimePartitioning`` object.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  expiration_ms\n",
      "     |      int: Number of milliseconds to keep the storage for a partition.\n",
      "     |\n",
      "     |  field\n",
      "     |      str: Field in the table to use for partitioning\n",
      "     |\n",
      "     |  require_partition_filter\n",
      "     |      bool: Specifies whether partition filters are required for queries\n",
      "     |\n",
      "     |      DEPRECATED: Use\n",
      "     |      :attr:`~google.cloud.bigquery.table.Table.require_partition_filter`,\n",
      "     |      instead.\n",
      "     |\n",
      "     |  type_\n",
      "     |      google.cloud.bigquery.table.TimePartitioningType: The type of time\n",
      "     |      partitioning to use.\n",
      "\n",
      "    class TimePartitioningType(builtins.object)\n",
      "     |  Specifies the type of time partitioning to perform.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  DAY = 'DAY'\n",
      "     |\n",
      "     |  HOUR = 'HOUR'\n",
      "     |\n",
      "     |  MONTH = 'MONTH'\n",
      "     |\n",
      "     |  YEAR = 'YEAR'\n",
      "\n",
      "    class TransactionInfo(builtins.tuple)\n",
      "     |  TransactionInfo(transaction_id: str)\n",
      "     |\n",
      "     |  [Alpha] Information of a multi-statement transaction.\n",
      "     |\n",
      "     |  https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#TransactionInfo\n",
      "     |\n",
      "     |  .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      TransactionInfo\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |\n",
      "     |  _asdict(self)\n",
      "     |      Return a new dict which maps field names to their values.\n",
      "     |\n",
      "     |  _replace(self, /, **kwds)\n",
      "     |      Return a new TransactionInfo object replacing specified fields with new values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  _make(iterable) from builtins.type\n",
      "     |      Make a new TransactionInfo object from a sequence or iterable\n",
      "     |\n",
      "     |  from_api_repr(transaction_info: Dict[str, str]) -> 'TransactionInfo' from builtins.type\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |\n",
      "     |  __new__(_cls, transaction_id: str)\n",
      "     |      Create new instance of TransactionInfo(transaction_id,)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  transaction_id\n",
      "     |      Alias for field number 0\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'transaction_id': <class 'str'>}\n",
      "     |\n",
      "     |  __match_args__ = ('transaction_id',)\n",
      "     |\n",
      "     |  __orig_bases__ = (<function NamedTuple>,)\n",
      "     |\n",
      "     |  _field_defaults = {}\n",
      "     |\n",
      "     |  _fields = ('transaction_id',)\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |\n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |\n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return bool(key in self).\n",
      "     |\n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |\n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |\n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |\n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |\n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |\n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |\n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |\n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |\n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |\n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |\n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |\n",
      "     |  count(self, value, /)\n",
      "     |      Return number of occurrences of value.\n",
      "     |\n",
      "     |  index(self, value, start=0, stop=9223372036854775807, /)\n",
      "     |      Return first index of value.\n",
      "     |\n",
      "     |      Raises ValueError if the value is not present.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from builtins.tuple:\n",
      "     |\n",
      "     |  __class_getitem__(...) from builtins.type\n",
      "     |      See PEP 585\n",
      "\n",
      "    class UDFResource(builtins.object)\n",
      "     |  UDFResource(udf_type, value)\n",
      "     |\n",
      "     |  Describe a single user-defined function (UDF) resource.\n",
      "     |\n",
      "     |  Args:\n",
      "     |      udf_type (str): The type of the resource ('inlineCode' or 'resourceUri')\n",
      "     |\n",
      "     |      value (str): The inline code or resource URI.\n",
      "     |\n",
      "     |  See:\n",
      "     |  https://cloud.google.com/bigquery/user-defined-functions#api\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |\n",
      "     |  __init__(self, udf_type, value)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __hash__ = None\n",
      "\n",
      "    class UnknownJob(_AsyncJob)\n",
      "     |  UnknownJob(job_id, client)\n",
      "     |\n",
      "     |  A job whose type cannot be determined.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      UnknownJob\n",
      "     |      _AsyncJob\n",
      "     |      google.api_core.future.polling.PollingFuture\n",
      "     |      google.api_core.future.base.Future\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Class methods defined here:\n",
      "     |\n",
      "     |  from_api_repr(resource: dict, client) -> 'UnknownJob' from abc.ABCMeta\n",
      "     |      Construct an UnknownJob from the JSON representation.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          resource (Dict): JSON representation of a job.\n",
      "     |          client (google.cloud.bigquery.client.Client):\n",
      "     |              Client connected to BigQuery API.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          UnknownJob: Job corresponding to the resource.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _AsyncJob:\n",
      "     |\n",
      "     |  __init__(self, job_id, client)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  cancel(self, client=None, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  cancel job via a POST request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/cancel\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating that the cancel request was sent.\n",
      "     |\n",
      "     |  cancelled(self)\n",
      "     |      Check if the job has been cancelled.\n",
      "     |\n",
      "     |      This always returns False. It's not possible to check if a job was\n",
      "     |      cancelled in the API. This method is here to satisfy the interface\n",
      "     |      for :class:`google.api_core.future.Future`.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: False\n",
      "     |\n",
      "     |  done(self, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None, reload: bool = True) -> bool\n",
      "     |      Checks if the job is complete.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |          reload (Optional[bool]):\n",
      "     |              If ``True``, make an API call to refresh the job state of\n",
      "     |              unfinished jobs before checking. Default ``True``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: True if the job is complete, False otherwise.\n",
      "     |\n",
      "     |  exists(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> bool\n",
      "     |      API call:  test for the existence of the job via a GET request\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          bool: Boolean indicating existence of the job.\n",
      "     |\n",
      "     |  reload(self, client=None, retry: 'retries.Retry' = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None)\n",
      "     |      API call:  refresh job properties via a GET request.\n",
      "     |\n",
      "     |      See\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get\n",
      "     |\n",
      "     |      Args:\n",
      "     |          client (Optional[google.cloud.bigquery.client.Client]):\n",
      "     |              the client to use.  If not passed, falls back to the\n",
      "     |              ``client`` stored on the current dataset.\n",
      "     |\n",
      "     |          retry (Optional[google.api_core.retry.Retry]): How to retry the RPC.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |\n",
      "     |  result(self, retry: Optional[google.api_core.retry.retry_unary.Retry] = <google.api_core.retry.retry_unary.Retry object at 0x720289c185c0>, timeout: Optional[float] = None) -> '_AsyncJob'\n",
      "     |      Start the job and wait for it to complete and get the result.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          retry (Optional[google.api_core.retry.Retry]):\n",
      "     |              How to retry the RPC. If the job state is ``DONE``, retrying is aborted\n",
      "     |              early, as the job will not change anymore.\n",
      "     |          timeout (Optional[float]):\n",
      "     |              The number of seconds to wait for the underlying HTTP transport\n",
      "     |              before using ``retry``.\n",
      "     |              If multiple requests are made under the hood, ``timeout``\n",
      "     |              applies to each individual request.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          _AsyncJob: This instance.\n",
      "     |\n",
      "     |      Raises:\n",
      "     |          google.cloud.exceptions.GoogleAPICallError:\n",
      "     |              if the job failed.\n",
      "     |          concurrent.futures.TimeoutError:\n",
      "     |              if the job did not complete in the given timeout.\n",
      "     |\n",
      "     |  to_api_repr(self)\n",
      "     |      Generate a resource for the job.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _AsyncJob:\n",
      "     |\n",
      "     |  configuration\n",
      "     |      Job-type specific configurtion.\n",
      "     |\n",
      "     |  created\n",
      "     |      Datetime at which the job was created.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the creation time (None until set from the server).\n",
      "     |\n",
      "     |  ended\n",
      "     |      Datetime at which the job finished.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the end time (None until set from the server).\n",
      "     |\n",
      "     |  error_result\n",
      "     |      Error information about the job as a whole.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[Mapping]: the error information (None until set from the server).\n",
      "     |\n",
      "     |  errors\n",
      "     |      Information about individual errors generated by the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[List[Mapping]]:\n",
      "     |              the error information (None until set from the server).\n",
      "     |\n",
      "     |  etag\n",
      "     |      ETag for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the ETag (None until set from the server).\n",
      "     |\n",
      "     |  job_id\n",
      "     |      str: ID of the job.\n",
      "     |\n",
      "     |  job_type\n",
      "     |      Type of job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: one of 'load', 'copy', 'extract', 'query'.\n",
      "     |\n",
      "     |  labels\n",
      "     |      Dict[str, str]: Labels for the job.\n",
      "     |\n",
      "     |  location\n",
      "     |      str: Location where the job runs.\n",
      "     |\n",
      "     |  num_child_jobs\n",
      "     |      The number of child jobs executed.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.num_child_jobs\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          int\n",
      "     |\n",
      "     |  parent_job_id\n",
      "     |      Return the ID of the parent job.\n",
      "     |\n",
      "     |      See:\n",
      "     |      https://cloud.google.com/bigquery/docs/reference/rest/v2/Job#JobStatistics.FIELDS.parent_job_id\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: parent job id.\n",
      "     |\n",
      "     |  path\n",
      "     |      URL path for the job's APIs.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the path based on project and job ID.\n",
      "     |\n",
      "     |  project\n",
      "     |      Project bound to the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          str: the project (derived from the client).\n",
      "     |\n",
      "     |  reservation_usage\n",
      "     |      Job resource usage breakdown by reservation.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          List[google.cloud.bigquery.job.ReservationUsage]:\n",
      "     |              Reservation usage stats. Can be empty if not set from the server.\n",
      "     |\n",
      "     |  script_statistics\n",
      "     |      Statistics for a child job of a script.\n",
      "     |\n",
      "     |  self_link\n",
      "     |      URL for the job resource.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  session_info\n",
      "     |      [Preview] Information of the session if this job is part of one.\n",
      "     |\n",
      "     |      .. versionadded:: 2.29.0\n",
      "     |\n",
      "     |  started\n",
      "     |      Datetime at which the job was started.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[datetime.datetime]:\n",
      "     |              the start time (None until set from the server).\n",
      "     |\n",
      "     |  state\n",
      "     |      Status of the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]:\n",
      "     |              the state (None until set from the server).\n",
      "     |\n",
      "     |  transaction_info\n",
      "     |      Information of the multi-statement transaction if this job is part of one.\n",
      "     |\n",
      "     |      Since a scripting query job can execute multiple transactions, this\n",
      "     |      property is only expected on child jobs. Use the\n",
      "     |      :meth:`google.cloud.bigquery.client.Client.list_jobs` method with the\n",
      "     |      ``parent_job`` parameter to iterate over child jobs.\n",
      "     |\n",
      "     |      .. versionadded:: 2.24.0\n",
      "     |\n",
      "     |  user_email\n",
      "     |      E-mail address of user who submitted the job.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[str]: the URL (None until set from the server).\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.api_core.future.polling.PollingFuture:\n",
      "     |\n",
      "     |  add_done_callback(self, fn)\n",
      "     |      Add a callback to be executed when the operation is complete.\n",
      "     |\n",
      "     |      If the operation is not already complete, this will start a helper\n",
      "     |      thread to poll for the status of the operation in the background.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          fn (Callable[Future]): The callback to execute when the operation\n",
      "     |              is complete.\n",
      "     |\n",
      "     |  exception(self, timeout=<object object at 0x7202a04c6650>)\n",
      "     |      Get the exception from the operation, blocking if necessary.\n",
      "     |\n",
      "     |      See the documentation for the :meth:`result` method for details on how\n",
      "     |      this method operates, as both ``result`` and this method rely on the\n",
      "     |      exact same polling logic. The only difference is that this method does\n",
      "     |      not accept ``retry`` and ``polling`` arguments but relies on the default ones\n",
      "     |      instead.\n",
      "     |\n",
      "     |      Args:\n",
      "     |          timeout (int): How long to wait for the operation to complete.\n",
      "     |          If None, wait indefinitely.\n",
      "     |\n",
      "     |      Returns:\n",
      "     |          Optional[google.api_core.GoogleAPICallError]: The operation's\n",
      "     |              error.\n",
      "     |\n",
      "     |  running(self)\n",
      "     |      True if the operation is currently running.\n",
      "     |\n",
      "     |  set_exception(self, exception)\n",
      "     |      Set the Future's exception.\n",
      "     |\n",
      "     |  set_result(self, result)\n",
      "     |      Set the Future's result.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.api_core.future.base.Future:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class WriteDisposition(builtins.object)\n",
      "     |  Specifies the action that occurs if destination table already exists.\n",
      "     |\n",
      "     |  The default value is :attr:`WRITE_APPEND`.\n",
      "     |\n",
      "     |  Each action is atomic and only occurs if BigQuery is able to complete\n",
      "     |  the job successfully. Creation, truncation and append actions occur as one\n",
      "     |  atomic update upon job completion.\n",
      "     |\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  WRITE_APPEND = 'WRITE_APPEND'\n",
      "     |\n",
      "     |  WRITE_EMPTY = 'WRITE_EMPTY'\n",
      "     |\n",
      "     |  WRITE_TRUNCATE = 'WRITE_TRUNCATE'\n",
      "\n",
      "DATA\n",
      "    DEFAULT_RETRY = <google.api_core.retry.retry_unary.Retry object>\n",
      "    __all__ = ['__version__', 'Client', 'ConnectionProperty', 'QueryJob', ...\n",
      "\n",
      "VERSION\n",
      "    3.19.0\n",
      "\n",
      "FILE\n",
      "    /data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/cloud/bigquery/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bigquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## the Client object is set to interact with the data in Google Cloud.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mbigquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## construct a reference using client with the dataset method for the hacker_news dataset contained in the bigquery-public-data project \u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataset_ref \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mdataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhacker_news\u001b[39m\u001b[38;5;124m'\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbigquery-public-data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/cloud/bigquery/client.py:241\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, project, credentials, _http, location, default_query_job_config, default_load_job_config, client_info, client_options)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    232\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_http\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     kw_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: client_info}\n\u001b[1;32m    249\u001b[0m     bq_host \u001b[38;5;241m=\u001b[39m _get_bigquery_host()\n",
      "File \u001b[0;32m/data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/cloud/client/__init__.py:320\u001b[0m, in \u001b[0;36mClientWithProject.__init__\u001b[0;34m(self, project, credentials, client_options, _http)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, credentials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _http\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 320\u001b[0m     \u001b[43m_ClientProjectMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     Client\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mself\u001b[39m, credentials\u001b[38;5;241m=\u001b[39mcredentials, client_options\u001b[38;5;241m=\u001b[39mclient_options, _http\u001b[38;5;241m=\u001b[39m_http\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m/data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/cloud/client/__init__.py:268\u001b[0m, in \u001b[0;36m_ClientProjectMixin.__init__\u001b[0;34m(self, project, credentials)\u001b[0m\n\u001b[1;32m    265\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_determine_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject was not passed and could not be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetermined from the environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     )\n",
      "File \u001b[0;32m/data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/cloud/client/__init__.py:287\u001b[0m, in \u001b[0;36m_ClientProjectMixin._determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_determine_default\u001b[39m(project):\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper:  use default project detection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_determine_default_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/cloud/_helpers/__init__.py:152\u001b[0m, in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine default project ID explicitly or implicitly as fall-back.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mSee :func:`google.auth.default` for details on how the default project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m:returns: Default project if it can be determined.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     _, project \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m project\n",
      "File \u001b[0;32m/data/miniconda3/envs/kagglesql/lib/python3.12/site-packages/google/auth/_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    688\u001b[0m             )\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "## the Client object is set to interact with the data in Google Cloud.\n",
    "client = bigquery.Client()\n",
    "\n",
    "## construct a reference using client with the dataset method for the hacker_news dataset contained in the bigquery-public-data project \n",
    "dataset_ref = client.dataset('hacker_news', project='bigquery-public-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
